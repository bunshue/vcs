## Scrapy爬蟲框架分佈式實現

### 分佈式爬蟲原理



### Scrapy分佈式實現

1. 安裝Scrapy-Redis。
2. 配置Redis服務器。
3. 修改配置文件。
   - SCHEDULER = 'scrapy_redis.scheduler.Scheduler'
   - DUPEFILTER_CLASS = 'scrapy_redis.dupefilter.RFPDupeFilter'
   - REDIS_HOST = '1.2.3.4'
   - REDIS_PORT = 6379
   - REDIS_PASSWORD = '1qaz2wsx'
   - SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'
   - SCHEDULER_PERSIST = True（通過持久化支持接續爬取）
   - SCHEDULER_FLUSH_ON_START = True（每次啟動時重新爬取）

### Scrapyd分佈式部署

1. 安裝Scrapyd
2. 修改配置文件
   - mkdir /etc/scrapyd
   - vim /etc/scrapyd/scrapyd.conf
3. 安裝Scrapyd-Client
   - 將項目打包成Egg文件。
   - 將打包的Egg文件通過addversion.json接口部署到Scrapyd上。

