{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "## Outline\n",
    "\n",
    "2. Architecures\n",
    "2. Train and test functions\n",
    "3. CNN models\n",
    "4. MNIST\n",
    "5. CIFAR-10\n",
    " \n",
    "Sources:\n",
    "\n",
    "Deep learning\n",
    "- [cs231n.stanford.edu](http://cs231n.stanford.edu/)\n",
    "\n",
    "CNN\n",
    "- [Stanford cs231n](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "Pytorch\n",
    "- [WWW tutorials](https://pytorch.org/tutorials/)\n",
    "- [github tutorials](https://github.com/pytorch/tutorials)\n",
    "- [github examples](https://github.com/pytorch/examples)\n",
    "\n",
    "MNIST and pytorch:\n",
    "- [MNIST nextjournal.com/gkoehler/pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
    "- [MNIST github/pytorch/examples](https://github.com/pytorch/examples/tree/master/mnist)\n",
    "- [MNIST kaggle](https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist)\n",
    "\n",
    "## Architectures\n",
    "\n",
    "Sources:\n",
    "\n",
    "- [cv-tricks.com](https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception)\n",
    "- [zhenye-na.github.io(]https://zhenye-na.github.io/2018/12/01/cnn-deep-leearning-ai-week2.html)\n",
    "\n",
    "\n",
    "### LeNet\n",
    "\n",
    "The first  Convolutional Networks were developed by Yann LeCun in 1990â€™s.\n",
    "\n",
    "![LeNet](./figures/LeNet_Original_Image.jpg)\n",
    "\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "(2012, Alex Krizhevsky, Ilya Sutskever and Geoff Hinton)\n",
    "\n",
    "![AlexNet](./figures/alexnet.png)\n",
    "\n",
    "![AlexNet architecture](./figures/alexnet_param_tab.png)\n",
    "\n",
    "\n",
    "- Deeper, bigger,\n",
    "- Featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer always immediately followed by a POOL layer).\n",
    "- **ReLu(Rectified Linear Unit)** for the non-linear part, instead of a Tanh or Sigmoid.\n",
    "\n",
    "The advantage of the ReLu over sigmoid is that it trains much faster than the latter because the derivative of sigmoid becomes very small in the saturating region and therefore the updates to the weights almost vanish. This is called **vanishing gradient problem**.\n",
    "\n",
    "- **Dropout**: reduces the over-fitting by using a Dropout layer after every FC layer. Dropout layer has a probability,(p), associated with it and is applied at every neuron of the response map separately. It randomly switches off the activation with the probability p.  \n",
    "\n",
    "![Dropout](./figures/dropout.png)\n",
    "\n",
    "\n",
    "Why does DropOut work?\n",
    "\n",
    "The idea behind the dropout is similar to the model ensembles. Due to the dropout layer, different sets of neurons which are switched off, represent a different architecture and all these different architectures are trained in parallel with weight given to each subset and the summation of weights being one. For n neurons attached to DropOut, the number of subset architectures formed is 2^n. So it amounts to prediction being averaged over these ensembles of models. This provides a structured model regularization which helps in avoiding the over-fitting. Another view of DropOut being helpful is that since neurons are randomly chosen, they tend to avoid developing co-adaptations among themselves thereby enabling them to develop meaningful features, independent of others.\n",
    "\n",
    "- **Data augmentation** is carried out to reduce over-fitting. This Data augmentation includes mirroring and cropping the images to increase the variation in the training data-set.\n",
    "\n",
    "\n",
    "**GoogLeNet**. (Szegedy et al. from Google 2014) was a Convolutional Network . Its main contribution was the development of an\n",
    "\n",
    "- **Inception Module** that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M).\n",
    "\n",
    "![Inception Module](./figures/inception_block.png){width=15cm}\n",
    "\n",
    "- There are also several followup versions to the GoogLeNet, most recently Inception-v4.\n",
    "\n",
    "**VGGNet**. (Karen Simonyan and Andrew Zisserman 2014)\n",
    "\n",
    "![VGGNet](./figures/vgg.png){width=15cm}\n",
    "\n",
    "![VGGNet architecture](./figures/vgg_param_tab.png){width=15cm}\n",
    "\n",
    "- 16 CONV/FC layers and, appealingly, features an extremely homogeneous architecture.\n",
    "\n",
    "- Only performs 3x3 convolutions and 2x2 pooling from the beginning to the end. Replace large kernel-sized filters(11 and 5 in the first and second convolutional layer, respectively) with multiple 3X3 kernel-sized filters one after another.\n",
    "\n",
    "With a given receptive field(the effective area size of input image on which output depends), multiple stacked smaller size kernel is better than the one with a larger size kernel because multiple non-linear layers increases the depth of the network which enables it to learn more complex features, and that too at a lower cost. For example, three 3X3 filters on top of each other with stride 1 ha a receptive size of 7, but the number of parameters involved is 3*(9^2) in comparison to 49^2 parameters of kernels with a size of 7. \n",
    "\n",
    "- Lot more memory and parameters (140M)\n",
    "\n",
    "**ResNet**. (Kaiming He et al. 2015)\n",
    "\n",
    "Resnet block variants ([Source](http://torch.ch/blog/2016/02/04/resnets.html)):\n",
    "\n",
    "![ResNet block](./figures/resnets_modelvariants.png){width=15cm}\n",
    "\n",
    "![ResNet 18](./figures/resnet18.png){width=15cm}\n",
    "\n",
    "![ResNet 18 architecture](./figures/resnet_param_tab.png){width=15cm}\n",
    "\n",
    "- Skip connections\n",
    "- Batch normalization. \n",
    "- State of the art CNN models and are the default choice (as of May 10, 2016). In particular, also see more\n",
    "- Recent developments that tweak the original architecture from Kaiming He et al. Identity Mappings in Deep Residual Networks (published March 2016).\n",
    "\n",
    "[Models in pytorch](https://github.com/pytorch/vision/tree/master/torchvision/models)\n",
    "\n",
    "\n",
    "## Architecures general guidelines\n",
    "\n",
    "- ConvNets stack CONV,POOL,FC layers\n",
    "- Trend towards smaller filters and deeper architectures: stack 3x3, instead of 5x5\n",
    "- Trend towards getting rid of POOL/FC layers (just CONV)\n",
    "- Historically architectures looked like [(CONV-RELU) x N POOL?] x M (FC-RELU) x K, SOFTMAX where N is usually up to ~5, M is large, 0 <= K <= 2.\n",
    "- but recent advances such as ResNet/GoogLeNet have challenged this paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "#\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu' # Force CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train_val_model.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "def train_val_model(model, criterion, optimizer, dataloaders, num_epochs=25,\n",
    "        scheduler=None, log_interval=None):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Store losses and accuracies accross epochs\n",
    "    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if log_interval is not None and epoch % log_interval == 0:\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            nsamples = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                nsamples += inputs.shape[0]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if scheduler is not None and phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            #nsamples = dataloaders[phase].dataset.data.shape[0]\n",
    "            epoch_loss = running_loss / nsamples\n",
    "            epoch_acc = running_corrects.double() / nsamples\n",
    "\n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            if log_interval is not None and epoch % log_interval == 0:\n",
    "                print('{} Loss: {:.4f} Acc: {:.2f}%'.format(\n",
    "                    phase, epoch_loss, 100 * epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if log_interval is not None and epoch % log_interval == 0:\n",
    "            print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(100 * best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, losses, accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN models\n",
    "\n",
    "### LeNet-5\n",
    "\n",
    "Here we implement LeNet-5 with relu activation. Sources:\n",
    "[(1)](https://github.com/bollakarthikeya/LeNet-5-PyTorch/blob/master/lenet5_cpu.py),\n",
    "[(2)](https://www.kaggle.com/usingtc/lenet-with-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    layers: (nb channels in input layer, \n",
    "             nb channels in 1rst conv,\n",
    "             nb channels in 2nd conv,\n",
    "             nb neurons for 1rst FC: TO BE TUNED,\n",
    "             nb neurons for 2nd FC,\n",
    "             nb neurons for 3rd FC,\n",
    "             nb neurons output FC TO BE TUNED)\n",
    "    \"\"\"\n",
    "    def __init__(self, layers = (1, 6, 16, 1024, 120, 84, 10), debug=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.debug = debug\n",
    "        self.conv1 = nn.Conv2d(layers[0], layers[1], 5, padding=2) \n",
    "        self.conv2 = nn.Conv2d(layers[1], layers[2], 5)\n",
    "        self.fc1   = nn.Linear(layers[3], layers[4])\n",
    "        self.fc2   = nn.Linear(layers[4], layers[5])\n",
    "        self.fc3   = nn.Linear(layers[5], layers[6])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # same shape / 2\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # -4 / 2\n",
    "        if self.debug:\n",
    "            print(\"### DEBUG: Shape of last convnet=\", x.shape[1:], \". FC size=\", np.prod(x.shape[1:]))\n",
    "        x = x.view(-1, self.layers[3])            \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGNet like: conv-relu blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network (LeNet-5)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MiniVGGNet(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self, layers=(1, 16, 32, 1024, 120, 84, 10), debug=False):   \n",
    "        super(MiniVGGNet, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.debug = debug\n",
    "\n",
    "        # Conv block 1\n",
    "        self.conv11 = nn.Conv2d(in_channels=layers[0], out_channels=layers[1], kernel_size=3,\n",
    "                                stride=1, padding=0, bias=True)\n",
    "        self.conv12 = nn.Conv2d(in_channels=layers[1], out_channels=layers[1], kernel_size=3,\n",
    "                                stride=1, padding=0, bias=True)\n",
    "\n",
    "        # Conv block 2\n",
    "        self.conv21 = nn.Conv2d(in_channels=layers[1], out_channels=layers[2], kernel_size=3,\n",
    "                                stride=1, padding=0, bias=True)\n",
    "        self.conv22 = nn.Conv2d(in_channels=layers[2], out_channels=layers[2], kernel_size=3,\n",
    "                                stride=1, padding=1, bias=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1   = nn.Linear(layers[3], layers[4])\n",
    "        self.fc2   = nn.Linear(layers[4], layers[5])\n",
    "        self.fc3   = nn.Linear(layers[5], layers[6])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv22(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "    \n",
    "        if self.debug:\n",
    "            print(\"### DEBUG: Shape of last convnet=\", x.shape[1:], \". FC size=\", np.prod(x.shape[1:]))\n",
    "        x = x.view(-1, self.layers[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-like Model:\n",
    "\n",
    "Stack multiple resnet blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# An implementation of https://arxiv.org/pdf/1512.03385.pdf                    #\n",
    "# See section 4.2 for the model architecture on CIFAR-10                       #\n",
    "# Some part of the code was referenced from below                              #\n",
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "import torch.nn as nn\n",
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "        #return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet9\n",
    "\n",
    "- [DAWNBench on cifar10](https://dawn.cs.stanford.edu/benchmark/index.html#cifar10)\n",
    "\n",
    "- [ResNet9: train to 94% CIFAR10 accuracy in 100 seconds](https://lambdalabs.com/blog/resnet9-train-to-94-cifar10-accuracy-in-100-seconds/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "WD = os.path.join(Path.home(), \"data\", \"pystatml\", \"dl_mnist_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "\n",
    "def load_mnist(batch_size_train, batch_size_test):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size_test, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, val_loader = load_mnist(64, 1000)\n",
    "\n",
    "dataloaders = dict(train=train_loader, val=val_loader)\n",
    "                   \n",
    "# Info about the dataset\n",
    "data_shape = dataloaders[\"train\"].dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(dataloaders[\"train\"].dataset.targets)\n",
    "print(\"Datasets shape\", {x: dataloaders[x].dataset.data.shape for x in ['train', 'val']})\n",
    "print(\"N input features\", D_in, \"N output\", D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dry run in debug mode to get the shape of the last convnet layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((1, 6, 16, 1, 120, 84, 10), debug=True)\n",
    "batch_idx, (data_example, target_example) = next(enumerate(train_loader))\n",
    "print(model)\n",
    "_ = model(data_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set First FC layer to 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((1, 6, 16, 400, 120, 84, 10)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=5, log_interval=2)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet(layers=(1, 16, 32, 1, 120, 84, 10), debug=True)\n",
    "\n",
    "print(model)\n",
    "_ = model(data_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set First FC layer to 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet((1, 16, 32, 800, 120, 84, 10)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=5, log_interval=2)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the size of training dataset\n",
    "\n",
    "Reduce the size of the training dataset by considering only `10` minibatche for size`16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = load_mnist(16, 1000)\n",
    "\n",
    "train_size = 10 * 16\n",
    "\n",
    "# Stratified sub-sampling\n",
    "targets = train_loader.dataset.targets.numpy()\n",
    "nclasses = len(set(targets))\n",
    "\n",
    "indices = np.concatenate([np.random.choice(np.where(targets == lab)[0], int(train_size / nclasses),replace=False) \n",
    "    for lab in set(targets)])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_loader.dataset, batch_size=16,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(indices))\n",
    "\n",
    "# Check train subsampling\n",
    "train_labels = np.concatenate([labels.numpy() for inputs, labels in train_loader])\n",
    "print(\"Train size=\", len(train_labels), \" Train label count=\", {lab:np.sum(train_labels == lab) for lab in set(train_labels)})\n",
    "print(\"Batch sizes=\", [inputs.size(0) for inputs, labels in train_loader])\n",
    "\n",
    "# Put together train and val\n",
    "dataloaders = dict(train=train_loader, val=val_loader)\n",
    "                   \n",
    "# Info about the dataset\n",
    "data_shape = dataloaders[\"train\"].dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(dataloaders[\"train\"].dataset.targets.unique())\n",
    "print(\"Datasets shape\", {x: dataloaders[x].dataset.data.shape for x in ['train', 'val']})\n",
    "print(\"N input features\", D_in, \"N output\", D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((1, 6, 16, 400, 120, 84, D_out)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=100, log_interval=20)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet((1, 16, 32, 800, 120, 84, 10)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=100, log_interval=20)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 dataset\n",
    "\n",
    "[Source Yunjey Choi](https://github.com/yunjey/pytorch-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "WD = os.path.join(Path.home(), \"data\", \"pystatml\", \"dl_cifar10_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Put together train and val\n",
    "dataloaders = dict(train=train_loader, val=val_loader)\n",
    "                   \n",
    "# Info about the dataset\n",
    "data_shape = dataloaders[\"train\"].dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(set(dataloaders[\"train\"].dataset.targets))\n",
    "print(\"Datasets shape:\", {x: dataloaders[x].dataset.data.shape for x in ['train', 'val']})\n",
    "print(\"N input features:\", D_in, \"N output:\", D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((3, 6, 16, 1, 120, 84, D_out), debug=True)\n",
    "batch_idx, (data_example, target_example) = next(enumerate(train_loader))\n",
    "print(model)\n",
    "_ = model(data_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 576 neurons to the first FC layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD with momentum `lr=0.001, momentum=0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((3, 6, 16, 576, 120, 84, D_out)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase learning rate and momentum `lr=0.01, momentum=0.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((3, 6, 16, 576, 120, 84, D_out)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptative learning rate: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5((3, 6, 16, 576, 120, 84, D_out)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet(layers=(3, 16, 32, 1, 120, 84, D_out), debug=True)\n",
    "print(model)\n",
    "_ = model(data_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 1152 neurons to the first FC layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD with large momentum and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet((3, 16, 32, 1152, 120, 84, D_out)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniVGGNet((3, 16, 32, 1152, 120, 84, D_out)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(ResidualBlock, [2, 2, 2], num_classes=D_out).to(device) # 195738 parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders,\n",
    "                       num_epochs=25, log_interval=5)\n",
    "\n",
    "_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
