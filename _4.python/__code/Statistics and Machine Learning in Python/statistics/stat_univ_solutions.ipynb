{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate statistics solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator of main statistical measures\n",
    "\n",
    "- Generate 2 random samples $x \\sim N(1.78, 0.1)$, $y \\sim N(1.66, 0.1)$ both of size 10.\n",
    "\n",
    "- Compute xbar $\\bar{x}, \\sigma_x, \\sigma_{xy}$ using only `np.sum()` operation.\n",
    "Explore `np.` module to find out the numpy functions that does the same\n",
    "computations and compare them (using `assert`) with your previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One sample t-test\n",
    "\n",
    "- Given the following samples, test whether its true mean is 1.75. Warning, when computing the std or the variance set ddof=1. The default value 0, leads to the biased estimator of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "np.random.seed(seed=42)  # make the example reproducible\n",
    "\n",
    "n = 10\n",
    "x = np.random.normal(loc=1.76, scale=.1, size=n)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the t-value (tval)\n",
    "\n",
    "- Plot the T(n-1) distribution for 100 tvalues values within [0, 10]. Draw P(T(n-1)>tval)\n",
    "  ie. color the surface defined by x values larger than tval below the T(n-1).\n",
    "  Using the code.\n",
    "\n",
    "- Compute the p-value: P(T(n-1)>tval).\n",
    "\n",
    "- The p-value is one-sided: a two-sided test would test P(T(n-1) > tval)\n",
    "  and P(T(n-1) < -tval). What would be the two sided p-value ?\n",
    "\n",
    "- Compare the two-sided p-value with the one obtained by stats.ttest_1samp\n",
    "using `assert np.allclose(arr1, arr2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xbar, s, xmu, = np.mean(x), np.std(x, ddof=1), 1.75\n",
    "\n",
    "tval = (xbar - xmu) / (s / np.sqrt(n))\n",
    "\n",
    "# Survival function (1 - `cdf`)\n",
    "pval = stats.t.sf(tval, n - 1)\n",
    "\n",
    "pval2sided = pval * 2\n",
    "# do it with sicpy\n",
    "assert np.allclose((tval, pval2sided), stats.ttest_1samp(x, xmu))\n",
    "\n",
    "print(tval, pval)\n",
    "\n",
    "tvalues = np.linspace(-10, 10, 100)\n",
    "plt.plot(tvalues, stats.t.pdf(tvalues, n-1), 'b-', label=\"T(n-1)\")\n",
    "upper_tval_tvalues = tvalues[tvalues > tval]\n",
    "plt.fill_between(upper_tval_tvalues, 0, stats.t.pdf(upper_tval_tvalues, n-1), alpha=.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression and correlation (application)\n",
    "\n",
    "Load the dataset: birthwt Risk Factors Associated with Low Infant Birth Weight at\n",
    "`ftp://ftp.cea.fr/pub/unati/people/educhesnay/pystatml/datasets/birthwt.csv`\n",
    "\n",
    "1. Test the association of mother’s age and birth weight using the correlation test and linear regeression.\n",
    "\n",
    "2. Test the association of mother’s weight and birth weight using the correlation test and linear regeression.\n",
    "\n",
    "3. Produce two scatter plot of: (i) age by birth weight; (ii) mother’s weight by birth weight.\n",
    "\n",
    "Conclusion ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "url = 'https://github.com/duchesnay/pystatsml/raw/master/datasets/birthwt.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.pearsonr(df.age, df.bwt))\n",
    "print(stats.pearsonr(df.bwt, df.lwt))\n",
    "\n",
    "plt.plot(df.bwt, df.lwt, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression (maths)\n",
    "\n",
    "Considering the salary and the experience of the salary table.\n",
    "\n",
    "https://github.com/duchesnay/pystatsml/raw/master/datasets/salary_table.csv\n",
    "\n",
    "\n",
    "Compute:\n",
    "\n",
    "- Estimate the model paramters $\\beta, \\beta_0$ using scipy `stats.linregress(x,y)` \n",
    "\n",
    "- Compute the predicted values $\\hat{y}$\n",
    "\n",
    "Compute:\n",
    "\n",
    "- $\\bar{y}$: `y_mu`\n",
    "\n",
    "- $SS_\\text{tot}$: `ss_tot`\n",
    "\n",
    "- $SS_\\text{reg}$: `ss_reg`\n",
    "\n",
    "- $SS_\\text{res}$: `ss_res`\n",
    "\n",
    "- Check partition of variance formula based on sum of squares by using `assert np.allclose(val1, val2, atol=1e-05)`\n",
    "\n",
    "- Compute $R^2$ and compare it with the `r_value` above\n",
    "\n",
    "- Compute the $F$ score\n",
    "\n",
    "- Compute the $p$-value:\n",
    " *  Plot the $F(1, n)$ distribution for 100 $f$ values within $[10, 25]$. Draw $P(F(1, n) > F)$, i.e. color the surface defined by the $x$ values larger than $F$ below the $F(1, n)$.\n",
    "\n",
    " * $P(F(1, n) > F)$ is the $p$-value, compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "url = 'https://github.com/duchesnay/pystatsml/raw/master/datasets/salary_table.csv'\n",
    "salary = pd.read_csv(url)\n",
    "\n",
    "y, x = salary.salary, salary.experience\n",
    "\n",
    "# Model parameters\n",
    "beta, beta0, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "print(\"y=%f x + %f  r:%f, r-squared:%f, p-value:%f, std_err:%f\" % (beta, beta0, r_value, r_value**2, p_value, std_err))\n",
    "\n",
    "# plotting the line\n",
    "yhat = beta * x  +  beta0 # regression line\n",
    "plt.plot(x, yhat, 'r-', x, y,'o')\n",
    "plt.xlabel('Experience (years)')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "## $\\bar{y}$ `y_mu`\n",
    "\n",
    "y_mu = np.mean(y)\n",
    "\n",
    "## $SS_\\text{tot}$: `ss_tot`\n",
    "\n",
    "ss_tot = np.sum((y - y_mu) ** 2)\n",
    "\n",
    "## $SS_\\text{reg}$: `ss_reg`\n",
    "ss_reg = np.sum((yhat - y_mu) ** 2)\n",
    "\n",
    "## $SS_\\text{res}$: `ss_res`\n",
    "ss_res = np.sum((y - yhat) ** 2)\n",
    "\n",
    "## Check partition of variance formula based on SS using `assert np.allclose(val1, val2, atol=1e-05)`\n",
    "assert np.allclose(ss_tot - (ss_reg + ss_res), 0, atol=1e-05)\n",
    "\n",
    "## What np.allclose does ?\n",
    "\n",
    "## What assert does\n",
    "\n",
    "## What is it worth for ?\n",
    "\n",
    "## Compute $R^2$ and compare with `r_value` above\n",
    "r2 = ss_reg / ss_tot\n",
    "\n",
    "assert np.sqrt(r2) == r_value\n",
    "\n",
    "## Compute F score\n",
    "n = y.size\n",
    "fval = ss_reg / (ss_res / (n - 2))\n",
    "\n",
    "\n",
    "# Compute the p-value:\n",
    "#  * Plot the F(1,n) distribution for 100 f values within [10, 25]. Draw P(F(1,n)>F) ie. color the surface defined by x values larger than F below the F(1,n).\n",
    "#  * P(F(1,n)>F) is the p-value, compute it.\n",
    "\n",
    "fvalues = np.linspace(10, 25, 100)\n",
    "\n",
    "plt.plot(fvalues, stats.f.pdf(fvalues, 1, 30), 'b-', label=\"F(1, 30)\")\n",
    "\n",
    "upper_fval_fvalues = fvalues[fvalues > fval]\n",
    "plt.fill_between(upper_fval_fvalues, 0, stats.f.pdf(upper_fval_fvalues, 1, 30), alpha=.8)\n",
    "\n",
    "# pdf(x, df1, df2): Probability density function at x of the given RV.\n",
    "plt.legend()\n",
    "\n",
    "# Survival function (1 - `cdf`)\n",
    "pval = stats.f.sf(fval, 1, n - 2)\n",
    "\n",
    "\n",
    "## With statmodels\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('salary ~ experience', salary)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "## With sklearn\n",
    "\n",
    "import sklearn.feature_selection\n",
    "#sklearn.feature_selection.f_regression??\n",
    "sklearn.feature_selection.f_regression(x.reshape((n, 1)), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple regression\n",
    "\n",
    "Considering the simulated data used below: \n",
    "\n",
    "1. What are the dimensions of $\\mathrm{pinv}(X)$?\n",
    "\n",
    "2. Compute the MSE between the predicted values and the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "np.random.seed(seed=42)  # make the example reproducible\n",
    "\n",
    "# Dataset\n",
    "N, P = 50, 4\n",
    "X = np.random.normal(size= N * P).reshape((N, P))\n",
    "## Our model needs an intercept so we add a column of 1s:\n",
    "X[:, 0] = 1\n",
    "print(X[:5, :])\n",
    "\n",
    "betastar = np.array([10, 1., .5, 0.1])\n",
    "e = np.random.normal(size=N)\n",
    "y = np.dot(X, betastar) + e\n",
    "\n",
    "# Estimate the parameters\n",
    "Xpinv = scipy.linalg.pinv2(X)\n",
    "betahat = np.dot(Xpinv, y)\n",
    "print(\"Estimated beta:\\n\", betahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the dimensions of pinv$(X)$ ?\n",
    "\n",
    "# ((P x N) (N x P))^1 (P x N)\n",
    "# P x N\n",
    "\n",
    "print(Xpinv.shape)\n",
    "\n",
    "#2. Compute the MSE between the predicted values and the true values.\n",
    "\n",
    "\n",
    "yhat = np.dot(X, betahat)\n",
    "\n",
    "mse = np.sum((y - yhat) ** 2) / N\n",
    "print(\"MSE =\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample t-test (maths)\n",
    "\n",
    "Given the following two sample, test whether their means are equals.\n",
    "\n",
    "```\n",
    "height = np.array([\n",
    "    1.83,  1.83,  1.73,  1.82,  1.83,  1.73,  1.99, 1.85,  1.68,  1.87,\n",
    "    1.66,  1.71,  1.73,  1.64,  1.70,  1.60,  1.79,  1.73,  1.62,  1.77])\n",
    "grp = np.array([\"M\"] * 10 + [\"F\"] * 10)\n",
    "```\n",
    "\n",
    "- Compute the means/std-dev per groups.\n",
    "\n",
    "- Compute the $t$-value (standard two sample t-test with equal variances).\n",
    "\n",
    "- Compute the $p$-value.\n",
    "\n",
    "- The $p$-value is one-sided: a two-sided test would test `P(T > tval)`\n",
    "  and `P(T < -tval)`. What would the two sided $p$-value be?\n",
    "\n",
    "- Compare the two-sided $p$-value with the one obtained by `stats.ttest_ind` using `assert np.allclose(arr1, arr2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = np.array([ 1.83,  1.83,  1.73,  1.82,  1.83,  1.73,  1.99,  1.85,  1.68,  1.87,\n",
    "                    1.66,  1.71,  1.73,  1.64,  1.70,  1.60,  1.79,  1.73,  1.62,  1.77])\n",
    "grp = np.array([\"M\"] * 10 + [\"F\"] * 10)\n",
    "\n",
    "x = height[grp==\"M\"]\n",
    "y = height[grp==\"F\"]\n",
    "\n",
    "nx, ny = len(x), len(y)\n",
    "\n",
    "# mean/std\n",
    "xbar, ybar = np.mean(x), np.mean(y)\n",
    "xvar, yvar = np.var(x, ddof=1), np.var(y, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equal variances t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se\n",
    "sigma = np.sqrt((xvar * (nx - 1) + yvar * (ny - 1)) / (nx + ny - 2))\n",
    "se = sigma * np.sqrt(1 / nx + 1 / ny)\n",
    "\n",
    "# tval\n",
    "tval = (xbar - ybar) / se\n",
    "\n",
    "print(\"tval=%.2f, pval=%.4f\" % (tval, pval))\n",
    "\n",
    "# df\n",
    "df = nx + ny - 2\n",
    "pval = stats.t.sf(tval, df)\n",
    "pval2sided = pval * 2\n",
    "\n",
    "# With scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "assert np.allclose((tval, pval2sided),\n",
    "                   stats.ttest_ind(x, y, equal_var=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unequal variance (Welch) t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = np.sqrt(xvar / nx + yvar / ny)\n",
    "\n",
    "tval = (xbar - ybar) / se\n",
    "\n",
    "# Use the following function to approximate the df needed for the p-value\n",
    "\n",
    "def unequal_var_ttest_df(v1, n1, v2, n2):\n",
    "    vn1 = v1 / n1\n",
    "    vn2 = v2 / n2\n",
    "    df = (vn1 + vn2)**2 / (vn1**2 / (n1 - 1) + vn2**2 / (n2 - 1))\n",
    "    return df\n",
    "\n",
    "df = unequal_var_ttest_df(xvar, nx, yvar, ny)\n",
    "\n",
    "# Compute the p-value.\n",
    "#\n",
    "# The p-value is one-sided: a two-sided test would test P(T > tval)\n",
    "# and P(T < -tval). What would be the two sided p-value ?\n",
    "\n",
    "pval = stats.t.sf(tval, df)\n",
    "pval2sided = pval * 2\n",
    "\n",
    "# Compare the two-sided p-value with the one obtained by `stats.ttest_ind` using `assert np.allclose(arr1, arr2)`\n",
    "\n",
    "# do it with scipy\n",
    "assert np.allclose((tval, pval2sided), stats.ttest_ind(x, y, equal_var=False))\n",
    "\n",
    "\n",
    "# Plot of the two sample t-test\n",
    "\n",
    "xjitter = np.random.normal(loc=-1, size=len(x), scale=.01)\n",
    "yjitter = np.random.normal(loc=+1, size=len(y), scale=.01)\n",
    "plt.plot(xjitter, x, \"ob\", alpha=.5)\n",
    "plt.plot(yjitter, y, \"ob\", alpha=.5)\n",
    "plt.plot([-1, +1], [xbar, ybar], \"or\", markersize=15)\n",
    "\n",
    "#left, left + width, bottom, bottom + height\n",
    "#plt.bar(left=0, height=se, width=0.1, bottom=ybar-se/2)\n",
    "## effect size error bar\n",
    "plt.errorbar(-.1, ybar + (xbar - ybar) / 2, yerr=(xbar - ybar) / 2,\n",
    "             elinewidth=3, capsize=5, markeredgewidth=3,\n",
    "             color='r')\n",
    "\n",
    "plt.errorbar([-.8, .8], [xbar, ybar], yerr=np.sqrt([xvar, yvar]) / 2,\n",
    "             elinewidth=3, capsize=5, markeredgewidth=3,\n",
    "             color='b')\n",
    "\n",
    "plt.errorbar(.1, ybar, yerr=se / 2,\n",
    "             elinewidth=3, capsize=5, markeredgewidth=3,\n",
    "             color='b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample t-test and random permutation\n",
    "\n",
    "Generate 100 samples following the model:\n",
    "$$\n",
    "y = g + \\varepsilon\n",
    "$$\n",
    "Where the noise $\\varepsilon \\sim N(1, 1)$ and $g \\in \\{0, 1\\}$ is a group indicator variable with 50 ones and 50 zeros.\n",
    "\n",
    "- Write a function `tstat(y, g)` that compute the two samples t-test of y splited in two groups defined by g.\n",
    "\n",
    "- Sample the t-statistic distribution under the null hypothesis using random permutations.\n",
    "\n",
    "- Assess the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Model data\n",
    "eps = np.random.normal(loc=0, scale=1, size=100)\n",
    "g = np.concatenate([np.zeros(50), np.ones(50)])\n",
    "\n",
    "y = g + eps\n",
    "\n",
    "def tstat(y, g):\n",
    "    ys = [y[g == l] for l in np.unique(g)]\n",
    "    means = [np.mean(vals) for vals in ys]\n",
    "    sse = [np.sum((vals - means[i]) ** 2) for i, vals in enumerate(ys)]\n",
    "    counts = [len(vals) for vals in ys]\n",
    "    s = np.sqrt(np.sum(sse) / (len(y) - 2))\n",
    "    tval = (means[1] - means[0]) / (s * np.sqrt(1 / counts[0] + 1 / counts[0]))\n",
    "    return(tval)\n",
    "\n",
    "# Permutation: simulate the null hypothesis\n",
    "nperm = 10000\n",
    "perms = np.zeros(nperm + 1)\n",
    "perms[0] = tstat(y, g)\n",
    "\n",
    "for i in range(1, nperm):\n",
    "    perms[i] = tstat(y, np.random.permutation(g))\n",
    "\n",
    "pval = np.sum(perms >= perms[0]) / len(perms)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two sample t-test (application)\n",
    "\n",
    "Risk Factors Associated with Low Infant Birth Weight:\n",
    "\n",
    "`https://github.com/duchesnay/pystatsml/raw/master/datasets/birthwt.csv`\n",
    "\n",
    "\n",
    "1. Explore the data\n",
    "\n",
    "2. Recode smoke factor\n",
    "\n",
    "3. Compute the means/std-dev per groups.\n",
    "\n",
    "4. Plot birth weight by smoking (box plot, violin plot or histogram)\n",
    "\n",
    "5. Test the effect of smoking on birth weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/duchesnay/pystatsml/raw/master/datasets/birthwt.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.smoke.describe()\n",
    "\n",
    "df.smoke = df.smoke.map({1:\"y\", 0:\"n\"})\n",
    "\n",
    "df.smoke.describe()\n",
    "\n",
    "print(df[['smoke' , 'bwt']] .groupby(\"smoke\").mean())\n",
    "print(df[['smoke' , 'bwt']] .groupby(\"smoke\").std())\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.violinplot(x=\"smoke\", y=\"bwt\", data=df, inner=None)\n",
    "ax = sns.swarmplot(x=\"smoke\", y=\"bwt\", data=df,\n",
    "                    color=\"white\", edgecolor=\"gray\")\n",
    "\n",
    "import scipy.stats as stats\n",
    "print(stats.ttest_ind(df.bwt[df.smoke == \"y\"],\n",
    "                      df.bwt[df.smoke == \"n\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate associations (developpement) \n",
    "\n",
    "Write a function `univar_stat(df, target, variables)` that computes the parametric statistics and $p$-values between the `target` variable (provided as as string) and all `variables` (provided as a list of string) of the pandas DataFrame `df`. The target is a quantitative variable but variables may be quantitative or qualitative. The function returns a DataFrame with four columns: `variable`, `test`, `value`, `p_value`.\n",
    "\n",
    "Apply it to the salary dataset available at https://github.com/duchesnay/pystatsml/raw/master/datasets/salary_table.csv, with target being `S`: salaries for IT staff in a corporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple comparisons\n",
    "\n",
    "This exercise has 2 goals: apply you knowledge of statistics using vectorized numpy operations.\n",
    "Given the dataset provided for multiple comparisons, compute the two-sample $t$-test (assuming equal variance) for each (column) feature of the `Y` array given the two groups defined by `grp` variable. You should return two vectors of size `n_features`: one for the $t$-values and one for the $p$-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA\n",
    "\n",
    "Perform an ANOVA dataset described bellow\n",
    "\n",
    "- Compute between and within variances\n",
    "- Compute $F$-value: `fval`\n",
    "- Compare the $p$-value with the one obtained by `stats.f_oneway` using `assert np.allclose(arr1, arr2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "mu_k = np.array([1, 2, 3])    # means of 3 samples\n",
    "sd_k = np.array([1, 1, 1])    # sd of 3 samples\n",
    "n_k = np.array([10, 20, 30])  # sizes of 3 samples\n",
    "grp = [0, 1, 2]               # group labels\n",
    "n = np.sum(n_k)\n",
    "label = np.hstack([[k] * n_k[k] for k in [0, 1, 2]])\n",
    "\n",
    "y = np.zeros(n)\n",
    "for k in grp:\n",
    "    y[label == k] = np.random.normal(mu_k[k], sd_k[k], n_k[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# estimate parameters\n",
    "ybar_k = np.zeros(3)\n",
    "\n",
    "ybar = y.mean()\n",
    "for k in grp:\n",
    "    ybar_k[k] = np.mean(y[label == k])\n",
    "\n",
    "\n",
    "betweenvar = np.sum([n_k[k] * (ybar_k[k] - ybar) ** 2 for k in grp]) / (len(grp) - 1)\n",
    "withinvar = np.sum([np.sum((y[label==k] - ybar_k[k]) ** 2) for k in grp]) / (n - len(grp))\n",
    "\n",
    "fval = betweenvar / withinvar\n",
    "# Survival function (1 - `cdf`)\n",
    "pval = stats.f.sf(fval, (len(grp) - 1), n - len(grp))\n",
    "\n",
    "# Compute with scipy\n",
    "fval, pval = stats.f_oneway(y[label == 0], y[label == 1], y[label == 2])\n",
    "\n",
    "\n",
    "assert np.allclose((fval, pval),\n",
    "                   stats.f_oneway(y[label == 0], y[label == 1], y[label == 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
