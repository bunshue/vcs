{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c548abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter max words per sentence for summary: 14\n",
      "Enter number of sentences for summary: 15\n",
      "\n",
      "SUMMARY:\n",
      "From every mountainside, let freedom ring.\n",
      "Let freedom ring from Lookout Mountain in Tennessee!\n",
      "Let freedom ring from every hill and molehill in Mississippi.\n",
      "Let freedom ring from the curvaceous slopes of California!\n",
      "Let freedom ring from the snow capped Rockies of Colorado!\n",
      "But one hundred years later the Negro is still not free.\n",
      "From the mighty mountains of New York, let freedom ring.\n",
      "From the prodigious hilltops of New Hampshire, let freedom ring.\n",
      "And I say to you today my friends, let freedom ring.\n",
      "I have a dream today.\n",
      "It is a dream deeply rooted in the American dream.\n",
      "Free at last!\n",
      "Thank God almighty, we're free at last!\"\n",
      "We must not allow our creative protest to degenerate into physical violence.\n",
      "This is the faith that I go back to the mount with.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def main():\n",
    "    # 進行網路爬蟲\n",
    "    url = 'http://www.analytictech.com/mb021/mlk.htm'\n",
    "    page = requests.get(url)\n",
    "    page.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(page.text, 'html.parser')\n",
    "    p_elems = [element.text for element in soup.find_all('p')]\n",
    "\n",
    "    speech = ' '.join(p_elems)  # 將段落內容串在一起\n",
    "\n",
    "    # 修正錯字、刪除多餘的空格、移除非字母內容\n",
    "    speech = speech.replace(')mowing', 'knowing')\n",
    "    speech = re.sub('\\s+', ' ', speech) \n",
    "    speech_edit = re.sub('[^a-zA-Z]', ' ', speech)\n",
    "    speech_edit = re.sub('\\s+', ' ', speech_edit)\n",
    "\n",
    "    # 請使用者輸入要包括在摘要中的句子數和每個句子的字數上限\n",
    "    while True:\n",
    "        max_words = input(\"Enter max words per sentence for summary: \")\n",
    "        num_sents = input(\"Enter number of sentences for summary: \")\n",
    "        if max_words.isdigit() and num_sents.isdigit():\n",
    "            break\n",
    "        else:\n",
    "            print(\"\\nInput must be in whole numbers.\\n\")\n",
    "                      \n",
    "    # 清理文字，並為句子評分\n",
    "    speech_edit_no_stop = remove_stop_words(speech_edit)\n",
    "    word_freq = get_word_freq(speech_edit_no_stop)\n",
    "    sent_scores = score_sentences(speech, word_freq, max_words)\n",
    "\n",
    "    # 產生摘要\n",
    "    counts = Counter(sent_scores)\n",
    "    summary = counts.most_common(int(num_sents))\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    for i in summary:\n",
    "        print(i[0])\n",
    "\n",
    "def remove_stop_words(speech_edit):\n",
    "    \"\"\"移除停用詞並傳回結果字串\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    speech_edit_no_stop = ''\n",
    "    for word in nltk.word_tokenize(speech_edit):\n",
    "        if word.lower() not in stop_words:\n",
    "            speech_edit_no_stop += word + ' '  \n",
    "    return speech_edit_no_stop\n",
    "\n",
    "def get_word_freq(speech_edit_no_stop):\n",
    "    \"\"\"以字典形式傳回字串中單字出現的頻率\"\"\"\n",
    "    word_freq = nltk.FreqDist(nltk.word_tokenize(speech_edit_no_stop.lower()))\n",
    "    return word_freq\n",
    "\n",
    "def score_sentences(speech, word_freq, max_words):\n",
    "    \"\"\"以字典形式傳回根據單字頻率算出的句子分數\"\"\"\n",
    "    sent_scores = dict()\n",
    "    sentences = nltk.sent_tokenize(speech)\n",
    "    for sent in sentences:\n",
    "        sent_scores[sent] = 0\n",
    "        words = nltk.word_tokenize(sent.lower())\n",
    "        sent_word_count = len(words)\n",
    "        if sent_word_count <= int(max_words):\n",
    "            for word in words:\n",
    "                if word in word_freq.keys():\n",
    "                    sent_scores[sent] += word_freq[word]\n",
    "            sent_scores[sent] = sent_scores[sent] / sent_word_count\n",
    "    return sent_scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
