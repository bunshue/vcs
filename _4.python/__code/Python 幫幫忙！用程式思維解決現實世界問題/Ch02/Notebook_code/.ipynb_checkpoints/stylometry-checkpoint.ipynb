{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8c2269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mr. Sherlock Holmes, who was usually very late in the mornings, save\n",
      "upon those not infrequent occasions when he was up all night, was seated\n",
      "at the breakfast table. I stood upon the hearth-rug and picked up the\n",
      "stick which our visitor had left behind him the night before. It was a\n",
      "fine, thick piec\n",
      "\n",
      "Number of words for doyle = 58387\n",
      "\n",
      "\n",
      "Number of words for wells = 59469\n",
      "\n",
      "\n",
      "Number of words for unknown = 74961\n",
      "\n",
      "length shortest corpus = 58387\n",
      "\n",
      "Using matplotlib backend: Qt5Agg\n",
      "Chi-squared for doyle = 4744.4\n",
      "Chi-squared for wells = 6856.3\n",
      "Most-likely author by vocabulary is doyle\n",
      "\n",
      "Jaccard Similarity for doyle = 0.34847801578354004\n",
      "Jaccard Similarity for wells = 0.30786921307869214\n",
      "Most-likely author by similarity is doyle\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LINES = ['-', ':', '--']  # 設定圖表中的線條樣式\n",
    "\n",
    "def main():\n",
    "    # 載入文字檔到作者的字典\n",
    "    strings_by_author = dict()\n",
    "    strings_by_author['doyle'] = text_to_string('hound.txt')\n",
    "    strings_by_author['wells'] = text_to_string('war.txt')\n",
    "    strings_by_author['unknown'] = text_to_string('lost.txt')\n",
    "\n",
    "    # 檢查文章內容是否已正常載入\n",
    "    print(strings_by_author['doyle'][:300])\n",
    "\n",
    "    # 進行斷詞和文體分析\n",
    "    words_by_author = make_word_dict(strings_by_author)\n",
    "    len_shortest_corpus = find_shortest_corpus(words_by_author)\n",
    "    \n",
    "    word_length_test(words_by_author, len_shortest_corpus)\n",
    "    stopwords_test(words_by_author, len_shortest_corpus)    \n",
    "    parts_of_speech_test(words_by_author, len_shortest_corpus)\n",
    "    vocab_test(words_by_author)\n",
    "    jaccard_test(words_by_author, len_shortest_corpus) \n",
    "\n",
    "def text_to_string(filename):\n",
    "    \"\"\"讀取文字檔並以字串形式傳回\"\"\"\n",
    "    with open(filename, encoding='utf-8', errors='ignore') as infile:\n",
    "        return infile.read()\n",
    "\n",
    "def make_word_dict(strings_by_author):\n",
    "    \"\"\"傳回將作品斷詞後的字典\"\"\"\n",
    "    words_by_author = dict()\n",
    "    for author in strings_by_author:\n",
    "        tokens = nltk.word_tokenize(strings_by_author[author])\n",
    "        words_by_author[author] = ([token.lower() for token in tokens\n",
    "                                    if token.isalpha()])\n",
    "    return words_by_author\n",
    "\n",
    "def find_shortest_corpus(words_by_author):\n",
    "    \"\"\"傳回最短語料庫的長度\"\"\"\n",
    "    word_count = []\n",
    "    for author in words_by_author:\n",
    "        word_count.append(len(words_by_author[author]))\n",
    "        print('\\nNumber of words for {} = {}\\n'.\n",
    "              format(author, len(words_by_author[author])))\n",
    "    len_shortest_corpus = min(word_count)\n",
    "    print('length shortest corpus = {}\\n'.format(len_shortest_corpus))        \n",
    "    return len_shortest_corpus    \n",
    "\n",
    "def word_length_test(words_by_author, len_shortest_corpus):\n",
    "    #下一行程式若在 Anaconda 環境執行請取消註解 \n",
    "    %matplotlib\n",
    "    \"\"\"畫出各作者使用的詞彙長度圖，所有作品都截斷成與最短語料庫相同長度\"\"\"\n",
    "    by_author_length_freq_dist = dict()\n",
    "    plt.figure(1)    \n",
    "    plt.ion()\n",
    "    for i, author in enumerate(words_by_author):\n",
    "        word_lengths = [len(word) for word in words_by_author[author]\n",
    "                        [:len_shortest_corpus]]\n",
    "        by_author_length_freq_dist[author] = nltk.FreqDist(word_lengths)\n",
    "        by_author_length_freq_dist[author].plot(15,\n",
    "                                                linestyle=LINES[i],\n",
    "                                                label=author,\n",
    "                                                title='Word Length')\n",
    "    plt.legend()\n",
    "    # plt.show()  # 要在程式編輯時看到圖案，可取消註解\n",
    "\n",
    "def stopwords_test(words_by_author, len_shortest_corpus):\n",
    "    \"\"\"畫出每位作者使用停用詞的頻率，所有作品都截斷成與最短語料庫的相同長度\"\"\"\n",
    "    stopwords_by_author_freq_dist = dict()\n",
    "    plt.figure(2) \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #print('Number of stopwords = {}\\n'.format(len(stop_words)))\n",
    "    #print('Stopwords = {}\\n'.format(stop_words))\n",
    "    for i, author in enumerate(words_by_author):\n",
    "        stopwords_by_author = [word for word in words_by_author[author]\n",
    "                               [:len_shortest_corpus]\n",
    "                               if word in stop_words]    \n",
    "        stopwords_by_author_freq_dist[author] = nltk.FreqDist(\n",
    "            stopwords_by_author)    \n",
    "        stopwords_by_author_freq_dist[author].plot(50,\n",
    "                                                   label=author,\n",
    "                                                   linestyle=LINES[i],\n",
    "                                                   title=\n",
    "                                                   '50 Most Common Stopwords')\n",
    "    plt.legend()\n",
    "    # plt.show()  # 要在程式編輯時看到圖案，可取消註解\n",
    "\n",
    "def parts_of_speech_test(words_by_author, len_shortest_corpus):\n",
    "    \"\"\"畫出作者使用名詞、動詞、副詞等不同詞性的圖形\"\"\"\n",
    "    by_author_pos_freq_dist = dict()\n",
    "    plt.figure(3)\n",
    "    for i, author in enumerate(words_by_author):\n",
    "        pos_by_author = [pos[1] for pos in nltk.pos_tag(\n",
    "            words_by_author[author][:len_shortest_corpus])] \n",
    "        by_author_pos_freq_dist[author] = nltk.FreqDist(pos_by_author)\n",
    "        by_author_pos_freq_dist[author].plot(35,\n",
    "                                             label=author,\n",
    "                                             linestyle=LINES[i],\n",
    "                                             title='Part of Speech')\n",
    "    plt.legend()\n",
    "    plt.show() # Windows PowerShell的使用者需使用 plt.show(block=True) 防止圖案關閉\n",
    "                       \n",
    "def vocab_test(words_by_author):\n",
    "    \"\"\"用卡方統計來比較作者的詞彙量\"\"\"\n",
    "    chisquared_by_author = dict()\n",
    "    for author in words_by_author:\n",
    "        if author != 'unknown': \n",
    "            # 合併作者的語料庫與 unknown 的語料庫，並取得 1000 個最常用的詞彙\n",
    "            combined_corpus = (words_by_author[author] +\n",
    "                               words_by_author['unknown'])\n",
    "            author_proportion = (len(words_by_author[author])/\n",
    "                                 len(combined_corpus))\n",
    "            combined_freq_dist = nltk.FreqDist(combined_corpus)\n",
    "            most_common_words = list(combined_freq_dist.most_common(1000))\n",
    "            chisquared = 0\n",
    "\n",
    "            # 取得觀察到的計數值和計算預期的計數值\n",
    "            for word, combined_count in most_common_words:\n",
    "                observed_count_author = words_by_author[author].count(word)\n",
    "                expected_count_author = combined_count * author_proportion\n",
    "                chisquared += ((observed_count_author -\n",
    "                                expected_count_author)**2 /\n",
    "                               expected_count_author)\n",
    "                chisquared_by_author[author] = chisquared    \n",
    "            print('Chi-squared for {} = {:.1f}'.\n",
    "                  format(author, chisquared))\n",
    "            \n",
    "\n",
    "    most_likely_author = min(chisquared_by_author, \n",
    "                             key=chisquared_by_author.get)\n",
    "    print('Most-likely author by vocabulary is {}\\n'.\n",
    "          format(most_likely_author))\n",
    "\n",
    "def jaccard_test(words_by_author, len_shortest_corpus):\n",
    "    \"\"\"計算已知作者語料庫對 unknown 語料庫的雅卡爾指數\"\"\"\n",
    "    jaccard_by_author = dict()\n",
    "    unique_words_unknown = set(words_by_author['unknown']\n",
    "                               [:len_shortest_corpus])\n",
    "    authors = (author for author in words_by_author\n",
    "               if author != 'unknown')    \n",
    "    for author in authors:\n",
    "        unique_words_author = set(words_by_author[author]\n",
    "                                  [:len_shortest_corpus]) \n",
    "        shared_words = unique_words_author.intersection(\n",
    "            unique_words_unknown)\n",
    "        jaccard_sim = (float(len(shared_words))/ \n",
    "                       (len(unique_words_author) +\n",
    "                        len(unique_words_unknown) -\n",
    "                        len(shared_words)))\n",
    "        jaccard_by_author[author] = jaccard_sim\n",
    "        print('Jaccard Similarity for {} = {}'.format(author,\n",
    "                                                      jaccard_sim))\n",
    "        \n",
    "    most_likely_author = max(jaccard_by_author,\n",
    "                             key=jaccard_by_author.get)\n",
    "    print('Most-likely author by similarity is {}'.\n",
    "          format(most_likely_author))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12667f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
