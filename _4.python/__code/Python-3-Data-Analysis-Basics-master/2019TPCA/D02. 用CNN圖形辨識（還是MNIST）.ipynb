{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun 被譽為 Deep Learning 的三巨頭之一。他的 CNN (Convolutional Neural Networks) 是讓 Neural Network 重新受到重視的主因之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 初始準備\n",
    "\n",
    "基本上和之前是一樣的, 我們就不再說明。\n",
    "\n",
    "    %env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 讀入 MNIST 數據庫\n",
    "\n",
    "### 由 Keras 讀入 MNIST\n",
    "\n",
    "基本上和我們上次一樣, 這次因為 Keras 已偷偷把數據庫存在你的電腦, 所以會快很多!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入格式整理\n",
    "\n",
    "如果你還記得, 我們每筆輸入資料都是 28x28 的陣列, CNN 其實就是吃「圖」的, 所以基本上不用像之前把每筆資料拉平。「但。是。」平常的圖都有 R, G, B 三個 channels, 每個 channel 都是一個矩陣, 也就是一張圖可能是三個矩陣! 我們是灰階, 也就是只有一個 channel。但這件事也要明確的告訴 Keras。\n",
    "\n",
    "換句話說, 我們的輸入每筆資料型式要從 (28, 28) 換成 (28, 28, 1)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 要的是 (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認一下..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原來 28x28 矩陣..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffdc8335c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X,  cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出格式整理\n",
    "\n",
    "和上次一樣, 我們用標準 1-hot 方式處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train/255\n",
    "#x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 打造你的 CNN\n",
    "\n",
    "### 決定神經網路架構、讀入相關套件\n",
    "\n",
    "CNN 我們一樣要決定用幾層的 CNN, 然後是不是每次都要做 max-pooling。再來就是拉平、送入標準神經網路 (再度要決定幾層、幾個神經元)。\n",
    "\n",
    "我們上課的時候, 同學建議要做 3 次的 convolution + max-pooling, filter 大小都是 $5\\times 5$。\n",
    "\n",
    "* 做 <span style=\"color:red;\">3</span> 次 convolution, 每次都接 max-pooling\n",
    "* filter 大小都是 <span style=\"color:red;\">3x3</span>, max-pooling 都用 <span style=\"color:red;\">2x2</span> 為一小區塊\n",
    "\n",
    "CNN 一個小技巧是每層的 filters 數目是越來越多, 上課同學建議第一層 4 個, 因為要做三次, 所以我們 filters 數分別是 <span style=\"color:red;\">10, 20, 40</span>。做完 convolution 之後, 我們要拉平、再送入一個標準的神經網路。這個神經網路設計是這樣:\n",
    "\n",
    "* 只有 <span style=\"color:red;\">3</span> 個隱藏層, 使用 <span style=\"color:red;\"></span>:\n",
    "\n",
    "- layer 1: 5\n",
    "- layer 2: 8\n",
    "- layer 3: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建構我們的神經網路\n",
    "\n",
    "一開始一樣是打開個空白的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一個隱藏層一樣要告訴 Keras 我們輸入長什麼樣子。`padding` 設成 `same` 是每個 filter 會輸出原來 28x28 一樣大小的矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(10, (3, 3), padding='same', input_shape=(28, 28, 1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(20, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再 Max-Pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三次 Convolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(40, (3, 3), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-Pooling 最終回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們要送進一般的神經網路了。記得這是要拉平的, 還在 Keras 會幫我們做!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(20, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出和上次一樣!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 組裝\n",
    "\n",
    "和之前比較不一樣的是我們還要做 `compile` 才正式把我們的神經網路建好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視我們的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 20)        1820      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 40)          7240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1805      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 11,403\n",
      "Trainable params: 11,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0899 - accuracy: 0.0940\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0897 - accuracy: 0.1322\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0895 - accuracy: 0.1740\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0891 - accuracy: 0.1901\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0882 - accuracy: 0.1964\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0861 - accuracy: 0.1925\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0811 - accuracy: 0.2035\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0740 - accuracy: 0.3380\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0540 - accuracy: 0.6010\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0337 - accuracy: 0.7645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffdbc922dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡因為第一次訓練有點遜 (CNN 標準), 所以我再執行 `fit` 一次, 因此實際上是訓練了 20 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2-5 結果測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分數\n",
    "\n",
    "我們來看測試資料 (我們的 CNN 沒看過的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 75us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看成績, 順便用 Python 3.6 開始的 f-string format 方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的 loss: 0.02530\n",
      "測試資料的正確率: 0.8328999876976013\n"
     ]
    }
   ],
   "source": [
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 儲存結果\n",
    "\n",
    "結果看來還不差, 所以我們把結果存起來。上次我們介紹分別存架構和權重的方法, 這次我們看看怎麼樣一次就存入權重 + 結構!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 欣賞一下成果\n",
    "\n",
    "我們示範一下怎麼讀回我們的神經網路。你會發現讀回來之後就可以直接使用了!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把我們原來的 model 刪掉, 保證接下來的是讀進來的。我們要用一個 `load_model` 的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('myCNNmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們用另一個方式: 每次選 5 個顯示, 看是不是有正確辨識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看來真的可以直接用!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pick = np.random.randint(1,9999, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test[pick[i]].reshape(28,28), cmap='Greys')\n",
    "    plt.title(predict[pick[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "\n",
    "我們到此, 基本上是「亂做」的神經網路。有些同學在不斷試驗的過程中, 可能會發現有時會出現很糟糕的結果。因此, 接下來我們要介紹怎麼樣用些簡單的手法, 能讓學習效果比較穩定, 而且有可能可以增加學習效率。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
