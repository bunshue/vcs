{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 分詞工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting a.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile a.txt\n",
    "\n",
    "去參觀 100 v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.998 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天 我 去 參觀 觀展 展覽 展覽館\n",
      "今天 我 去 參觀 展覽館\n",
      "['今天', '我', '去參觀', '展覽館']\n",
      "今天 t\n",
      "我 r\n",
      "去參觀 v\n",
      "展覽館 n\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "print(' '.join(jieba.cut('今天我去參觀展覽館', cut_all=True))) # 全模式\n",
    "print(' '.join(jieba.cut('今天我去參觀展覽館', cut_all=False))) # 精確模式\n",
    "\n",
    "jieba.load_userdict('a.txt')\n",
    "print(jieba.lcut('今天我去參觀展覽館'))\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"今天我去參觀展覽館\")\n",
    "for w in words:\n",
    "    print(\"%s %s\" %(w.word, w.flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 TF-IDF逆文本頻率指數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['第一天 我 參觀 了 美術館', '第二天 我 參觀 了 博物館', '第三天 我 參觀 了 動物園']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "\n",
    "arr = ['第一天我參觀了美術館',\n",
    "       '第二天我參觀了博物館',\n",
    "       '第三天我參觀了動物園',]\n",
    "\n",
    "arr = [' '.join(jieba.lcut(i)) for i in arr] # 分詞\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   動物園  博物館  參觀  第一天  第三天  第二天  美術館\n",
      "0    0    0   1    1    0    0    1\n",
      "1    0    1   1    0    0    1    0\n",
      "2    1    0   1    0    1    0    0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(arr) \n",
    "word = vectorizer.get_feature_names() \n",
    "df = pd.DataFrame(X.toarray(), columns=word)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0句：\n",
      "參觀 0.39\n",
      "第一天 0.65\n",
      "美術館 0.65\n",
      "第1句：\n",
      "博物館 0.65\n",
      "參觀 0.39\n",
      "第二天 0.65\n",
      "第2句：\n",
      "動物園 0.65\n",
      "參觀 0.39\n",
      "第三天 0.65\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(X)\n",
    "weight = tfidf.toarray()\n",
    "for i in range(len(weight)): # 訪問每一句\n",
    "    print(\"第{}句：\".format(i))\n",
    "    for j in range(len(word)):  # 訪問每個詞\n",
    "        if weight[i][j] > 0.05:  # 只顯示重要關鍵字\n",
    "            print(word[j],round(weight[i][j],2))  # 保留兩位小數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'第一天': 1, '我': 1, '參觀': 1, '了': 1, '美術館': 1}), Counter({'第二天': 1, '我': 1, '參觀': 1, '了': 1, '博物館': 1}), Counter({'第三天': 1, '我': 1, '參觀': 1, '了': 1, '動物園': 1})]\n",
      "第0句：\n",
      "第一天 0.28\n",
      "我 0.14\n",
      "參觀 0.14\n",
      "了 0.14\n",
      "美術館 0.28\n",
      "第1句：\n",
      "第二天 0.28\n",
      "我 0.14\n",
      "參觀 0.14\n",
      "了 0.14\n",
      "博物館 0.28\n",
      "第2句：\n",
      "第三天 0.28\n",
      "我 0.14\n",
      "參觀 0.14\n",
      "了 0.14\n",
      "動物園 0.28\n"
     ]
    }
   ],
   "source": [
    "# 寫程序實現TF-IDF方法\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "countlist = []\n",
    "for i in range(len(arr)):\n",
    "    count = Counter(arr[i].split(' ')) # 用空格將字串切分成字符串列表，統計每個詞出現次數\n",
    "    countlist.append(count)\n",
    "print(countlist)\n",
    "\n",
    "def tf(word, count): \n",
    "    return count[word] / sum(count.values())\n",
    "def contain(word, count_list): # 統計包含關鍵詞word的句子數量\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "def idf(word, count_list):\n",
    "    return np.log(len(count_list) / (contain(word, count_list)) + 1)  #爲避免分母爲0，分母加1\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)\n",
    "for i, count in enumerate(countlist):\n",
    "    print(\"第{}句：\".format(i))\n",
    "    scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "    for word, score in scores.items():\n",
    "        print(word, round(score, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
