{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- 第 1 部分 ---\n# 載入函式庫與資料集\nfrom sklearn.datasets import load_digits\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(123456)\ndata = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\ndata.Time = (data.Time-data.Time.min())/data.Time.std()\ndata.Amount = (data.Amount-data.Amount.mean())/data.Amount.std()\n\n# 把資料分為 70% 訓練資料集與 30% 測試資料集\nx_train, x_test, y_train, y_test = train_test_split(data.drop('Class', axis = 1).values, \n                                                    data.Class.values, \n                                                    test_size = 0.3)\n\n# --- 第 2 部分 ---\n# 計算訓練資料集以及驗證資料集準確率\nx, y = x_train, y_train\nlearner = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1),\n                             algorithm=\"SAMME\")\nparam_range = [x for x in range(90, 181, 10)]\ntrain_scores, test_scores = validation_curve(learner, x, y,\n                                             param_name = 'n_estimators',\n                                             param_range=param_range,\n                                             cv = 10,\n                                             scoring = \"f1\",\n                                             n_jobs = -1)\n\n# --- 第 3 部分 ---\n# 對每個超參數計算模型準確率的平均數與標準差\ntrain_scores_mean = np.mean(train_scores, axis = 1)\ntrain_scores_std = np.std(train_scores, axis = 1)\ntest_scores_mean = np.mean(test_scores, axis = 1)\ntest_scores_std = np.std(test_scores, axis = 1)\n\n\n# --- 第 4 部分 ---\n# 繪製折線圖\nplt.figure(figsize = (8, 8))\nplt.title('Validation curves')\n# 繪製標準差\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha = 0.1,\n                 color=\"C1\")\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha = 0.1, color = \"C0\")\n\n# 繪製平均數\nplt.plot(param_range, train_scores_mean, 'o-', color = \"C1\",\n         label=\"Training score\")\nplt.plot(param_range, test_scores_mean, 'o-', color = \"C0\",\n         label=\"Cross-validation score\")\n\nplt.xticks(param_range)\nplt.xlabel('Ensemble Size')\nplt.ylabel('F1 Score')\nplt.legend(loc=\"best\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T09:28:35.820975Z","iopub.execute_input":"2021-11-28T09:28:35.821364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- 第 5 部分 ---\n# 進行集成\nensemble = AdaBoostClassifier(n_estimators = 160, \n                              learning_rate = 1.0)\nensemble.fit(x_train, y_train)\nprint('AdaBoost f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\nprint('AdaBoost recall', metrics.recall_score(y_test, ensemble.predict(x_test)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:12:19.079128Z","iopub.execute_input":"2021-11-29T02:12:19.07955Z","iopub.status.idle":"2021-11-29T02:15:06.837693Z","shell.execute_reply.started":"2021-11-29T02:12:19.079499Z","shell.execute_reply":"2021-11-29T02:15:06.835283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- 第 6 部分 ---\n# 篩選特徵\nthreshold = 0.1\n\ncorrelations = data.corr()['Class'].drop('Class')\nfs = list(correlations[(abs(correlations)>threshold)].index.values)\nfs.append('Class')\ndata = data[fs]\n\nx_train_f, x_test_f, y_train_f, y_test_f = train_test_split(data.drop('Class', axis=1).values, \n                                                    data.Class.values, \n                                                    test_size=0.3)\n\nensemble = AdaBoostClassifier(n_estimators = 160, \n                              learning_rate = 1.0)\nensemble.fit(x_train_f, y_train_f)\nprint('AdaBoost f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\nprint('AdaBoost recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:15:24.920354Z","iopub.execute_input":"2021-11-29T02:15:24.920705Z","iopub.status.idle":"2021-11-29T02:16:35.067753Z","shell.execute_reply.started":"2021-11-29T02:15:24.920665Z","shell.execute_reply":"2021-11-29T02:16:35.065624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- 第 7 部分 ---\n# 增加學習率到1.3\nensemble = AdaBoostClassifier(n_estimators=160, learning_rate=1.3)\nensemble.fit(x_train, y_train)\nprint('AdaBoost f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\nprint('AdaBoost recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n\nensemble = AdaBoostClassifier(n_estimators=160, learning_rate=1.3)\nensemble.fit(x_train_f, y_train_f)\nprint('AdaBoost f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\nprint('AdaBoost recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:17:27.808267Z","iopub.execute_input":"2021-11-29T02:17:27.808567Z","iopub.status.idle":"2021-11-29T02:21:25.657783Z","shell.execute_reply.started":"2021-11-29T02:17:27.808533Z","shell.execute_reply":"2021-11-29T02:21:25.656765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- 第 8 部分 ---\n# 增加學習率到1.6\nensemble = AdaBoostClassifier(n_estimators=160, learning_rate=1.6)\nensemble.fit(x_train, y_train)\nprint('AdaBoost f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\nprint('AdaBoost recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n\nensemble = AdaBoostClassifier(n_estimators=160, learning_rate=1.6)\nensemble.fit(x_train_f, y_train_f)\nprint('AdaBoost f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\nprint('AdaBoost recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:24:12.790417Z","iopub.execute_input":"2021-11-29T02:24:12.790879Z","iopub.status.idle":"2021-11-29T02:28:24.039743Z","shell.execute_reply.started":"2021-11-29T02:24:12.790835Z","shell.execute_reply":"2021-11-29T02:28:24.037896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- 第 9 部分 ---\n# 增加基學習器數量\nensemble = AdaBoostClassifier(n_estimators=320, learning_rate=1.3)\nensemble.fit(x_train, y_train)\nprint('AdaBoost f1', metrics.f1_score (y_test, ensemble.predict(x_test)))\nprint('AdaBoost recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n\nensemble = AdaBoostClassifier(n_estimators=320, learning_rate=1.3)\nensemble.fit(x_train_f, y_train_f)\nprint('AdaBoost f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\nprint('AdaBoost recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T02:29:18.759468Z","iopub.execute_input":"2021-11-29T02:29:18.759785Z","iopub.status.idle":"2021-11-29T02:37:40.684305Z","shell.execute_reply.started":"2021-11-29T02:29:18.759753Z","shell.execute_reply":"2021-11-29T02:37:40.683351Z"},"trusted":true},"execution_count":null,"outputs":[]}]}