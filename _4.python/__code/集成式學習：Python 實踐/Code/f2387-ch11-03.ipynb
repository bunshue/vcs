{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom string import punctuation\n\nfrom sklearn import metrics\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-27T03:48:35.567374Z","iopub.execute_input":"2021-12-27T03:48:35.568162Z","iopub.status.idle":"2021-12-27T03:48:37.526794Z","shell.execute_reply.started":"2021-12-27T03:48:35.568016Z","shell.execute_reply":"2021-12-27T03:48:37.525863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 讀取資料並指定標籤\nlabels = ['polarity', 'id', 'date', 'query', 'user', 'text']\ndata = pd.read_csv(\"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\", \n                   names=labels,\n                   encoding='latin-1')\ndata = data.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:37.531182Z","iopub.execute_input":"2021-12-27T03:48:37.531647Z","iopub.status.idle":"2021-12-27T03:48:45.799041Z","shell.execute_reply.started":"2021-12-27T03:48:37.531597Z","shell.execute_reply":"2021-12-27T03:48:45.798043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 只保留文字內容和極性，將極性改為 0、1\ndata = data[['text', 'polarity']]\ndata.polarity.replace(4, 1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:45.800317Z","iopub.execute_input":"2021-12-27T03:48:45.800591Z","iopub.status.idle":"2021-12-27T03:48:45.965648Z","shell.execute_reply.started":"2021-12-27T03:48:45.800559Z","shell.execute_reply":"2021-12-27T03:48:45.964816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 創建一個停用詞列表\nstops = stopwords.words(\"english\")\n\n# 添加不帶單引號的停用詞\nno_quotes = []\nfor word in stops:\n    if \"'\" in word:\n        no_quotes.append(re.sub(r'\\'', '', word))\nstops.extend(no_quotes)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:45.967712Z","iopub.execute_input":"2021-12-27T03:48:45.96814Z","iopub.status.idle":"2021-12-27T03:48:45.980652Z","shell.execute_reply.started":"2021-12-27T03:48:45.968091Z","shell.execute_reply":"2021-12-27T03:48:45.979567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_string(string):\n    # 刪除 HTML 特殊字元\n    tmp = re.sub(r'\\&\\w*;', '', string)\n    # 刪除 @user\n    tmp = re.sub(r'@(\\w+)', '', tmp)\n    # 刪除鏈結\n    tmp = re.sub(r'(http|https|ftp)://[a-zA-Z0-9\\\\./]+', \n                 '', \n                 tmp)\n    # 轉小寫\n    tmp = tmp.lower()\n    # 刪除主題標籤\n    tmp = re.sub(r'#(\\w+)', '', tmp)\n    # 刪除重複字元\n    tmp = re.sub(r'(.)\\1{1,}', r'\\1\\1', tmp)\n    # 刪除任何不是字母的東西\n    tmp = re.sub(\"[^a-zA-Z]\", \" \", tmp)\n    # 刪除少於兩個字元的任何內容\n    tmp = re.sub(r'\\b\\w{1,2}\\b', '', tmp)\n    # 刪除多個空格\n    tmp = re.sub(r'\\s\\s+', ' ', tmp)\n    return tmp\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:45.98226Z","iopub.execute_input":"2021-12-27T03:48:45.982579Z","iopub.status.idle":"2021-12-27T03:48:45.990945Z","shell.execute_reply.started":"2021-12-27T03:48:45.982546Z","shell.execute_reply":"2021-12-27T03:48:45.989786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(string):\n\n    stemmer = PorterStemmer()\n    # 刪除標點符號\n    removed_punc = ''.join([char for char in string \n                            if char not in punctuation])\n\n    cleaned = []\n    # 刪除停用詞\n    for word in removed_punc.split(' '):\n        if word not in stops:\n            cleaned.append(stemmer.stem(word.lower()))\n    return ' '.join(cleaned)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:45.992963Z","iopub.execute_input":"2021-12-27T03:48:45.993295Z","iopub.status.idle":"2021-12-27T03:48:46.003171Z","shell.execute_reply.started":"2021-12-27T03:48:45.993251Z","shell.execute_reply":"2021-12-27T03:48:46.002543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_features_ngrams(features, n_grams, classifiers):\n\n    print(features, n_grams)\n\n    # 初始化 TfidfVectorizer 函式\n    tf = TfidfVectorizer(max_features = features, \n                         ngram_range = n_grams,\n                         stop_words = 'english')\n\n    # 將文字資料轉換成數值向量\n    tf.fit(data.text)\n    transformed = tf.transform(data.text)\n\n    np.random.seed(123456)\n\n    def check_classifier(name, classifier):\n        print('--'+name+'--')\n\n        # 將稀疏矩陣轉換成numpy矩陣\n        x_data = transformed[:train_size].toarray()\n        y_data = data.polarity[:train_size].values\n\n        # 訓練基學習器\n        classifier.fit(x_data, y_data)\n        i_s = metrics.accuracy_score(y_data, \n                                     classifier.predict(x_data))\n\n        # 在測試集上評估基學習器效能\n        x_data = transformed[test_start:test_end].toarray()\n        y_data = data.polarity[test_start:test_end].values\n        oos = metrics.accuracy_score(y_data, \n                                     classifier.predict(x_data))\n\n        # 匯出結果\n        with open(\"outs.txt\",\"a\") as f:\n            f.write(str(features)+',')\n            f.write(str(n_grams[-1])+',')\n            f.write(name+',')\n            f.write('%.4f'%i_s+',')\n            f.write('%.4f'%oos+'\\n')\n\n    for name, classifier in classifiers:\n        check_classifier(name, classifier)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:46.004421Z","iopub.execute_input":"2021-12-27T03:48:46.004808Z","iopub.status.idle":"2021-12-27T03:48:46.024731Z","shell.execute_reply.started":"2021-12-27T03:48:46.004776Z","shell.execute_reply":"2021-12-27T03:48:46.023886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac=1).reset_index(drop=True)\ndata.text = data.text.apply(clean_string)\ndata.text = data.text.apply(preprocess)\n\ntrain_size = 10000\ntest_start = 10000\ntest_end = 100000\n\n# 創建 csv 標頭\nwith open(\"outs.txt\",\"a\") as f:\n    f.write('features,ngram_range,classifier')\n    f.write('train_acc,test_acc\\n')\n\n# 測試所有特徵和 n-連字串組合\nfor features in [500, 1000, 5000, 10000, 20000, 30000]:\n    for n_grams in [(1, 1), (1, 2), (1, 3)]:\n\n        # 初始化集成模型\n        voting = VotingClassifier([('DT', \n                                    DecisionTreeClassifier()),\n                                   ('NB',\n                                    MultinomialNB()),\n                                   ('Ridge', \n                                    RidgeClassifier())])\n\n        # 整合集成模型與單一基學習器\n        classifiers = [('DT', \n                        DecisionTreeClassifier()),\n                       ('NB', \n                        MultinomialNB()),\n                       ('Ridge', \n                        RidgeClassifier()),\n                       ('Voting', \n                        voting)]\n\n        # 訓練模型\n        check_features_ngrams(features, n_grams, classifiers)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:48:46.026174Z","iopub.execute_input":"2021-12-27T03:48:46.026723Z","iopub.status.idle":"2021-12-27T03:54:49.248094Z","shell.execute_reply.started":"2021-12-27T03:48:46.026673Z","shell.execute_reply":"2021-12-27T03:54:49.246694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ntext = []\nwith open(\"outs.txt\", 'r') as f:\n   text = f.readlines()\n   f.close()\n\nx = [500, 1000, 5000, 10000, 20000, 30000]\n\nfor model in [\"DT\", \"NB\", \"Ridge\", \"Voting\"]:\n    gram_1 = []\n    gram_2 = []\n    gram_3 = []\n    for line in text:\n        token = line.split(\",\")\n        if(token[2] == model):\n            if(int(token[1]) == 1):\n                gram_1.append(float(token[4]))\n            if(int(token[1]) == 2):\n                gram_2.append(float(token[4]))\n            if(int(token[1]) == 3):\n                gram_3.append(float(token[4]))\n    \n    plt.figure(figsize = (8, 8))\n    plt.plot(x, gram_1, label = \"1-gram\")\n    plt.plot(x, gram_2, label = \"2-gram\",\n             linestyle = \"-.\")\n    plt.plot(x, gram_3, label = \"3-gram\",\n             linestyle = \"--\")\n    plt.xlabel(\"Features\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.title(model)\n    plt.show()\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:54:49.249438Z","iopub.status.idle":"2021-12-27T03:54:49.250733Z","shell.execute_reply.started":"2021-12-27T03:54:49.250351Z","shell.execute_reply":"2021-12-27T03:54:49.250402Z"},"trusted":true},"execution_count":null,"outputs":[]}]}