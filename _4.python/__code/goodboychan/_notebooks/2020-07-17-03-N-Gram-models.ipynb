{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram models\n",
    "> Learn about n-gram modeling and use it to perform sentiment analysis on movie reviews. This is the Summary of lecture \"Feature Engineering for NLP in Python\", via datacamp.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Datacamp, Natural_Language_Processing]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a bag of words model\n",
    "- Bag of words model\n",
    "    - Extract word tokens\n",
    "    - Compute frequency of word tokens\n",
    "    - Construct a word vector out of these frequencies and vocabulary of corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW model for movie taglines\n",
    "In this exercise, you have been provided with a `corpus` of more than 7000 movie tag lines. Your job is to generate the bag of words representation `bow_matrix` for these taglines. For this exercise, we will ignore the text preprocessing step and generate `bow_matrix` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>roll the dice and unleash the excitement!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>still yelling. still fighting. still ready for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>friends are the people who let you be yourself...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>just when his world is back to normal... he's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>949</td>\n",
       "      <td>Heat</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>a los angeles crime saga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        title  \\\n",
       "1   8844                      Jumanji   \n",
       "2  15602             Grumpier Old Men   \n",
       "3  31357            Waiting to Exhale   \n",
       "4  11862  Father of the Bride Part II   \n",
       "5    949                         Heat   \n",
       "\n",
       "                                            overview  \\\n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "5  Obsessive master thief, Neil McCauley leads a ...   \n",
       "\n",
       "                                             tagline  \n",
       "1          roll the dice and unleash the excitement!  \n",
       "2  still yelling. still fighting. still ready for...  \n",
       "3  friends are the people who let you be yourself...  \n",
       "4  just when his world is back to normal... he's ...  \n",
       "5                           a los angeles crime saga  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./dataset/movie_overviews.csv').dropna()\n",
    "movies['tagline'] = movies['tagline'].str.lower()\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = movies['tagline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7033, 6614)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print the shape of bow_matrix\n",
    "print(bow_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to generate a bag of words representation for a given corpus of documents. Notice that the word vectors created have more than 6600 dimensions. However, most of these dimensions have a value of zero since most words do not occur in a particular tagline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing dimensionality and preprocessing\n",
    "In this exercise, you have been provided with a `lem_corpus` which contains the pre-processed versions of the movie taglines from the previous exercise. In other words, the taglines have been lowercased and lemmatized, and stopwords have been removed.\n",
    "\n",
    "Your job is to generate the bag of words representation `bow_lem_matrix` for these lemmatized taglines and compare its shape with that of `bow_matrix` obtained in the previous exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_corpus = corpus.apply(lambda row: ' '.join([t.lemma_ for t in nlp(row) \n",
    "                                                if t.lemma_ not in stopwords \n",
    "                                                and t.lemma_.isalpha()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                            roll dice unleash excitement\n",
       "2                                   yell fight ready love\n",
       "3                            friend people let let forget\n",
       "4                              world normal surprise life\n",
       "5                                  los angeles crime saga\n",
       "                              ...                        \n",
       "9091                         kingsglaive final fantasy xv\n",
       "9093                       happen vegas stay vegas happen\n",
       "9095    decorate officer devoted family man defend hon...\n",
       "9097                              god incarnate city doom\n",
       "9098                                      band know story\n",
       "Name: tagline, Length: 7033, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7033, 4964)\n"
     ]
    }
   ],
   "source": [
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate of word vectors\n",
    "bow_lem_matrix = vectorizer.fit_transform(lem_corpus)\n",
    "\n",
    "# Print the shape of how_lem_matrix\n",
    "print(bow_lem_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping feature indices with feature names\n",
    "n the lesson video, we had seen that `CountVectorizer` doesn't necessarily index the vocabulary in alphabetical order. In this exercise, we will learn to map each feature index to its corresponding feature name from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['The lion is the king of the jungle',\n",
    "             'Lions have lifespans of a decade', \n",
    "             'The lion is an endangered species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>decade</th>\n",
       "      <th>endangered</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>jungle</th>\n",
       "      <th>king</th>\n",
       "      <th>lifespans</th>\n",
       "      <th>lion</th>\n",
       "      <th>lions</th>\n",
       "      <th>of</th>\n",
       "      <th>species</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   an  decade  endangered  have  is  jungle  king  lifespans  lion  lions  of  \\\n",
       "0   0       0           0     0   1       1     1          0     1      0   1   \n",
       "1   0       1           0     1   0       0     0          1     0      1   1   \n",
       "2   1       0           1     0   1       0     0          0     1      0   0   \n",
       "\n",
       "   species  the  \n",
       "0        0    3  \n",
       "1        0    0  \n",
       "2        1    1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Generate matrix of word vectors\n",
    "bow_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "# Convert bow_matrix into a DataFrame\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray())\n",
    "\n",
    "# Map the column names to vocabulary\n",
    "bow_df.columns = vectorizer.get_feature_names()\n",
    "\n",
    "# Print bow_df\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the column names refer to the token whose frequency is being recorded. Therefore, since the first column name is an, the first feature represents the number of times the word `'an'` occurs in a particular sentence. `get_feature_names()` essentially gives us a list which represents the mapping of the feature indices to the feature name in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a BoW Naive Bayes classifier\n",
    "- Steps\n",
    "    1. Text preprocessing\n",
    "    2. Building a bag-of-words model (or representation)\n",
    "    3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW vectors for movie reviews\n",
    "n this exercise, you have been given two pandas Series, `X_train` and `X_test`, which consist of movie reviews. They represent the training and the test review data respectively. Your task is to preprocess the reviews and generate BoW vectors for these two sets using `CountVectorizer`.\n",
    "\n",
    "Once we have generated the BoW vector matrices `X_train_bow` and `X_test_bow`, we will be in a very good position to apply a machine learning model to it and conduct sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this anime series starts out great interesting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>some may go for a film like this but i most as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ve seen this piece of perfection during the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this movie is likely the worst movie i ve ever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it ll soon be 10 yrs since this movie was rele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  this anime series starts out great interesting...          0\n",
       "1  some may go for a film like this but i most as...          0\n",
       "2  i ve seen this piece of perfection during the ...          1\n",
       "3  this movie is likely the worst movie i ve ever...          0\n",
       "4  it ll soon be 10 yrs since this movie was rele...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv('./dataset/movie_reviews_clean.csv')\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movie_reviews['review']\n",
    "y = movie_reviews['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 14859)\n",
      "(250, 14859)\n"
     ]
    }
   ],
   "source": [
    "# Create a CounterVectorizer object\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "\n",
    "# fit and transform X_train\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Print shape of X_train_bow and X_test_bow\n",
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a good idea of preprocessing text and transforming them into their bag-of-words representation using `CountVectorizer`. In this exercise, you have set the lowercase argument to True. However, note that this is the default value of lowercase and passing it explicitly is not necessary. Also, note that both `X_train_bow` and `X_test_bow` have 7822 features. There were words present in `X_test` that were not in `X_train`. CountVectorizer chose to ignore them in order to ensure that the dimensions of both sets remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the sentiment of a movie review\n",
    "n the previous exercise, you generated the bag-of-words representations for the training and test movie review data. In this exercise, we will use this model to train a Naive Bayes classifier that can detect the sentiment of a movie review and compute its accuracy. Note that since this is a binary classification problem, the model is only capable of classifying a review as either positive (1) or negative (0). It is incapable of detecting neutral reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the test set is 0.836\n",
      "The sentiment predicted by the classifier is 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train_bow, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf.score(X_test_bow, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
    "\n",
    "# Predict the sentiment of a negative review\n",
    "review = 'The movie was terrible. The music was underwhelming and the acting mediocre.'\n",
    "prediction = clf.predict(vectorizer.transform([review]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully performed basic sentiment analysis. Note that the accuracy of the classifier is 80%. Considering the fact that it was trained on only 750 reviews, this is reasonably good performance. The classifier also correctly predicts the sentiment of a mini negative review which we passed into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building n-gram models\n",
    "- BoW shortcomings\n",
    "    - Example\n",
    "        - `The movie was good and not boring` -> positive\n",
    "        - `The movie was not good and boring` -> negative\n",
    "    - Exactly the same BoW representation!\n",
    "    - Context of the words is lost.\n",
    "    - Sentiment dependent on the position of `not`\n",
    "- n-grams\n",
    "    - Contiguous sequence of n elements (or words) in a given document.\n",
    "    - Bi-grams / Tri-grams\n",
    "- n-grams Shortcomings\n",
    "    - Increase number of dimension, occurs curse of dimensionality\n",
    "    - Higher order n-grams are rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram models for movie tag lines\n",
    "In this exercise, we have been provided with a corpus of more than 9000 movie tag lines. Our job is to generate n-gram models up to n equal to 1, n equal to 2 and n equal to 3 for this data and discover the number of features for each model.\n",
    "\n",
    "We will then compare the number of features generated for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng1, ng2 and ng3 have 6614, 37100 and 76881 features respectively\n"
     ]
    }
   ],
   "source": [
    "# Generate n-grams upto n=1\n",
    "vectorizer_ng1 = CountVectorizer(ngram_range=(1, 1))\n",
    "ng1 = vectorizer_ng1.fit_transform(corpus)\n",
    "\n",
    "# Generate n-grams upto n=2\n",
    "vectorizer_ng2 = CountVectorizer(ngram_range=(1, 2))\n",
    "ng2 = vectorizer_ng2.fit_transform(corpus)\n",
    "\n",
    "# Generate n-grams upto n=3\n",
    "vectorizer_ng3 = CountVectorizer(ngram_range=(1, 3))\n",
    "ng3 = vectorizer_ng3.fit_transform(corpus)\n",
    "\n",
    "# Print the number of features for each model\n",
    "print(\"ng1, ng2 and ng3 have %i, %i and %i features respectively\" % \n",
    "      (ng1.shape[1], ng2.shape[1], ng3.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to generate n-gram models containing higher order n-grams. Notice that `ng2` has over 37,000 features whereas `ng3` has over 76,000 features. This is much greater than the 6,000 dimensions obtained for `ng1`. As the n-gram range increases, so does the number of features, leading to increased computational costs and a problem known as the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher order n-grams for sentiment analysis\n",
    "Similar to a previous exercise, we are going to build a classifier that can detect if the review of a particular movie is positive or negative. However, this time, we will use n-grams up to n=2 for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_ng = ng_vectorizer.fit_transform(X_train)\n",
    "X_test_ng = ng_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the test set is 0.824\n",
      "The sentiment predicted by the classifier is 0\n"
     ]
    }
   ],
   "source": [
    "# Define an instance of MultinomialNB\n",
    "clf_ng = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf_ng.fit(X_train_ng, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf_ng.score(X_test_ng, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)\n",
    "\n",
    "# Predict the sentiment of a negative review\n",
    "review = 'The movie was not good. The plot had several holes and the acting lacked panache'\n",
    "prediction = clf_ng.predict(ng_vectorizer.transform([review]))[0]\n",
    "print(\"The sentiment predicted by the classifier is %i\" % (prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this classifier performs slightly better than the BoW version. Also, it succeeds at correctly identifying the sentiment of the mini-review as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing performance of n-gram models\n",
    "You now know how to conduct sentiment analysis by converting text into various n-gram representations and feeding them to a classifier. In this exercise, we will conduct sentiment analysis for the same movie reviews from before using two n-gram models: unigrams and n-grams upto n equal to 3.\n",
    "\n",
    "We will then compare the performance using three criteria: accuracy of the model on the test set, time taken to execute the program and the number of features created when generating the n-gram representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took 0.127 seconds to complete. The accuracy on the test set is 0.75. \n",
      "The ngram representation had 12347 features.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(movie_reviews['review'],\n",
    "                                                    movie_reviews['sentiment'], \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=movie_reviews['sentiment'])\n",
    "\n",
    "# Generateing ngrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)\n",
    "\n",
    "# Fit classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Print the accuracy, time and number of dimensions\n",
    "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. \" %\n",
    "      (time.time() - start_time, clf.score(test_X, test_y)))\n",
    "print(\"The ngram representation had %i features.\" % (train_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program took 0.681 seconds to complete. The accuracy on the test set is 0.77. \n",
      "The ngram representation had 178240 features.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(movie_reviews['review'],\n",
    "                                                    movie_reviews['sentiment'], \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=movie_reviews['sentiment'])\n",
    "\n",
    "# Generateing ngrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_X = vectorizer.fit_transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)\n",
    "\n",
    "# Fit classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# Print the accuracy, time and number of dimensions\n",
    "print(\"The program took %.3f seconds to complete. The accuracy on the test set is %.2f. \" %\n",
    "      (time.time() - start_time, clf.score(test_X, test_y)))\n",
    "print(\"The ngram representation had %i features.\" % (train_X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program took around 0.2 seconds in the case of the unigram model and more than 10 times longer for the higher order n-gram model. The unigram model had over 12,000 features whereas the n-gram model for upto n=3 had over 178,000! Despite taking higher computation time and generating more features, the classifier only performs marginally better in the latter case, producing an accuracy of 77% in comparison to the 75% for the unigram model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
