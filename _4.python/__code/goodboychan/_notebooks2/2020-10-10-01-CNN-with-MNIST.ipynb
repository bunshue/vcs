{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with MNIST dataset\n",
    "> In this post, we will implement various type of CNN for MNIST dataset. In Tensorflow, there are various ways to define CNN model like sequential model, functional model, and sub-class model. We'll simply implement each type and test it.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Deep_Learning, Tensorflow-Keras]\n",
    "- image: images/CNN_MNIST.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rc('font', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model with sequential API\n",
    "Previously, we learned basic operation of convolution and max-pooling. Actually, we already implemented simple type of CNN model for MNIST classification, which is manually combined with 2D convolution layer and max-pooling layer. But there are other ways to define CNN model. In this section, we will implement CNN model with Sequential API.\n",
    "\n",
    "Briefly speaking, we will build the model as follows,\n",
    "\n",
    "![CNN](image/CNN_MNIST.png)\n",
    "\n",
    " 3x3 2D convolution layer is defined as an input layer, and post-process with 2x2 max-pooling. And these process will be redundant 3 times, then set fully-connected layer as an output layer for classification. In convolution layer, stride will be 1, and padding will be `same` (that is, we will use half padding). And in max-pooling layer, stride will be 2, and padding will also be `same`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setting\n",
    "Firstly, we need to define hyperparameter that affect model training. For the review, **hyperparameter** is a parameter whose value is used to control the learning process, such as learning rate, epochs, and batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the tracking model training, it is helpful to build checkpoint while training the model, so when we the model training is failed due to unexpected reason, we can re-train it with checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cur_dir, 'checkpoints', 'mnist_cnn_seq')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'mnist_cnn_seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipelining\n",
    "Before model implementation, it requires data pipelining, also known as data-preprocess. As you can see from previous example, the original raw data is hardly used directly. So we need to normalize it, convert it, that we can express whole process as an \"data-preprocessing\".\n",
    "\n",
    "Note that, the label of each data is class label. So to use it in Neural network model, it needs to encode it as an binary code. Maybe someone already knew it, it is **one-hot** encoding. Luckily, tf.keras also implements `to_categorical` for one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train.astype(np.float32) / 255.\n",
    "X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "# Convert it to 4D array (or we can use np.expand_dims for dimension expansion)\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build dataset pipeline\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=100000).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with Sequential API\n",
    "Building model with Sequential API is similar with previous example. The difference is that Sequential API pre-build the model skeleton, then add each specific layers. In this code, we will build one API to build whole models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential(name='CNN_Sequential')\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME', input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.activations.relu))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, when we directly add the layer, we need to enter the input data for generating output. But in Sequential model, each previous layers node is connected with next layers node automatically, All we need to do is to input the data in the model, then output will be generated from the whole model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Gradient \n",
    "Same as MLP, we need to define loss function and use gradient descent for finding minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    return loss\n",
    "\n",
    "# Gradient Function\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Evaluation\n",
    "For finding optimum value, we will use \"Adam\" Optimizer with predifined learning_rate. Also, we need to define evaluation function so that we can check the performance (or accuracy of model).\n",
    "\n",
    "One more thing, We already mention that checkpoint is required for tracking history. So we will define it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    correct_predict = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(cnn=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "Finally, we can train model with our training dataset. And also we need to check the performance while training the model, so after train the model in each epoch, we will also evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.18302731 train acc: 0.9541 test acc: 0.9875\n",
      "Epoch: 2 loss: 0.04729259 train acc: 0.9897 test acc: 0.9915\n",
      "Epoch: 3 loss: 0.03278064 train acc: 0.9931 test acc: 0.9911\n",
      "Epoch: 4 loss: 0.02512466 train acc: 0.9952 test acc: 0.9926\n",
      "Epoch: 5 loss: 0.01846576 train acc: 0.9966 test acc: 0.9911\n",
      "Epoch: 6 loss: 0.01516856 train acc: 0.9974 test acc: 0.9924\n",
      "Epoch: 7 loss: 0.01260581 train acc: 0.9981 test acc: 0.9930\n",
      "Epoch: 8 loss: 0.01126267 train acc: 0.9980 test acc: 0.9926\n",
      "Epoch: 9 loss: 0.00826933 train acc: 0.9990 test acc: 0.9935\n",
      "Epoch: 10 loss: 0.00785774 train acc: 0.9990 test acc: 0.9926\n",
      "Epoch: 11 loss: 0.00759397 train acc: 0.9990 test acc: 0.9937\n",
      "Epoch: 12 loss: 0.00697561 train acc: 0.9992 test acc: 0.9933\n",
      "Epoch: 13 loss: 0.00637996 train acc: 0.9993 test acc: 0.9922\n",
      "Epoch: 14 loss: 0.00513943 train acc: 0.9995 test acc: 0.9924\n",
      "Epoch: 15 loss: 0.00479634 train acc: 0.9996 test acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "for e in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        grads = grad(model, images, labels)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_loss = avg_loss + loss\n",
    "        avg_train_acc = avg_train_acc + acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_test_acc = avg_test_acc + acc\n",
    "        test_step += 1\n",
    "    avg_test_acc = avg_test_acc / test_step\n",
    "    \n",
    "    print(\"Epoch: {}\".format(e + 1),\n",
    "          \"loss: {:.8f}\".format(avg_loss),\n",
    "          \"train acc: {:.4f}\".format(avg_train_acc),\n",
    "          \"test acc: {:.4f}\".format(avg_test_acc))\n",
    "    \n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model with Functional API\n",
    "We can find out that it works in Sequential API. Now let's implement it with another approach, the Functional APIs. Whole process will be same, except building model section.\n",
    "\n",
    "There is some limitation while building model with Sequential API. As you can see from `create_model`, whole layers are connected in one pipeline. But what if we want to use multi-input, or multi-output? And in Sequaltial API, we cannot mannually build the layer block. For instance, [ResNet](https://arxiv.org/abs/1512.03385) uses specific block named **residual block** that contained **skip connection**. But we cannot implement manual block in sequential API. Or we cannot build shared layers, so same layer is called several times.\n",
    "\n",
    "Actually, building process is almost similar with that of Sequential API. All we need to do is to define input, output, and connect each layers like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_functional():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', \n",
    "                                   activation=tf.keras.activations.relu)(inputs)\n",
    "    pool1 = tf.keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                   activation=tf.keras.activations.relu)(pool1)\n",
    "    pool2 = tf.keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
    "    conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                   activation=tf.keras.activations.relu)(pool2)\n",
    "    pool3 = tf.keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
    "    pool3_flat = tf.keras.layers.Flatten()(pool3)\n",
    "    dense4 = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)(pool3_flat)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.4)(dense4)\n",
    "    logits = tf.keras.layers.Dense(units=10)(drop4)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model_functional()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the summary of model, the total parameter is the same as previous one. Interest thing is that the default name is defined as \"functional_x\". From these, we can found out that our new model is implemented with functional API.\n",
    "\n",
    "One more example, in Residual block, we can implement skip connection like this,\n",
    "\n",
    "![skip connection](image/skip_connection.png)\n",
    "\n",
    "```python\n",
    "inputs = tf.keras.Input(shape=(28, 28, 256))\n",
    "conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(1, 1), padding='SAME', activation=tf.keras.activations.relu)(inputs)\n",
    "conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=tf.keras.activations.relu)(conv1)\n",
    "conv3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(1, 1), padding='SAME')(conv2)\n",
    "# skip connection\n",
    "add3 = tf.keras.layers.add([conv3, inputs])\n",
    "relu3 = tf.keras.activations.relu(add3)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=relu3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model with Model Subclassing\n",
    "The other way to build model is Subclassing. Technically, it is defined model with python Class. Model Subclassing is the approach to build a fully-customizable model by subclassing `tf.keras.Model`. So we can define the inital implementation like layer, node parameter on `__init__` method, and forward pass on `call` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.pool3_flat = tf.keras.layers.Flatten()\n",
    "        self.dense4 = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)\n",
    "        self.drop4 = tf.keras.layers.Dropout(rate=0.4)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.pool3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        net = self.dense5(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we just instantiate the `CNNModel` class, so the connection is not connected when instantiates. If we want to find the summary of this network, we need to build it or fit it with some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            multiple                  320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(1, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model with Model Ensemble\n",
    "The last method to build model is Ensemble method. Actually, the keyword **ensemble** is from statistics and machine learning. In wikipedia, it is defined that this method use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithm alone. If you know about the Machine Learning, Random Forest is an ensemble model using bagging approach.\n",
    "\n",
    "In short, we can run several CNN Networks simultaneously, and choose the best network that shows good performance.\n",
    "\n",
    "![CNN_ensemble](image/CNN_ensemble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first step, we build the base model with Model Subclassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.pool3_flat = tf.keras.layers.Flatten()\n",
    "        self.dense4 = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)\n",
    "        self.drop4 = tf.keras.layers.Dropout(rate=0.4)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.pool3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        net = self.dense5(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, here is the point. If we want use 3 models for ensemble, we just instantiate each model and append it to the list like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for m in range(3):\n",
    "    models.append(CNNModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use same loss and gradient function as previous, since all function is focused on one model. But our purpose is choose the best model of test dataset, so we need to change `evaluate` method for multiple models. Also, we need to modify checkpoint saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    return loss\n",
    "\n",
    "# Gradient Function\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "def evaluate(models, images, labels):\n",
    "    predicts = tf.zeros_like(labels)\n",
    "    for model in models:\n",
    "        logits = model(images, training=False)\n",
    "        predicts += logits\n",
    "    correct_predict = tf.equal(tf.argmax(predicts, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "checkpoints = []\n",
    "for model in models:\n",
    "    checkpoints.append(tf.train.Checkpoint(cnn=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, of course, training and validation process will be changed for multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.16114779 Train Accuracy: 0.9645 Test Accuracy: 0.9905\n",
      "Epoch: 2 Loss: 0.04136952 Train Accuracy: 0.9926 Test Accuracy: 0.9926\n",
      "Epoch: 3 Loss: 0.02659128 Train Accuracy: 0.9959 Test Accuracy: 0.9936\n",
      "Epoch: 4 Loss: 0.02009956 Train Accuracy: 0.9969 Test Accuracy: 0.9935\n",
      "Epoch: 5 Loss: 0.01601616 Train Accuracy: 0.9980 Test Accuracy: 0.9942\n",
      "Epoch: 6 Loss: 0.01329517 Train Accuracy: 0.9987 Test Accuracy: 0.9941\n",
      "Epoch: 7 Loss: 0.01031435 Train Accuracy: 0.9990 Test Accuracy: 0.9948\n",
      "Epoch: 8 Loss: 0.00889915 Train Accuracy: 0.9993 Test Accuracy: 0.9937\n",
      "Epoch: 9 Loss: 0.00782115 Train Accuracy: 0.9995 Test Accuracy: 0.9941\n",
      "Epoch: 10 Loss: 0.00677414 Train Accuracy: 0.9996 Test Accuracy: 0.9946\n",
      "Epoch: 11 Loss: 0.00599033 Train Accuracy: 0.9996 Test Accuracy: 0.9951\n",
      "Epoch: 12 Loss: 0.00527186 Train Accuracy: 0.9997 Test Accuracy: 0.9947\n",
      "Epoch: 13 Loss: 0.00516927 Train Accuracy: 0.9998 Test Accuracy: 0.9952\n",
      "Epoch: 14 Loss: 0.00405203 Train Accuracy: 0.9999 Test Accuracy: 0.9949\n",
      "Epoch: 15 Loss: 0.00418452 Train Accuracy: 0.9999 Test Accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "for e in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        for model in models:\n",
    "            grads = grad(model, images, labels)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            loss = loss_fn(model, images, labels)\n",
    "            avg_loss += loss / 3\n",
    "        acc = evaluate(models, images, labels)\n",
    "        avg_train_acc += acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        acc = evaluate(models, images, labels)\n",
    "        avg_test_acc += acc\n",
    "        test_step += 1\n",
    "    avg_test_acc = avg_test_acc / test_step\n",
    "    \n",
    "    print(\"Epoch: {}\".format(e + 1),\n",
    "          \"Loss: {:.8f}\".format(avg_loss),\n",
    "          \"Train Accuracy: {:.4f}\".format(avg_train_acc),\n",
    "          \"Test Accuracy: {:.4f}\".format(avg_test_acc))\n",
    "    \n",
    "    for idx, checkpoint in enumerate(checkpoints):\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix+'-{}'.format(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial accuracy is already high in 99%, we cannot check improvement of ensemble method, but if you stuck in low performance on inference, we maybe apply this kind of approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best CNN model in MNIST dataset\n",
    "We covered various type of model implementation, and also introduced ensemble method for model improvement. But there are other ways to improve model performance. \n",
    "\n",
    "Actually, while we modify the network model, we may be faced with the Overfitting/Underfitting problem. This kind of problem is also known as Bias-Variance Tradeoff. The ultimate solution (if possible) for handling this is to add more data  representing various patterns. But in real case, limitation of data amount is commonly occurred. So easiest way to increase data amount is regenerate the data from original data. Not only increasing the amount, we can also transform the image like rotation, color distribution, shift and so on. This approach is called **Data Augmentation**.\n",
    "\n",
    "### Data Augmentation\n",
    "For image transformation, we use `ndimage` from `scipy`. And here, we will apply rotation and shift transformation from original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import random\n",
    "\n",
    "def data_augmentation(images, labels):\n",
    "    aug_images = []\n",
    "    aug_labels = []\n",
    "    \n",
    "    for image, label in zip(images, labels):\n",
    "        aug_images.append(image)\n",
    "        aug_labels.append(label)\n",
    "        \n",
    "        # Background image for filling empty pixel\n",
    "        bg_value = np.median(image)\n",
    "        for _ in range(4):\n",
    "            # Rotation\n",
    "            rot_image = ndimage.rotate(image, angle=random.randint(-15, 15), \n",
    "                                       reshape=False, cval=bg_value)\n",
    "            # Shift\n",
    "            shift_image = ndimage.shift(rot_image, shift=np.random.randint(-2, 2, 2), \n",
    "                                        cval=bg_value)\n",
    "            \n",
    "            aug_images.append(shift_image)\n",
    "            aug_labels.append(label)\n",
    "    aug_images = np.array(aug_images)\n",
    "    aug_labels = np.array(aug_labels)\n",
    "    return aug_images, aug_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while data-preprocessing, we need to apply data augmentation for original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train, y_train = data_augmentation(X_train, y_train)\n",
    "\n",
    "# Convert numpy float type and normalize it\n",
    "X_train = X_train.astype(np.float32) / 255.\n",
    "X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "# Convert it to 4D array (or we can use np.expand_dims for dimension expansion)\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build dataset pipeline\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=500000).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "Batch normalization is another form of regularization that rescales the output of a layer to make sure that have mean 0 and standard deviation 1 (that is, normal distribution). This approach is known as helping model training. We can apply this in our network. In this case, we will specific layers containing 1 convolution layer with batch normalization. And we can also apply kernel initialization with \"Xavier initialization\". (check the [detail](https://goodboychan.github.io/chans_jupyter/python/deep_learning/tensorflow-keras/2020/09/18/01-Several-Tips-for-Improving-Neural-Network.html#Weight-Initialization) in previous post for Xavier initialization) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=(3, 3), strides=1, padding='SAME'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, \n",
    "                                           strides=strides, padding=padding,\n",
    "                                           kernel_initializer='glorot_normal')\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv(inputs)\n",
    "        net = self.bn(net)\n",
    "        return tf.keras.activations.relu(net)\n",
    "    \n",
    "class DenseBNRelu(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(DenseBNRelu, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(units=units, kernel_initializer='glorot_normal')\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.dense(inputs)\n",
    "        net = self.bn(net)\n",
    "        return tf.keras.activations.relu(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we can build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=32, kernel_size=(3, 3), padding='SAME')\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv2 = ConvBNRelu(filters=64, kernel_size=(3, 3), padding='SAME')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv3 = ConvBNRelu(filters=128, kernel_size=(3, 3), padding='SAME')\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.pool3_flat = tf.keras.layers.Flatten()\n",
    "        self.dense4 = DenseBNRelu(units=256)\n",
    "        self.drop4 = tf.keras.layers.Dropout(rate=0.4)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.pool3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        return self.dense5(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the ensemble method. In this case, we will use 5 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for _ in range(5):\n",
    "    models.append(CNNModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same in loss function and gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    return loss\n",
    "\n",
    "# Gradient Function\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate(models, images, labels):\n",
    "    predicts = tf.zeros_like(labels)\n",
    "    for model in models:\n",
    "        logits = model(images, training=False)\n",
    "        predicts += logits\n",
    "    correct_predict = tf.equal(tf.argmax(predicts, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Decay\n",
    "When back-propagation is process while training the model, `learning_rate` is kind of step_size when the optimizer is moved for finding optimal solution. If we changed our learning rate in depend on time (some called decaying, annealing whatever), it will easily find the optimal solution. There are other ways for learning rate scheduler like InverseTimeDecay, PolynomialDecay, etc. Find out more in [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate Scheduler\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                          decay_steps=X_train.shape[0] / batch_size * 5 * 5,\n",
    "                                          decay_rate=0.5,\n",
    "                                          staircase=True)\n",
    "\n",
    "# Optimizer with learning rate scheduler\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoints = []\n",
    "for model in models:\n",
    "    checkpoints.append(tf.train.Checkpoint(cnn=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation\n",
    "Finally, we can train and validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.08002218 Train Accuracy: 0.9215 Test Accuracy: 0.9924\n",
      "Epoch: 2 Loss: 0.03462527 Train Accuracy: 0.9963 Test Accuracy: 0.9960\n",
      "Epoch: 3 Loss: 0.02448047 Train Accuracy: 0.9978 Test Accuracy: 0.9963\n",
      "Epoch: 4 Loss: 0.01887396 Train Accuracy: 0.9986 Test Accuracy: 0.9965\n",
      "Epoch: 5 Loss: 0.01442536 Train Accuracy: 0.9992 Test Accuracy: 0.9955\n",
      "Epoch: 6 Loss: 0.00874317 Train Accuracy: 0.9996 Test Accuracy: 0.9965\n",
      "Epoch: 7 Loss: 0.00609205 Train Accuracy: 0.9998 Test Accuracy: 0.9968\n",
      "Epoch: 8 Loss: 0.00503694 Train Accuracy: 0.9999 Test Accuracy: 0.9969\n",
      "Epoch: 9 Loss: 0.00448319 Train Accuracy: 0.9999 Test Accuracy: 0.9964\n",
      "Epoch: 10 Loss: 0.00395256 Train Accuracy: 0.9999 Test Accuracy: 0.9964\n",
      "Epoch: 11 Loss: 0.00249814 Train Accuracy: 1.0000 Test Accuracy: 0.9971\n",
      "Epoch: 12 Loss: 0.00187171 Train Accuracy: 1.0000 Test Accuracy: 0.9967\n",
      "Epoch: 13 Loss: 0.00159950 Train Accuracy: 1.0000 Test Accuracy: 0.9965\n",
      "Epoch: 14 Loss: 0.00149392 Train Accuracy: 1.0000 Test Accuracy: 0.9962\n",
      "Epoch: 15 Loss: 0.00134583 Train Accuracy: 1.0000 Test Accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "for e in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        for model in models:\n",
    "            grads = grad(model, images, labels)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            loss = loss_fn(model, images, labels)\n",
    "            avg_loss += loss / 3\n",
    "        acc = evaluate(models, images, labels)\n",
    "        avg_train_acc += acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        acc = evaluate(models, images, labels)\n",
    "        avg_test_acc += acc\n",
    "        test_step += 1\n",
    "    avg_test_acc = avg_test_acc / test_step\n",
    "    \n",
    "    print(\"Epoch: {}\".format(e + 1),\n",
    "          \"Loss: {:.8f}\".format(avg_loss),\n",
    "          \"Train Accuracy: {:.4f}\".format(avg_train_acc),\n",
    "          \"Test Accuracy: {:.4f}\".format(avg_test_acc))\n",
    "    \n",
    "    for idx, checkpoint in enumerate(checkpoints):\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix+'-{}'.format(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll take long long time to train. Maybe takes some cup of coffee, and get some rest :)\n",
    "\n",
    "> Note: If we use `model.variables` while finding gradients, it will throw the warning log like, \"gradients do not exist for variables\". That's because the model tried to find gradient for whole variables including non-trainable variable like moving mean or variance. This is widely happened when we use batch normalization layer. To avoid this, we just select model's trainable variable (`model.trainable_variables`) for finding gradient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this post, we introduced several approaches to define CNN model: Sequential, Functional, and Model Subclassing. Also we can borrow the concept of \"ensemble\" method for improving our model performance. Additionally, we can regenerate the data through data-augmentation, and added batch normalization for speeding up our training. As a result, we can make simple CNN model for classifying MNIST dataset with 99% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
