{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing\n",
    "> In this post, we will dig into the strong NLP foundation through basic concepts like Tokenization, Stopword handling, Stemming and so on. We will use sklearn with Natural Language ToolKit (NLTK) package, which is widely used in NLP area.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Machine_Learning, Natural_Language_Processing]\n",
    "- image: images/ner_draw.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Natural-language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to fruitfully process large amounts of natural language data (wikipedia).\n",
    "\n",
    "This rapidly improving area of artificial intelligence covers tasks such as speech recognition, natural-language understanding, and natural language generation.\n",
    "\n",
    "In the following projects, we're going to be building a strong NLP foundation by practicing:\n",
    "\n",
    "- Tokenizing - Splitting sentences and words from the body of text.\n",
    "- Part of Speech tagging\n",
    "- Chunking\n",
    "\n",
    "This foundation will open the door for machine learning in conjunction with NLP. We will cover:\n",
    "\n",
    "- Machine learning in NLP\n",
    "- How to tie in Scikit-learn (sklearn) with NLTK\n",
    "- Training classifiers with a datasets (Next Project)\n",
    "\n",
    "Let's dive right in! We are going to be using the Natural Language Toolkit (NLTK) which is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required packages\n",
    "Mentioned before, it is required to import nltk package. But not only install the package itself, we need to import nltk-related packages. In that case, we just use `nltk.download()` to download required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, you may see some GUI form to download some packages. The efficient way to process NLP is selecting \"popular\" option. Then it will download and install required packages and Corpora.\n",
    "\n",
    "![nltk_download](image/nltk_download.png)\n",
    "\n",
    "We need more corporas for this post. Choose the next menu in Corpora, and install following things,\n",
    "\n",
    "- `state_union`\n",
    "- `udhr2`\n",
    "- `udhr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "Before beginning, Some words will not be familiar with us like corpus, Lexicon, and Token.\n",
    "**Corpus** is the body of text. It is singular. **Corpora** is the plural of this. **Lexicon** is the set of words and its meanings. And **Token** means each \"entity\" that is a part of whatever was split up based on specific rules. For example, We can tokenize the word based on stem, or space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "NLTK: 3.4.5\n",
      "Scikit-learn: 0.22.1\n"
     ]
    }
   ],
   "source": [
    "print('Python: {}'.format(sys.version))\n",
    "print('NLTK: {}'.format(nltk.__version__))\n",
    "print('Scikit-learn: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "When using Natural Language Processing, our goal is to perform some analysis or processing so that a computer can respond to text appropriately.\n",
    "\n",
    "The process of converting data to something a computer can understand is referred to as \"pre-processing.\" One of the major forms of pre-processing is going to be filtering out useless data. In natural language processing, useless words (data), are referred to as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"Hello students, how are you doing today? The olympics are inspiring, and Python is awesome. You look nice today.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to tokenize this sentence,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello students, how are you doing today?',\n",
       " 'The olympics are inspiring, and Python is awesome.',\n",
       " 'You look nice today.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see 3 sentence by tokenizing. Maybe we guess that it is tokenized by the Capital letter. \n",
    "\n",
    "Next, if you want the word that containing this sentense,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'students',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'today',\n",
       " '?',\n",
       " 'The',\n",
       " 'olympics',\n",
       " 'are',\n",
       " 'inspiring',\n",
       " ',',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'You',\n",
       " 'look',\n",
       " 'nice',\n",
       " 'today',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see almost all words in sentence is tokenized, but some specific characters are also contained like \",\", \"?\", \".\". These are called **puncutation**. Of course, these are important to understand the intension of sentence. But we'll cover it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words\n",
    "When using Natural Language Processing, our goal is to perform some analysis or processing so that a computer can respond to text appropriately.\n",
    "\n",
    "The process of converting data to something a computer can understand is referred to as \"pre-processing.\" One of the major forms of pre-processing is going to be filtering out useless data. In natural language processing, useless words (data), are referred to as **stop words**. Of course, it would be different in each language, in this post we will use english stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentioned before, it maybe important to understand the intension. But most of time, words in stopwords appears multiple times and it will be hard to understand the intension of sentence from computer side. So it is helpful to remove these words in advance. See what is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'some', 'sample', 'text', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'text', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"This is some sample text, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sent = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming, which attempts to normalize sentences, is another preprocessing step that we can perform. In the english language, different variations of words and sentences often having the same meaning. Stemming is a way to account for these variations; furthermore, it will help us shorten the sentences and shorten our lookup. For example, consider the following sentence:\n",
    "\n",
    "- I was taking a ride on my horse.\n",
    "- I was riding my horse.\n",
    "\n",
    "These sentences mean the same thing, as noted by the same tense (`-ing`) in each sentence; however, that isn't intuitively understood by the computer. To account for all the variations of words in the english language, we can use the `Porter` stemmer, which has been around since 1979. You can see the details in this [pages](https://tartarus.org/martin/PorterStemmer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride\n",
      "ride\n",
      "rider\n",
      "ride\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_words = ['ride', 'riding', 'rider', 'rides']\n",
    "\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we can apply this in token, so we can analyze which words appears occasionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when\n",
      "rider\n",
      "are\n",
      "ride\n",
      "their\n",
      "hors\n",
      ",\n",
      "they\n",
      "often\n",
      "think\n",
      "of\n",
      "how\n",
      "cowboy\n",
      "rode\n",
      "hors\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "text = \"When riders are riding their horses, they often think of how cowboys rode horses.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging (POS)\n",
    "Part of speech tagging means labeling words as nouns, verbs, adjectives, etc. Even better, NLTK can handle tenses! While we're at it, we are also going to import a new sentence tokenizer (`PunktSentenceTokenizer`). This tokenizer is capable of unsupervised learning, so it can be trained on any body of text.\n",
    "\n",
    "In this section, we will use pre-downloaded \"Universal declaration of human rights\" (`udhr` for short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Declaration of Human Rights\n",
      "Preamble\n",
      "Whereas recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world, \n",
      "\n",
      "Whereas disregard and contempt for human rights have resulted in barbarous acts which have outraged the conscience of mankind, and the advent of a world in which human beings shall enjoy freedom of speech and belief and freedom from fear and want has been proclaimed as the highest aspiration of the common people, \n",
      "\n",
      "Whereas it is essential, if man is not to be compelled to have recourse, as a last resort, to rebellion against tyranny and oppression, that human rights should be protected by the rule of law, \n",
      "\n",
      "Whereas it is essential to promote the development of friendly relations between nations, \n",
      "\n",
      "Whereas the peoples of the United Nations have in the Charter reaffirmed their faith in fundamental human rights, in the dignity and worth of the human person and in the equal rights of men and women and have determined to promote social progress and better standards of life in larger freedom, \n",
      "\n",
      "Whereas Member States have pledged themselves to achieve, in cooperation with the United Nations, the promotion of universal respect for and observance of human rights and fundamental freedoms, \n",
      "\n",
      "Whereas a common understanding of these rights and freedoms is of the greatest importance for the full realization of this pledge, \n",
      "\n",
      "Now, therefore, \n",
      "\n",
      "The General Assembly, \n",
      "\n",
      "Proclaims this Universal Declaration of Human Rights as a common standard of achievement for all peoples and all nations, to the end that every individual and every organ of society, keeping this Declaration constantly in mind, shall strive by teaching and education to promote respect for these rights and freedoms and by progressive measures, national and international, to secure their universal and effective recognition and observance, both among the peoples of Member States themselves and among the peoples of territories under their jurisdiction. \n",
      "\n",
      "Article 1 \n",
      "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
      "\n",
      "Article 2 \n",
      "Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "Article 3 \n",
      "Everyone has the right to life, liberty and security of person. \n",
      "\n",
      "Article 4 \n",
      "No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms. \n",
      "\n",
      "Article 5 \n",
      "No one shall be subjected to torture or to cruel, inhuman or degrading treatment or punishment. \n",
      "\n",
      "Article 6 \n",
      "Everyone has the right to recognition everywhere as a person before the law. \n",
      "\n",
      "Article 7 \n",
      "All are equal before the law and are entitled without any discrimination to equal protection of the law. All are entitled to equal protection against any discrimination in violation of this Declaration and against any incitement to such discrimination. \n",
      "\n",
      "Article 8 \n",
      "Everyone has the right to an effective remedy by the competent national tribunals for acts violating the fundamental rights granted him by the constitution or by law. \n",
      "\n",
      "Article 9 \n",
      "No one shall be subjected to arbitrary arrest, detention or exile. \n",
      "\n",
      "Article 10 \n",
      "Everyone is entitled in full equality to a fair and public hearing by an independent and impartial tribunal, in the determination of his rights and obligations and of any criminal charge against him. \n",
      "\n",
      "Article 11 \n",
      "Everyone charged with a penal offence has the right to be presumed innocent until proved guilty according to law in a public trial at which he has had all the guarantees necessary for his defence. \n",
      "No one shall be held guilty of any penal offence on account of any act or omission which did not constitute a penal offence, under national or international law, at the time when it was committed. Nor shall a heavier penalty be imposed than the one that was applicable at the time the penal offence was committed. \n",
      "Article 12 \n",
      "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honour and reputation. Everyone has the right to the protection of the law against such interference or attacks. \n",
      "\n",
      "Article 13 \n",
      "Everyone has the right to freedom of movement and residence within the borders of each State. \n",
      "Everyone has the right to leave any country, including his own, and to return to his country. \n",
      "Article 14 \n",
      "Everyone has the right to seek and to enjoy in other countries asylum from persecution. \n",
      "This right may not be invoked in the case of prosecutions genuinely arising from non-political crimes or from acts contrary to the purposes and principles of the United Nations. \n",
      "Article 15 \n",
      "Everyone has the right to a nationality. \n",
      "No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality. \n",
      "Article 16 \n",
      "Men and women of full age, without any limitation due to race, nationality or religion, have the right to marry and to found a family. They are entitled to equal rights as to marriage, during marriage and at its dissolution. \n",
      "Marriage shall be entered into only with the free and full consent of the intending spouses. \n",
      "The family is the natural and fundamental group unit of society and is entitled to protection by society and the State. \n",
      "Article 17 \n",
      "Everyone has the right to own property alone as well as in association with others. \n",
      "No one shall be arbitrarily deprived of his property. \n",
      "Article 18 \n",
      "Everyone has the right to freedom of thought, conscience and religion; this right includes freedom to change his religion or belief, and freedom, either alone or in community with others and in public or private, to manifest his religion or belief in teaching, practice, worship and observance. \n",
      "\n",
      "Article 19 \n",
      "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers. \n",
      "\n",
      "Article 20 \n",
      "Everyone has the right to freedom of peaceful assembly and association. \n",
      "No one may be compelled to belong to an association. \n",
      "Article 21 \n",
      "Everyone has the right to take part in the government of his country, directly or through freely chosen representatives. \n",
      "Everyone has the right to equal access to public service in his country. \n",
      "The will of the people shall be the basis of the authority of government; this will shall be expressed in periodic and genuine elections which shall be by universal and equal suffrage and shall be held by secret vote or by equivalent free voting procedures. \n",
      "Article 22 \n",
      "Everyone, as a member of society, has the right to social security and is entitled to realization, through national effort and international co-operation and in accordance with the organization and resources of each State, of the economic, social and cultural rights indispensable for his dignity and the free development of his personality. \n",
      "\n",
      "Article 23 \n",
      "Everyone has the right to work, to free choice of employment, to just and favourable conditions of work and to protection against unemployment. \n",
      "Everyone, without any discrimination, has the right to equal pay for equal work. \n",
      "Everyone who works has the right to just and favourable remuneration ensuring for himself and his family an existence worthy of human dignity, and supplemented, if necessary, by other means of social protection. \n",
      "Everyone has the right to form and to join trade unions for the protection of his interests. \n",
      "Article 24 \n",
      "Everyone has the right to rest and leisure, including reasonable limitation of working hours and periodic holidays with pay. \n",
      "\n",
      "Article 25 \n",
      "Everyone has the right to a standard of living adequate for the health and well-being of himself and of his family, including food, clothing, housing and medical care and necessary social services, and the right to security in the event of unemployment, sickness, disability, widowhood, old age or other lack of livelihood in circumstances beyond his control. \n",
      "Motherhood and childhood are entitled to special care and assistance. All children, whether born in or out of wedlock, shall enjoy the same social protection. \n",
      "Article 26 \n",
      "Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit. \n",
      "Education shall be directed to the full development of the human personality and to the strengthening of respect for human rights and fundamental freedoms. It shall promote understanding, tolerance and friendship among all nations, racial or religious groups, and shall further the activities of the United Nations for the maintenance of peace. \n",
      "Parents have a prior right to choose the kind of education that shall be given to their children. \n",
      "Article 27 \n",
      "Everyone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits. \n",
      "Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author. \n",
      "Article 28 \n",
      "Everyone is entitled to a social and international order in which the rights and freedoms set forth in this Declaration can be fully realized. \n",
      "\n",
      "Article 29 \n",
      "Everyone has duties to the community in which alone th\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "print(udhr.raw('English-Latin1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will also import some corpus examples, - George Bush's 2005 and 2006 state of the union addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "February 2, 2005\n",
      "\n",
      "\n",
      "9:10 P.M. EST \n",
      "\n",
      "THE PRESIDENT: Mr. Speaker, Vice President Cheney, members of Congress, fellow citizens: \n",
      "\n",
      "As a new Congress gathers, all of us in the elected branches of government share a great privilege: We've been placed in office by the votes of the people we serve. And tonight that is a privilege we share with newly-elected leaders of Afghanistan, the Palestinian Territories, Ukraine, and a free and sovereign Iraq. (Applause.) \n",
      "\n",
      "Two weeks ago, I stood on the steps of this Capitol and renewed the commitment of our nation to the guiding ideal of liberty for all. This evening I will set forth policies to advance that ideal at home and around the world. \n",
      "\n",
      "Tonight, with a healthy, growing economy, with more Americans going back to work, with our nation an active force for good in the world -- the state of our union is confident and strong. (Applause.) \n",
      "\n",
      "Our generati\n"
     ]
    }
   ],
   "source": [
    "print(train_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some text, we can train the PunktSentenceTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokens = custom_sent_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"PRESIDENT GEORGE W. BUSH'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS ON THE STATE OF THE UNION\\n \\nJanuary 31, 2006\\n\\nTHE PRESIDENT: Thank you all.\",\n",
       " 'Mr. Speaker, Vice President Cheney, members of Congress, members of the Supreme Court and diplomatic corps, distinguished guests, and fellow citizens: Today our nation lost a beloved, graceful, courageous woman who called America to its founding ideals and carried on a noble dream.',\n",
       " 'Tonight we are comforted by the hope of a glad reunion with the husband who was taken so long ago, and we are grateful for the good life of Coretta Scott King.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush reacts to applause during his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " \"White House photo by Eric DraperEvery time I'm invited to this rostrum, I'm humbled by the privilege, and mindful of the history we've seen together.\",\n",
       " 'We have gathered under this Capitol dome in moments of national mourning and national achievement.',\n",
       " 'We have served America through one of the most consequential periods of our history -- and it has been my honor to serve with you.',\n",
       " 'In a system of two parties, two chambers, and two elected branches, there will always be differences and debate.',\n",
       " 'But even tough debates can be conducted in a civil tone, and our differences cannot be allowed to harden into anger.',\n",
       " 'To confront the great issues before us, we must act in a spirit of goodwill and respect for one another -- and I will do my part.',\n",
       " 'Tonight the state of our Union is strong -- and together we will make it stronger.',\n",
       " '(Applause.)',\n",
       " 'In this decisive year, you and I will make choices that determine both the future and the character of our country.',\n",
       " 'We will choose to act confidently in pursuing the enemies of freedom -- or retreat from our duties in the hope of an easier life.',\n",
       " 'We will choose to build our prosperity by leading the world economy -- or shut ourselves off from trade and opportunity.',\n",
       " 'In a complex and challenging time, the road of isolationism and protectionism may seem broad and inviting -- yet it ends in danger and decline.',\n",
       " 'The only way to protect our people, the only way to secure the peace, the only way to control our destiny is by our leadership -- so the United States of America will continue to lead.',\n",
       " '(Applause.)',\n",
       " 'Abroad, our nation is committed to an historic, long-term goal -- we seek the end of tyranny in our world.',\n",
       " 'Some dismiss that goal as misguided idealism.',\n",
       " 'In reality, the future security of America depends on it.',\n",
       " 'On September the 11th, 2001, we found that problems originating in a failed and oppressive state 7,000 miles away could bring murder and destruction to our country.',\n",
       " 'Dictatorships shelter terrorists, and feed resentment and radicalism, and seek weapons of mass destruction.',\n",
       " 'Democracies replace resentment with hope, respect the rights of their citizens and their neighbors, and join the fight against terror.',\n",
       " \"Every step toward freedom in the world makes our country safer -- so we will act boldly in freedom's cause.\",\n",
       " '(Applause.)',\n",
       " 'Far from being a hopeless dream, the advance of freedom is the great story of our time.',\n",
       " 'In 1945, there were about two dozen lonely democracies in the world.',\n",
       " 'Today, there are 122.',\n",
       " \"And we're writing a new chapter in the story of self-government -- with women lining up to vote in Afghanistan, and millions of Iraqis marking their liberty with purple ink, and men and women from Lebanon to Egypt debating the rights of individuals and the necessity of freedom.\",\n",
       " 'At the start of 2006, more than half the people of our world live in democratic nations.',\n",
       " 'And we do not forget the other half -- in places like Syria and Burma, Zimbabwe, North Korea, and Iran -- because the demands of justice, and the peace of this world, require their freedom, as well.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush delivers his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " 'White House photo by Eric Draper No one can deny the success of freedom, but some men rage and fight against it.',\n",
       " 'And one of the main sources of reaction and opposition is radical Islam -- the perversion by a few of a noble faith into an ideology of terror and death.',\n",
       " 'Terrorists like bin Laden are serious about mass murder -- and all of us must take their declared intentions seriously.',\n",
       " 'They seek to impose a heartless system of totalitarian control throughout the Middle East, and arm themselves with weapons of mass murder.',\n",
       " 'Their aim is to seize power in Iraq, and use it as a safe haven to launch attacks against America and the world.',\n",
       " 'Lacking the military strength to challenge us directly, the terrorists have chosen the weapon of fear.',\n",
       " 'When they murder children at a school in Beslan, or blow up commuters in London, or behead a bound captive, the terrorists hope these horrors will break our will, allowing the violent to inherit the Earth.',\n",
       " 'But they have miscalculated: We love our freedom, and we will fight to keep it.',\n",
       " '(Applause.)',\n",
       " 'In a time of testing, we cannot find security by abandoning our commitments and retreating within our borders.',\n",
       " 'If we were to leave these vicious attackers alone, they would not leave us alone.',\n",
       " 'They would simply move the battlefield to our own shores.',\n",
       " 'There is no peace in retreat.',\n",
       " 'And there is no honor in retreat.',\n",
       " 'By allowing radical Islam to work its will -- by leaving an assaulted world to fend for itself -- we would signal to all that we no longer believe in our own ideals, or even in our own courage.',\n",
       " 'But our enemies and our friends can be certain: The United States will not retreat from the world, and we will never surrender to evil.',\n",
       " '(Applause.)',\n",
       " 'America rejects the false comfort of isolationism.',\n",
       " 'We are the nation that saved liberty in Europe, and liberated death camps, and helped raise up democracies, and faced down an evil empire.',\n",
       " 'Once again, we accept the call of history to deliver the oppressed and move this world toward peace.',\n",
       " 'We remain on the offensive against terror networks.',\n",
       " 'We have killed or captured many of their leaders -- and for the others, their day will come.',\n",
       " 'President George W. Bush greets members of Congress after his State of the Union Address at the Capitol, Tuesday, Jan.',\n",
       " '31, 2006.',\n",
       " 'White House photo by Eric Draper We remain on the offensive in Afghanistan, where a fine President and a National Assembly are fighting terror while building the institutions of a new democracy.',\n",
       " \"We're on the offensive in Iraq, with a clear plan for victory.\",\n",
       " \"First, we're helping Iraqis build an inclusive government, so that old resentments will be eased and the insurgency will be marginalized.\",\n",
       " \"Second, we're continuing reconstruction efforts, and helping the Iraqi government to fight corruption and build a modern economy, so all Iraqis can experience the benefits of freedom.\",\n",
       " \"And, third, we're striking terrorist targets while we train Iraqi forces that are increasingly capable of defeating the enemy.\",\n",
       " 'Iraqis are showing their courage every day, and we are proud to be their allies in the cause of freedom.',\n",
       " '(Applause.)',\n",
       " 'Our work in Iraq is difficult because our enemy is brutal.',\n",
       " 'But that brutality has not stopped the dramatic progress of a new democracy.',\n",
       " 'In less than three years, the nation has gone from dictatorship to liberation, to sovereignty, to a constitution, to national elections.',\n",
       " 'At the same time, our coalition has been relentless in shutting off terrorist infiltration, clearing out insurgent strongholds, and turning over territory to Iraqi security forces.',\n",
       " 'I am confident in our plan for victory; I am confident in the will of the Iraqi people; I am confident in the skill and spirit of our military.',\n",
       " 'Fellow citizens, we are in this fight to win, and we are winning.',\n",
       " '(Applause.)',\n",
       " 'The road of victory is the road that will take our troops home.',\n",
       " 'As we make progress on the ground, and Iraqi forces increasingly take the lead, we should be able to further decrease our troop levels -- but those decisions will be made by our military commanders, not by politicians in Washington, D.C.',\n",
       " '(Applause.)',\n",
       " 'Our coalition has learned from our experience in Iraq.',\n",
       " \"We've adjusted our military tactics and changed our approach to reconstruction.\",\n",
       " 'Along the way, we have benefitted from responsible criticism and counsel offered by members of Congress of both parties.',\n",
       " 'In the coming year, I will continue to reach out and seek your good advice.',\n",
       " 'Yet, there is a difference between responsible criticism that aims for success, and defeatism that refuses to acknowledge anything but failure.',\n",
       " '(Applause.)',\n",
       " 'Hindsight alone is not wisdom, and second-guessing is not a strategy.',\n",
       " '(Applause.)',\n",
       " 'With so much in the balance, those of us in public office have a duty to speak with candor.',\n",
       " 'A sudden withdrawal of our forces from Iraq would abandon our Iraqi allies to death and prison, would put men like bin Laden and Zarqawi in charge of a strategic country, and show that a pledge from America means little.',\n",
       " 'Members of Congress, however we feel about the decisions and debates of the past, our nation has only one option: We must keep our word, defeat our enemies, and stand behind the American military in this vital mission.',\n",
       " '(Applause.)',\n",
       " 'Laura Bush is applauded as she is introduced Tuesday evening, Jan.',\n",
       " '31, 2006 during the State of the Union Address at United States Capitol in Washington.',\n",
       " 'White House photo by Eric Draper Our men and women in uniform are making sacrifices -- and showing a sense of duty stronger than all fear.',\n",
       " \"They know what it's like to fight house to house in a maze of streets, to wear heavy gear in the desert heat, to see a comrade killed by a roadside bomb.\",\n",
       " 'And those who know the costs also know the stakes.',\n",
       " 'Marine Staff Sergeant Dan Clay was killed last month fighting in Fallujah.',\n",
       " 'He left behind a letter to his family, but his words could just as well be addressed to every American.',\n",
       " 'Here is what Dan wrote: \"I know what honor is.',\n",
       " '... It has been an honor to protect and serve all of you.',\n",
       " 'I faced death with the secure knowledge that you would not have to....',\n",
       " 'Never falter!',\n",
       " 'Don\\'t hesitate to honor and support those of us who have the honor of protecting that which is worth protecting.\"',\n",
       " \"Staff Sergeant Dan Clay's wife, Lisa, and his mom and dad, Sara Jo and Bud, are with us this evening.\",\n",
       " 'Welcome.',\n",
       " '(Applause.)',\n",
       " 'Our nation is grateful to the fallen, who live in the memory of our country.',\n",
       " \"We're grateful to all who volunteer to wear our nation's uniform -- and as we honor our brave troops, let us never forget the sacrifices of America's military families.\",\n",
       " '(Applause.)',\n",
       " 'Our offensive against terror involves more than military action.',\n",
       " 'Ultimately, the only way to defeat the terrorists is to defeat their dark vision of hatred and fear by offering the hopeful alternative of political freedom and peaceful change.',\n",
       " 'So the United States of America supports democratic reform across the broader Middle East.',\n",
       " 'Elections are vital, but they are only the beginning.',\n",
       " 'Raising up a democracy requires the rule of law, and protection of minorities, and strong, accountable institutions that last longer than a single vote.',\n",
       " 'The great people of Egypt have voted in a multi-party presidential election -- and now their government should open paths of peaceful opposition that will reduce the appeal of radicalism.',\n",
       " 'The Palestinian people have voted in elections.',\n",
       " 'And now the leaders of Hamas must recognize Israel, disarm, reject terrorism, and work for lasting peace.',\n",
       " '(Applause.)',\n",
       " 'Saudi Arabia has taken the first steps of reform -- now it can offer its people a better future by pressing forward with those efforts.',\n",
       " 'Democracies in the Middle East will not look like our own, because they will reflect the traditions of their own citizens.',\n",
       " 'Yet liberty is the future of every nation in the Middle East, because liberty is the right and hope of all humanity.',\n",
       " '(Applause.)',\n",
       " 'President George W. Bush waves toward the upper visitors gallery of the House Chamber following his State of the Union remarks Tuesday, Jan.',\n",
       " '31, 2006 at the United States Capitol.',\n",
       " 'White House photo by Eric Draper The same is true of Iran, a nation now held hostage by a small clerical elite that is isolating and repressing its people.',\n",
       " 'The regime in that country sponsors terrorists in the Palestinian territories and in Lebanon -- and that must come to an end.',\n",
       " '(Applause.)',\n",
       " 'The Iranian government is defying the world with its nuclear ambitions, and the nations of the world must not permit the Iranian regime to gain nuclear weapons.',\n",
       " '(Applause.)',\n",
       " 'America will continue to rally the world to confront these threats.',\n",
       " 'Tonight, let me speak directly to the citizens of Iran: America respects you, and we respect your country.',\n",
       " 'We respect your right to choose your own future and win your own freedom.',\n",
       " 'And our nation hopes one day to be the closest of friends with a free and democratic Iran.',\n",
       " '(Applause.)',\n",
       " 'To overcome dangers in our world, we must also take the offensive by encouraging economic progress, and fighting disease, and spreading hope in hopeless lands.',\n",
       " 'Isolationism would not only tie our hands in fighting enemies, it would keep us from helping our friends in desperate need.',\n",
       " 'We show compassion abroad because Americans believe in the God-given dignity and worth of a villager with HIV/AIDS, or an infant with malaria, or a refugee fleeing genocide, or a young girl sold into slavery.',\n",
       " 'We also show compassion abroad because regions overwhelmed by poverty, corruption, and despair are sources of terrorism, and organized crime, and human trafficking, and the drug trade.',\n",
       " 'In recent years, you and I have taken unprecedented action to fight AIDS and malaria, expand the education of girls, and reward developing nations that are moving forward with economic and political reform.',\n",
       " 'For people everywhere, the United States is a partner for a better life.',\n",
       " 'Short-changing these efforts would increase the suffering and chaos of our world, undercut our long-term security, and dull the conscience of our country.',\n",
       " 'I urge members of Congress to serve the interests of America by showing the compassion of America.',\n",
       " 'Our country must also remain on the offensive against terrorism here at home.',\n",
       " 'The enemy has not lost the desire or capability to attack us.',\n",
       " 'Fortunately, this nation has superb professionals in law enforcement, intelligence, the military, and homeland security.',\n",
       " 'These men and women are dedicating their lives, protecting us all, and they deserve our support and our thanks.',\n",
       " '(Applause.)',\n",
       " 'They also deserve the same tools they already use to fight drug trafficking and organized crime -- so I ask you to reauthorize the Patriot Act.',\n",
       " '(Applause.)',\n",
       " 'It is said that prior to the attacks of September the 11th, our government failed to connect the dots of the conspiracy.',\n",
       " 'We now know that two of the hijackers in the United States placed telephone calls to al Qaeda operatives overseas.',\n",
       " 'But we did not know about their plans until it was too late.',\n",
       " 'So to prevent another attack -- based on authority given to me by the Constitution and by statute -- I have authorized a terrorist surveillance program to aggressively pursue the international communications of suspected al Qaeda operatives and affiliates to and from America.',\n",
       " 'Previous Presidents have used the same constitutional authority I have, and federal courts have approved the use of that authority.',\n",
       " 'Appropriate members of Congress have been kept informed.',\n",
       " 'The terrorist surveillance program has helped prevent terrorist attacks.',\n",
       " 'It remains essential to the security of America.',\n",
       " 'If there are people inside our country who are talking with al Qaeda, we want to know about it, because we will not sit back and wait to be hit again.',\n",
       " '(Applause.)',\n",
       " 'In all these areas -- from the disruption of terror networks, to victory in Iraq, to the spread of freedom and hope in troubled regions -- we need the support of our friends and allies.',\n",
       " 'To draw that support, we must always be clear in our principles and willing to act.',\n",
       " 'The only alternative to American leadership is a dramatically more dangerous and anxious world.',\n",
       " 'Yet we also choose to lead because it is a privilege to serve the values that gave us birth.',\n",
       " 'American leaders -- from Roosevelt to Truman to Kennedy to Reagan -- rejected isolation and retreat, because they knew that America is always more secure when freedom is on the march.',\n",
       " 'Our own generation is in a long war against a determined enemy -- a war that will be fought by Presidents of both parties, who will need steady bipartisan support from the Congress.',\n",
       " 'And tonight I ask for yours.',\n",
       " 'Together, let us protect our country, support the men and women who defend us, and lead this world toward freedom.',\n",
       " '(Applause.)',\n",
       " 'Here at home, America also has a great opportunity: We will build the prosperity of our country by strengthening our economic leadership in the world.',\n",
       " 'Our economy is healthy and vigorous, and growing faster than other major industrialized nations.',\n",
       " 'In the last two-and-a-half years, America has created 4.6 million new jobs -- more than Japan and the European Union combined.',\n",
       " '(Applause.)',\n",
       " 'Even in the face of higher energy prices and natural disasters, the American people have turned in an economic performance that is the envy of the world.',\n",
       " 'The American economy is preeminent, but we cannot afford to be complacent.',\n",
       " \"In a dynamic world economy, we are seeing new competitors, like China and India, and this creates uncertainty, which makes it easier to feed people's fears.\",\n",
       " \"So we're seeing some old temptations return.\",\n",
       " 'Protectionists want to escape competition, pretending that we can keep our high standard of living while walling off our economy.',\n",
       " 'Others say that the government needs to take a larger role in directing the economy, centralizing more power in Washington and increasing taxes.',\n",
       " 'We hear claims that immigrants are somehow bad for the economy -- even though this economy could not function without them.',\n",
       " '(Applause.)',\n",
       " 'All these are forms of economic retreat, and they lead in the same direction -- toward a stagnant and second-rate economy.',\n",
       " 'Tonight I will set out a better path: an agenda for a nation that competes with confidence; an agenda that will raise standards of living and generate new jobs.',\n",
       " 'Americans should not fear our economic future, because we intend to shape it.',\n",
       " 'Keeping America competitive begins with keeping our economy growing.',\n",
       " 'And our economy grows when Americans have more of their own money to spend, save, and invest.',\n",
       " 'In the last five years, the tax relief you passed has left $880 billion in the hands of American workers, investors, small businesses, and families -- and they have used it to help produce more than four years of uninterrupted economic growth.',\n",
       " '(Applause.)',\n",
       " 'Yet the tax relief is set to expire in the next few years.',\n",
       " 'If we do nothing, American families will face a massive tax increase they do not expect and will not welcome.',\n",
       " 'Because America needs more than a temporary expansion, we need more than temporary tax relief.',\n",
       " 'I urge the Congress to act responsibly, and make the tax cuts permanent.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires us to be good stewards of tax dollars.',\n",
       " \"Every year of my presidency, we've reduced the growth of non-security discretionary spending, and last year you passed bills that cut this spending.\",\n",
       " 'This year my budget will cut it again, and reduce or eliminate more than 140 programs that are performing poorly or not fulfilling essential priorities.',\n",
       " 'By passing these reforms, we will save the American taxpayer another $14 billion next year, and stay on track to cut the deficit in half by 2009.',\n",
       " '(Applause.)',\n",
       " 'I am pleased that members of Congress are working on earmark reform, because the federal budget has too many special interest projects.',\n",
       " '(Applause.)',\n",
       " 'And we can tackle this problem together, if you pass the line-item veto.',\n",
       " '(Applause.)',\n",
       " 'We must also confront the larger challenge of mandatory spending, or entitlements.',\n",
       " \"This year, the first of about 78 million baby boomers turn 60, including two of my Dad's favorite people -- me and President Clinton.\",\n",
       " '(Laughter.)',\n",
       " 'This milestone is more than a personal crisis -- (laughter) -- it is a national challenge.',\n",
       " 'The retirement of the baby boom generation will put unprecedented strains on the federal government.',\n",
       " 'By 2030, spending for Social Security, Medicare and Medicaid alone will be almost 60 percent of the entire federal budget.',\n",
       " 'And that will present future Congresses with impossible choices -- staggering tax increases, immense deficits, or deep cuts in every category of spending.',\n",
       " 'Congress did not act last year on my proposal to save Social Security -- (applause) -- yet the rising cost of entitlements is a problem that is not going away.',\n",
       " '(Applause.)',\n",
       " 'And every year we fail to act, the situation gets worse.',\n",
       " 'So tonight, I ask you to join me in creating a commission to examine the full impact of baby boom retirements on Social Security, Medicare, and Medicaid.',\n",
       " 'This commission should include members of Congress of both parties, and offer bipartisan solutions.',\n",
       " 'We need to put aside partisan politics and work together and get this problem solved.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires us to open more markets for all that Americans make and grow.',\n",
       " 'One out of every five factory jobs in America is related to global trade, and we want people everywhere to buy American.',\n",
       " 'With open markets and a level playing field, no one can out-produce or out-compete the American worker.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires an immigration system that upholds our laws, reflects our values, and serves the interests of our economy.',\n",
       " 'Our nation needs orderly and secure borders.',\n",
       " '(Applause.)',\n",
       " 'To meet this goal, we must have stronger immigration enforcement and border protection.',\n",
       " '(Applause.)',\n",
       " 'And we must have a rational, humane guest worker program that rejects amnesty, allows temporary jobs for people who seek them legally, and reduces smuggling and crime at the border.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires affordable health care.',\n",
       " '(Applause.)',\n",
       " 'Our government has a responsibility to provide health care for the poor and the elderly, and we are meeting that responsibility.',\n",
       " '(Applause.)',\n",
       " 'For all Americans -- for all Americans, we must confront the rising cost of care, strengthen the doctor-patient relationship, and help people afford the insurance coverage they need.',\n",
       " '(Applause.)',\n",
       " 'We will make wider use of electronic records and other health information technology, to help control costs and reduce dangerous medical errors.',\n",
       " 'We will strengthen health savings accounts -- making sure individuals and small business employees can buy insurance with the same advantages that people working for big businesses now get.',\n",
       " '(Applause.)',\n",
       " 'We will do more to make this coverage portable, so workers can switch jobs without having to worry about losing their health insurance.',\n",
       " '(Applause.)',\n",
       " 'And because lawsuits are driving many good doctors out of practice -- leaving women in nearly 1,500 American counties without a single OB/GYN -- I ask the Congress to pass medical liability reform this year.',\n",
       " '(Applause.)',\n",
       " 'Keeping America competitive requires affordable energy.',\n",
       " 'And here we have a serious problem: America is addicted to oil, which is often imported from unstable parts of the world.',\n",
       " 'The best way to break this addiction is through technology.',\n",
       " 'Since 2001, we have spent nearly $10 billion to develop cleaner, cheaper, and more reliable alternative energy sources -- and we are on the threshold of incredible advances.',\n",
       " 'So tonight, I announce the Advanced Energy Initiative -- a 22-percent increase in clean-energy research -- at the Department of Energy, to push for breakthroughs in two vital areas.',\n",
       " 'To change how we power our homes and offices, we will invest more in zero-emission coal-fired plants, revolutionary solar and wind technologies, and clean, safe nuclear energy.',\n",
       " '(Applause.)',\n",
       " 'We must also change how we power our automobiles.',\n",
       " 'We will increase our research in better batteries for hybrid and electric cars, and in pollution-free cars that run on hydrogen.',\n",
       " \"We'll also fund additional research in cutting-edge methods of producing ethanol, not just from corn, but from wood chips and stalks, or switch grass.\",\n",
       " 'Our goal is to make this new kind of ethanol practical and competitive within six years.',\n",
       " '(Applause.)',\n",
       " 'Breakthroughs on this and other new technologies will help us reach another great goal: to replace more than 75 percent of our oil imports from the Middle East by 2025.',\n",
       " '(Applause.)',\n",
       " 'By applying the talent and technology of America, this country can dramatically improve our environment, move beyond a petroleum-based economy, and make our dependence on Middle Eastern oil a thing of the past.',\n",
       " '(Applause.)',\n",
       " 'And to keep America competitive, one commitment is necessary above all: We must continue to lead the world in human talent and creativity.',\n",
       " \"Our greatest advantage in the world has always been our educated, hardworking, ambitious people -- and we're going to keep that edge.\",\n",
       " \"Tonight I announce an American Competitiveness Initiative, to encourage innovation throughout our economy, and to give our nation's children a firm grounding in math and science.\",\n",
       " '(Applause.)',\n",
       " 'First, I propose to double the federal commitment to the most critical basic research programs in the physical sciences over the next 10 years.',\n",
       " \"This funding will support the work of America's most creative minds as they explore promising areas such as nanotechnology, supercomputing, and alternative energy sources.\",\n",
       " 'Second, I propose to make permanent the research and development tax credit -- (applause) -- to encourage bolder private-sector initiatives in technology.',\n",
       " 'With more research in both the public and private sectors, we will improve our quality of life -- and ensure that America will lead the world in opportunity and innovation for decades to come.',\n",
       " '(Applause.)',\n",
       " 'Third, we need to encourage children to take more math and science, and to make sure those courses are rigorous enough to compete with other nations.',\n",
       " \"We've made a good start in the early grades with the No Child Left Behind Act, which is raising standards and lifting test scores across our country.\",\n",
       " 'Tonight I propose to train 70,000 high school teachers to lead advanced-placement courses in math and science, bring 30,000 math and science professionals to teach in classrooms, and give early help to students who struggle with math, so they have a better chance at good, high-wage jobs.',\n",
       " \"If we ensure that America's children succeed in life, they will ensure that America succeeds in the world.\",\n",
       " '(Applause.)',\n",
       " 'Preparing our nation to compete in the world is a goal that all of us can share.',\n",
       " 'I urge you to support the American Competitiveness Initiative, and together we will show the world what the American people can achieve.',\n",
       " 'America is a great force for freedom and prosperity.',\n",
       " 'Yet our greatness is not measured in power or luxuries, but by who we are and how we treat one another.',\n",
       " 'So we strive to be a compassionate, decent, hopeful society.',\n",
       " 'In recent years, America has become a more hopeful nation.',\n",
       " 'Violent crime rates have fallen to their lowest levels since the 1970s.',\n",
       " 'Welfare cases have dropped by more than half over the past decade.',\n",
       " 'Drug use among youth is down 19 percent since 2001.',\n",
       " 'There are fewer abortions in America than at any point in the last three decades, and the number of children born to teenage mothers has been falling for a dozen years in a row.',\n",
       " '(Applause.)',\n",
       " 'These gains are evidence of a quiet transformation -- a revolution of conscience, in which a rising generation is finding that a life of personal responsibility is a life of fulfillment.',\n",
       " 'Government has played a role.',\n",
       " 'Wise policies, such as welfare reform and drug education and support for abstinence and adoption have made a difference in the character of our country.',\n",
       " 'And everyone here tonight, Democrat and Republican, has a right to be proud of this record.',\n",
       " '(Applause.)',\n",
       " 'Yet many Americans, especially parents, still have deep concerns about the direction of our culture, and the health of our most basic institutions.',\n",
       " \"They're concerned about unethical conduct by public officials, and discouraged by activist courts that try to redefine marriage.\",\n",
       " 'They worry about children in our society who need direction and love, and about fellow citizens still displaced by natural disaster, and about suffering caused by treatable diseases.',\n",
       " 'As we look at these challenges, we must never give in to the belief that America is in decline, or that our culture is doomed to unravel.',\n",
       " 'The American people know better than that.',\n",
       " 'We have proven the pessimists wrong before -- and we will do it again.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society depends on courts that deliver equal justice under the law.',\n",
       " 'The Supreme Court now has two superb new members -- new members on its bench: Chief Justice John Roberts and Justice Sam Alito.',\n",
       " '(Applause.)',\n",
       " 'I thank the Senate for confirming both of them.',\n",
       " 'I will continue to nominate men and women who understand that judges must be servants of the law, and not legislate from the bench.',\n",
       " '(Applause.)',\n",
       " 'Today marks the official retirement of a very special American.',\n",
       " \"For 24 years of faithful service to our nation, the United States is grateful to Justice Sandra Day O'Connor.\",\n",
       " '(Applause.)',\n",
       " 'A hopeful society has institutions of science and medicine that do not cut ethical corners, and that recognize the matchless value of every life.',\n",
       " 'Tonight I ask you to pass legislation to prohibit the most egregious abuses of medical research: human cloning in all its forms, creating or implanting embryos for experiments, creating human-animal hybrids, and buying, selling, or patenting human embryos.',\n",
       " 'Human life is a gift from our Creator -- and that gift should never be discarded, devalued or put up for sale.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society expects elected officials to uphold the public trust.',\n",
       " '(Applause.)',\n",
       " 'Honorable people in both parties are working on reforms to strengthen the ethical standards of Washington -- I support your efforts.',\n",
       " 'Each of us has made a pledge to be worthy of public responsibility -- and that is a pledge we must never forget, never dismiss, and never betray.',\n",
       " '(Applause.)',\n",
       " 'As we renew the promise of our institutions, let us also show the character of America in our compassion and care for one another.',\n",
       " 'A hopeful society gives special attention to children who lack direction and love.',\n",
       " \"Through the Helping America's Youth Initiative, we are encouraging caring adults to get involved in the life of a child -- and this good work is being led by our First Lady, Laura Bush.\",\n",
       " '(Applause.)',\n",
       " \"This year we will add resources to encourage young people to stay in school, so more of America's youth can raise their sights and achieve their dreams.\",\n",
       " \"A hopeful society comes to the aid of fellow citizens in times of suffering and emergency -- and stays at it until they're back on their feet.\",\n",
       " 'So far the federal government has committed $85 billion to the people of the Gulf Coast and New Orleans.',\n",
       " \"We're removing debris and repairing highways and rebuilding stronger levees.\",\n",
       " \"We're providing business loans and housing assistance.\",\n",
       " 'Yet as we meet these immediate needs, we must also address deeper challenges that existed before the storm arrived.',\n",
       " 'In New Orleans and in other places, many of our fellow citizens have felt excluded from the promise of our country.',\n",
       " 'The answer is not only temporary relief, but schools that teach every child, and job skills that bring upward mobility, and more opportunities to own a home and start a business.',\n",
       " 'As we recover from a disaster, let us also work for the day when all Americans are protected by justice, equal in hope, and rich in opportunity.',\n",
       " '(Applause.)',\n",
       " 'A hopeful society acts boldly to fight diseases like HIV/AIDS, which can be prevented, and treated, and defeated.',\n",
       " 'More than a million Americans live with HIV, and half of all AIDS cases occur among African Americans.',\n",
       " 'I ask Congress to reform and reauthorize the Ryan White Act, and provide new funding to states, so we end the waiting lists for AIDS medicines in America.',\n",
       " '(Applause.)',\n",
       " 'We will also lead a nationwide effort, working closely with African American churches and faith-based groups, to deliver rapid HIV tests to millions, end the stigma of AIDS, and come closer to the day when there are no new infections in America.',\n",
       " '(Applause.)',\n",
       " \"Fellow citizens, we've been called to leadership in a period of consequence.\",\n",
       " \"We've entered a great ideological conflict we did nothing to invite.\",\n",
       " 'We see great changes in science and commerce that will influence all our lives.',\n",
       " 'Sometimes it can seem that history is turning in a wide arc, toward an unknown shore.',\n",
       " 'Yet the destination of history is determined by human action, and every great movement of history comes to a point of choosing.',\n",
       " 'Lincoln could have accepted peace at the cost of disunity and continued slavery.',\n",
       " 'Martin Luther King could have stopped at Birmingham or at Selma, and achieved only half a victory over segregation.',\n",
       " 'The United States could have accepted the permanent division of Europe, and been complicit in the oppression of others.',\n",
       " 'Today, having come far in our own historical journey, we must decide: Will we turn back, or finish well?',\n",
       " 'Before history is written down in books, it is written in courage.',\n",
       " 'Like Americans before us, we will show that courage and we will finish well.',\n",
       " \"We will lead freedom's advance.\",\n",
       " 'We will compete and excel in the global economy.',\n",
       " 'We will renew the defining moral commitments of this land.',\n",
       " 'And so we move forward -- optimistic about our country, faithful to its cause, and confident of the victories to come.',\n",
       " 'May God bless America.',\n",
       " '(Applause.)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can tokenize each word in sentence. Now we need to tag each words with part of speech (also known as POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for t in tokens[:5]:\n",
    "            words = nltk.word_tokenize(t)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see tags are added after each words. Each tag means:\n",
    "\n",
    "- POS: Possesive ending\n",
    "- NNP: Proper noun, singular\n",
    "- IN: Preposition or subordinating conjuntion\n",
    "- NN: Noun, sigular or mass\n",
    "- RB : Adverb\n",
    "- VBP: Verb, non-3rd person sigular present\n",
    "- ...\n",
    "\n",
    "(The detailed list are found in [here](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html))\n",
    "\n",
    "Or you can download the tagsets from `nltk.download()`. (All packages -> tagsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "Now that each word has been tagged with a part of speech, we can move onto chunking, meaning that grouping the words into meaningful clusters. The main goal of chunking is to group words into \"noun phrases\", which is a noun with any associated verbs, adjectives, or adverbs.\n",
    "\n",
    "The part of speech tags that were generated in the previous step will be combined with regular expressions, such as the following:\n",
    "\n",
    "- $+$ = match 1 or more\n",
    "- $?$ = match 0 or 1 repetitions.\n",
    "- $*$ = match 0 or MORE repetitions\t  \n",
    "- $.$ = Any character except a new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokens[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            # combine the part-of-speech tag with a regular expression\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            # draw the chunks with nltk\n",
    "            chunked.draw()     \n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the chuck rule as follows:\n",
    "\n",
    "$<\\text{RB}.?>*$ = \"0 or more of any tense of adverb,\" followed by: \n",
    "\n",
    "$<\\text{VB}.?>*$ = \"0 or more of any tense of verb,\" followed by: \n",
    "\n",
    "$<\\text{NNP}>+$ = \"One or more proper nouns,\" followed by \n",
    "\n",
    "$<\\text{NN}>?$ = \"zero or one singular noun.\" \n",
    "\n",
    "See what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you can this kind of tree diagrams:\n",
    "\n",
    "![nltk_draw](image/nltk_draw.png)\n",
    "\n",
    "This diagram shows the hierarchical relationship between words and which words are grouping with some tokens.\n",
    "\n",
    "Or we can print it inline, not showing in GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokens[:10]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            # combine the part-of-speech tag with a regular expression\n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            # print the nltk tree\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
      "(Chunk ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk THE/NNP UNION/NNP January/NNP)\n",
      "(Chunk THE/NNP PRESIDENT/NNP)\n",
      "(Chunk Thank/NNP)\n",
      "(Chunk Mr./NNP Speaker/NNP)\n",
      "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
      "(Chunk Congress/NNP)\n",
      "(Chunk Supreme/NNP Court/NNP)\n",
      "(Chunk called/VBD America/NNP)\n",
      "(Chunk Coretta/NNP Scott/NNP King/NNP)\n",
      "(Chunk Applause/NNP)\n",
      "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "(Chunk State/NNP)\n",
      "(Chunk Union/NNP Address/NNP)\n",
      "(Chunk Capitol/NNP)\n",
      "(Chunk Tuesday/NNP)\n",
      "(Chunk Jan/NNP)\n",
      "(Chunk White/NNP House/NNP photo/NN)\n",
      "(Chunk Eric/NNP DraperEvery/NNP time/NN)\n",
      "(Chunk Capitol/NNP dome/NN)\n",
      "(Chunk have/VBP served/VBN America/NNP)\n"
     ]
    }
   ],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinking\n",
    "Another process in NLP is **chinking** that remove the chunks that we don't want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokens[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            # The main difference here is the }{, vs. the {}. This means we're removing \n",
    "            # from the chink one or more verbs, prepositions, determiners, or the word 'to'.\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            # print(chunked)\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "                print(subtree)\n",
    "\n",
    "            # chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP 'S/POS ADDRESS/NNP)\n",
      "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
      "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
      "(Chunk\n",
      "  THE/NNP\n",
      "  UNION/NNP\n",
      "  January/NNP\n",
      "  31/CD\n",
      "  ,/,\n",
      "  2006/CD\n",
      "  THE/NNP\n",
      "  PRESIDENT/NNP\n",
      "  :/:\n",
      "  Thank/NNP\n",
      "  you/PRP)\n",
      "(Chunk ./.)\n",
      "(Chunk\n",
      "  Mr./NNP\n",
      "  Speaker/NNP\n",
      "  ,/,\n",
      "  Vice/NNP\n",
      "  President/NNP\n",
      "  Cheney/NNP\n",
      "  ,/,\n",
      "  members/NNS)\n",
      "(Chunk Congress/NNP ,/, members/NNS)\n",
      "(Chunk\n",
      "  Supreme/NNP\n",
      "  Court/NNP\n",
      "  and/CC\n",
      "  diplomatic/JJ\n",
      "  corps/NN\n",
      "  ,/,\n",
      "  distinguished/JJ\n",
      "  guests/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  :/:)\n",
      "(Chunk our/PRP$ nation/NN)\n",
      "(Chunk ,/, graceful/JJ ,/, courageous/JJ woman/NN who/WP)\n",
      "(Chunk America/NNP)\n",
      "(Chunk its/PRP$ founding/NN ideals/NNS and/CC)\n",
      "(Chunk noble/JJ dream/NN ./.)\n",
      "(Chunk Tonight/NN we/PRP)\n",
      "(Chunk hope/NN)\n",
      "(Chunk glad/JJ reunion/NN)\n",
      "(Chunk husband/NN who/WP)\n",
      "(Chunk so/RB long/RB ago/RB ,/, and/CC we/PRP)\n",
      "(Chunk grateful/JJ)\n",
      "(Chunk good/JJ life/NN)\n",
      "(Chunk Coretta/NNP Scott/NNP King/NNP ./.)\n",
      "(Chunk (/( Applause/NNP ./. )/))\n",
      "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
      "(Chunk his/PRP$ State/NNP)\n",
      "(Chunk Union/NNP Address/NNP)\n",
      "(Chunk Capitol/NNP ,/, Tuesday/NNP ,/, Jan/NNP ./.)\n"
     ]
    }
   ],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For summary, using modified regular expressions, we can define **chunk patterns**. These are patterns of part-of-speech tags that define what kinds of words make up a **chunk**. We can also define patterns for what kinds of words should not be in a chunk. These unchunked words are known as **chinks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n",
    "One of the most common forms of chunking in natural language processing is called **Named Entity Recognition** (NER for short). NLTK is able to identify people, places, things, locations, monetary figures, and more.\n",
    "\n",
    "There are two major options with NLTK's named entity recognition: either recognize all named entities, or recognize named entities as their respective type, like people, places, locations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokens[:5]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "            \n",
    "            # print(chunked)\n",
    "            for subtree in namedEnt.subtrees(filter=lambda t: t.label() == 'NE'):\n",
    "                print(subtree)\n",
    "            \n",
    "#             namedEnt.draw()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NE GEORGE/NNP)\n",
      "(NE ADDRESS/NNP)\n",
      "(NE THE/NNP)\n",
      "(NE CONGRESS/NNP)\n",
      "(NE THE/NNP UNION/NNP)\n",
      "(NE Mr./NNP Speaker/NNP)\n",
      "(NE Cheney/NNP)\n",
      "(NE Congress/NNP)\n",
      "(NE Supreme/NNP Court/NNP)\n",
      "(NE America/NNP)\n",
      "(NE Coretta/NNP Scott/NNP King/NNP)\n",
      "(NE Applause/NNP)\n",
      "(NE George/NNP)\n",
      "(NE Union/NNP Address/NNP)\n",
      "(NE Capitol/NNP)\n",
      "(NE Jan/NNP)\n"
     ]
    }
   ],
   "source": [
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same visualization we can see above.\n",
    "\n",
    "![ner_draw](image/ner_draw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "Now, it's time to process text classification. All processes we've done is some kind of preprocessing the text data, like tokenization, stemming, POS tagging, chunking and chinking, and NER. \n",
    "\n",
    "In this part, we will use movie review dataset in NLTK, one of famous NLP datasets. This datasets are commonly used to sentimental analysis. But we need to classify each words in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2000\n",
      "First Review: (['capsule', ':', 'gal', 'is', 'a', '50s', '-', 'ish', 'london', 'cockney', 'gangster', 'who', 'has', 'retired', 'to', 'spain', '.', 'his', 'old', 'associates', 'want', 'him', 'for', 'one', 'last', 'job', 'and', 'send', 'the', 'vicious', 'don', 'to', 'give', 'him', 'an', 'offer', 'he', 'can', \"'\", 't', 'refuse', '.', 'a', 'standout', 'performance', 'by', 'ben', 'kingsley', 'as', 'don', 'cannot', 'save', 'what', 'is', 'essentially', 'a', 'set', 'of', 'cliches', 'recycled', 'from', 'old', 'westerns', '.', ',', '0', '(', '-', '4', 'to', '+', '4', ')', 'roger', 'ebert', 'asks', 'in', 'his', 'review', 'of', 'sexy', 'beast', ',', '\"', 'who', 'would', 'have', 'guessed', 'that', 'the', 'most', 'savage', 'mad', '-', 'dog', 'frothing', 'gangster', 'in', 'recent', 'movies', 'would', 'be', 'played', 'by', '.', '.', '.', 'ben', 'kingsley', '?', '\"', 'my', 'response', 'would', 'be', 'that', 'anyone', 'who', 'has', 'seen', 'alan', 'arkin', 'in', 'wait', 'until', 'dark', ',', 'henry', 'fonda', 'in', 'once', 'upon', 'a', 'time', 'in', 'the', 'west', ',', 'or', 'anthony', 'hopkins', 'in', 'the', 'silence', 'of', 'the', 'lambs', 'should', 'have', 'guessed', 'it', '.', 'they', 'should', 'know', 'that', 'the', 'way', 'for', 'a', 'film', 'to', 'create', 'a', 'really', 'creepy', 'sociopath', 'is', 'cast', 'someone', 'who', 'generally', 'plays', 'mild', ',', 'sympathetic', ',', 'or', 'even', 'ineffectual', 'character', 'roles', '.', 'the', 'same', 'characteristics', 'that', 'make', 'an', 'actor', 'seem', 'gentle', 'in', 'most', 'of', 'his', 'roles', 'can', 'work', 'in', 'his', 'favor', 'when', 'a', 'role', 'calls', 'for', 'him', 'to', 'be', 'fierce', 'and', 'vicious', '.', 'that', 'is', 'the', 'principle', 'that', 'works', 'for', 'kingsley', 'in', 'sexy', 'beast', '.', 'gary', '\"', 'gal', '\"', 'dove', '(', 'played', 'by', 'ray', 'winstone', ')', 'has', 'retired', 'from', 'a', 'london', 'career', 'of', 'crime', 'and', 'is', 'living', 'on', 'a', 'luxurious', 'villa', 'in', 'spain', '.', 'life', 'has', 'become', 'a', 'routine', 'of', 'sunning', 'himself', 'and', 'relaxing', '.', 'but', 'his', 'paradise', 'is', 'about', 'to', 'be', 'shattered', 'by', 'a', 'one', '-', 'two', '-', 'punch', '.', 'the', 'first', 'punch', 'is', 'a', 'boulder', 'that', 'comes', 'rolling', 'down', 'the', 'hill', 'next', 'to', 'the', 'villa', '.', 'the', 'second', 'punch', 'comes', 'from', 'gal', \"'\", 's', 'past', '.', 'back', 'in', 'london', 'gang', 'boss', 'teddy', 'bass', '(', 'ian', 'mcshane', ',', 'tv', \"'\", 's', 'lovejoy', ')', 'is', 'planning', 'to', 'break', 'into', 'a', 'safety', 'deposit', 'room', 'in', 'a', 'bank', 'and', 'he', 'wants', 'gal', '.', 'he', 'sends', 'his', 'most', 'rabid', 'henchman', 'don', 'logan', '(', 'ben', 'kingsley', ')', 'to', 'fetch', 'gal', '.', 'don', 'will', 'accept', 'any', 'decision', 'gal', 'makes', 'from', '\"', 'yes', '\"', 'to', '\"', 'certainly', '.', '\"', 'however', ',', 'if', 'gal', 'says', '\"', 'no', '\"', 'don', 'will', 'do', 'whatever', 'it', 'takes', 'to', 'turn', 'it', 'into', 'a', 'yes', 'including', 'threatening', 'guy', \"'\", 's', 'ex', '-', 'porn', '-', 'star', 'wife', 'deedee', '(', 'amanda', 'redman', ')', '.', 'in', 'the', 'meantime', 'don', 'knows', 'just', 'how', 'to', 'get', 'under', 'everybody', \"'\", 's', 'skin', '.', 'kingsley', 'makes', 'don', 'a', 'compact', 'package', 'of', 'fury', 'and', 'nastiness', '.', 'there', 'are', 'some', 'serious', 'problems', 'in', 'louis', 'mellis', \"'\", 's', 'and', 'david', 'scinto', \"'\", 's', 'script', 'that', 'should', 'have', 'been', 'caught', 'before', 'filming', '.', 'when', 'we', 'see', 'the', 'actual', 'crime', 'we', 'have', 'no', 'idea', 'why', 'gal', 'was', 'so', 'important', 'to', 'its', 'success', '.', 'beyond', 'an', 'ability', 'to', 'use', 'skin', '-', 'diving', 'gear', ',', 'no', 'special', 'talents', 'are', 'required', 'of', 'him', '.', 'any', 'local', 'hood', 'could', 'have', 'done', 'what', 'gal', 'is', 'needed', 'for', '.', 'additionally', 'the', 'crime', 'involves', 'digging', 'from', 'a', 'swimming', 'pool', 'to', 'the', 'bank', 'vault', ',', 'flooding', 'the', 'vault', '.', 'no', 'only', 'could', 'they', 'have', 'let', 'the', 'water', 'out', 'of', 'the', 'pool', 'and', 'avoided', 'the', 'complication', 'altogether', ',', 'but', 'there', 'is', 'by', 'far', 'too', 'much', 'water', 'to', 'be', 'accounted', 'for', 'by', 'what', 'was', 'in', 'the', 'pool', '.', 'in', 'spite', 'of', 'the', 'provocative', 'title', ',', 'the', 'story', 'is', 'cliched', 'and', 'overly', 'familiar', '.', 'i', 'know', 'i', 'have', 'seen', 'all', 'the', 'plot', 'elements', 'of', 'sexy', 'beast', 'in', 'old', 'westerns', 'like', 'the', 'law', 'and', 'jake', 'wade', '.', 'the', 'story', 'is', 'usually', 'of', 'the', 'reformed', 'outlaw', ',', 'a', 'robert', 'taylor', 'type', ',', 'who', 'has', 'hung', 'up', 'his', 'guns', 'and', 'is', 'trying', 'for', 'a', 'life', 'of', 'peaceful', 'respectability', '.', 'the', 'old', 'gang', ',', 'however', ',', 'wants', 'to', 'do', 'one', 'more', 'job', 'with', 'their', 'old', 'buddy', 'and', 'sends', 'a', 'rabid', 'richard', 'widmark', 'type', 'to', 'go', 'and', 'git', '?', 'im', '.', 'it', 'is', 'not', 'a', 'great', 'plot', '.', 'in', 'sexy', 'beast', 'even', 'the', 'plot', 'twists', 'have', 'gray', 'beards', '.', 'perhaps', 'the', 'film', 'has', 'a', 'little', 'more', 'respectability', 'because', 'it', 'was', 'made', 'not', 'as', 'a', 'western', 'but', 'as', 'a', 'stylish', 'british', 'gangster', 'film', '.', 'it', 'is', 'an', 'old', 'plot', 'dressed', 'up', 'to', 'look', 'new', '.', 'if', 'the', 'plot', 'is', 'old', ',', 'at', 'least', 'the', 'style', 'is', 'creative', '.', 'this', 'is', 'director', 'jonathan', 'glazer', \"'\", 's', 'first', 'film', ',', 'but', 'he', 'has', 'reputedly', 'done', 'some', 'notable', 'tv', 'ads', 'for', 'guinness', 'stout', '.', 'his', 'style', 'does', 'have', 'some', 'unexpected', 'touches', 'including', 'some', 'very', 'odd', 'dream', 'sequences', '.', 'cinematographer', 'ivan', 'bird', 'uses', 'a', 'lot', 'of', 'half', 'lit', 'scenes', '.', 'we', 'see', 'one', 'side', 'of', 'a', 'person', \"'\", 's', 'faces', '.', 'but', 'the', 'other', 'side', 'fades', 'into', 'the', 'darkness', ',', 'a', 'sort', 'of', 'metaphor', 'for', 'the', 'half', '-', 'world', 'these', 'characters', 'in', '-', 'habit', '.', 'half', 'of', 'everything', 'that', 'is', 'happening', 'is', 'also', 'kept', 'hidden', '.', 'we', 'yanks', 'will', 'have', 'a', 'hard', 'time', 'with', 'some', 'of', 'the', 'dialog', '.', 'at', 'least', 'in', 'my', 'theater', 'it', 'was', 'difficult', 'to', 'make', 'out', 'the', 'words', 'with', 'the', 'quiet', 'speaking', ',', 'the', 'heavy', 'accents', ',', 'and', 'the', 'cockney', 'language', '.', 'sexy', 'beast', 'is', 'a', 'very', 'and', 'familiar', 'minor', 'plot', 'lent', 'respectability', 'in', 'the', 'us', 'by', 'being', 'done', 'in', 'what', 'is', 'here', 'a', 'still', 'somewhat', 'novel', 'genre', ',', 'the', 'london', 'crime', 'film', '.', 'the', 'plot', 'may', 'be', 'new', 'to', 'british', 'crime', 'films', ',', 'but', 'it', 'would', 'be', 'overly', 'familiar', 'as', 'a', 'western', '.', 'further', 'respectability', 'comes', 'from', 'ben', 'kingsley', \"'\", 's', 'high', '-', 'powered', 'performance', '.', 'i', 'give', 'it', 'a', '4', 'on', 'the', '0', 'to', '10', 'scale', 'and', 'a', '0', 'on', 'the', '-', '4', 'to', '+', '4', 'scale', '.'], 'neg')\n",
      "\n",
      "Most common words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "\n",
      "The word happy: 215\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "\n",
    "# Build documents\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories() \n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle the documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents: {}'.format(len(documents)))\n",
    "print('First Review: {}'.format(documents[1]))\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "# Generate frequency distribution\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print('\\nMost common words: {}'.format(all_words.most_common(15)))\n",
    "print('\\nThe word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are 215 \"happy\" words in movie_reviews. It means that that review maybe positive review. And you can also notice that the common words contain punctuation or stop words and so on. \n",
    "\n",
    "Now we need to build features. In this post, we will use 4000 high frequent words as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it will be helpful to define the function that find the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Let's use an example from a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n",
      ":\n",
      "two\n",
      "teen\n",
      "couples\n",
      "go\n",
      "to\n",
      "a\n",
      "church\n",
      "party\n",
      ",\n",
      "drink\n",
      "and\n",
      "then\n",
      "drive\n",
      ".\n",
      "they\n",
      "get\n",
      "into\n",
      "an\n",
      "accident\n",
      "one\n",
      "of\n",
      "the\n",
      "guys\n",
      "dies\n",
      "but\n",
      "his\n",
      "girlfriend\n",
      "continues\n",
      "see\n",
      "him\n",
      "in\n",
      "her\n",
      "life\n",
      "has\n",
      "nightmares\n",
      "what\n",
      "'\n",
      "s\n",
      "deal\n",
      "?\n",
      "watch\n",
      "movie\n",
      "\"\n",
      "sorta\n",
      "find\n",
      "out\n",
      "critique\n",
      "mind\n",
      "-\n",
      "fuck\n",
      "for\n",
      "generation\n",
      "that\n",
      "touches\n",
      "on\n",
      "very\n",
      "cool\n",
      "idea\n",
      "presents\n",
      "it\n",
      "bad\n",
      "package\n",
      "which\n",
      "is\n",
      "makes\n",
      "this\n",
      "review\n",
      "even\n",
      "harder\n",
      "write\n",
      "since\n",
      "i\n",
      "generally\n",
      "applaud\n",
      "films\n",
      "attempt\n",
      "break\n",
      "mold\n",
      "mess\n",
      "with\n",
      "your\n",
      "head\n",
      "such\n",
      "(\n",
      "lost\n",
      "highway\n",
      "&\n",
      "memento\n",
      ")\n",
      "there\n",
      "are\n",
      "good\n",
      "ways\n",
      "making\n",
      "all\n",
      "types\n",
      "these\n",
      "folks\n",
      "just\n",
      "didn\n",
      "t\n",
      "snag\n",
      "correctly\n",
      "seem\n",
      "have\n",
      "taken\n",
      "pretty\n",
      "neat\n",
      "concept\n",
      "executed\n",
      "terribly\n",
      "so\n",
      "problems\n",
      "well\n",
      "its\n",
      "main\n",
      "problem\n",
      "simply\n",
      "too\n",
      "jumbled\n",
      "starts\n",
      "off\n",
      "normal\n",
      "downshifts\n",
      "fantasy\n",
      "world\n",
      "you\n",
      "as\n",
      "audience\n",
      "member\n",
      "no\n",
      "going\n",
      "dreams\n",
      "characters\n",
      "coming\n",
      "back\n",
      "from\n",
      "dead\n",
      "others\n",
      "who\n",
      "look\n",
      "like\n",
      "strange\n",
      "apparitions\n",
      "disappearances\n",
      "looooot\n",
      "chase\n",
      "scenes\n",
      "tons\n",
      "weird\n",
      "things\n",
      "happen\n",
      "most\n",
      "not\n",
      "explained\n",
      "now\n",
      "personally\n",
      "don\n",
      "trying\n",
      "unravel\n",
      "film\n",
      "every\n",
      "when\n",
      "does\n",
      "give\n",
      "me\n",
      "same\n",
      "clue\n",
      "over\n",
      "again\n",
      "kind\n",
      "fed\n",
      "up\n",
      "after\n",
      "while\n",
      "biggest\n",
      "obviously\n",
      "got\n",
      "big\n",
      "secret\n",
      "hide\n",
      "seems\n",
      "want\n",
      "completely\n",
      "until\n",
      "final\n",
      "five\n",
      "minutes\n",
      "do\n",
      "make\n",
      "entertaining\n",
      "thrilling\n",
      "or\n",
      "engaging\n",
      "meantime\n",
      "really\n",
      "sad\n",
      "part\n",
      "arrow\n",
      "both\n",
      "dig\n",
      "flicks\n",
      "we\n",
      "actually\n",
      "figured\n",
      "by\n",
      "half\n",
      "way\n",
      "point\n",
      "strangeness\n",
      "did\n",
      "start\n",
      "little\n",
      "bit\n",
      "sense\n",
      "still\n",
      "more\n",
      "guess\n",
      "bottom\n",
      "line\n",
      "movies\n",
      "should\n",
      "always\n",
      "sure\n",
      "before\n",
      "given\n",
      "password\n",
      "enter\n",
      "understanding\n",
      "mean\n",
      "showing\n",
      "melissa\n",
      "sagemiller\n",
      "running\n",
      "away\n",
      "visions\n",
      "about\n",
      "20\n",
      "throughout\n",
      "plain\n",
      "lazy\n",
      "!\n",
      "okay\n",
      "people\n",
      "chasing\n",
      "know\n",
      "need\n",
      "how\n",
      "giving\n",
      "us\n",
      "different\n",
      "offering\n",
      "further\n",
      "insight\n",
      "down\n",
      "apparently\n",
      "studio\n",
      "took\n",
      "director\n",
      "chopped\n",
      "themselves\n",
      "shows\n",
      "might\n",
      "ve\n",
      "been\n",
      "decent\n",
      "here\n",
      "somewhere\n",
      "suits\n",
      "decided\n",
      "turning\n",
      "music\n",
      "video\n",
      "edge\n",
      "would\n",
      "actors\n",
      "although\n",
      "wes\n",
      "bentley\n",
      "seemed\n",
      "be\n",
      "playing\n",
      "exact\n",
      "character\n",
      "he\n",
      "american\n",
      "beauty\n",
      "only\n",
      "new\n",
      "neighborhood\n",
      "my\n",
      "kudos\n",
      "holds\n",
      "own\n",
      "entire\n",
      "feeling\n",
      "unraveling\n",
      "overall\n",
      "doesn\n",
      "stick\n",
      "because\n",
      "entertain\n",
      "confusing\n",
      "rarely\n",
      "excites\n",
      "feels\n",
      "redundant\n",
      "runtime\n",
      "despite\n",
      "ending\n",
      "explanation\n",
      "craziness\n",
      "came\n",
      "oh\n",
      "horror\n",
      "slasher\n",
      "flick\n",
      "packaged\n",
      "someone\n",
      "assuming\n",
      "genre\n",
      "hot\n",
      "kids\n",
      "also\n",
      "wrapped\n",
      "production\n",
      "years\n",
      "ago\n",
      "sitting\n",
      "shelves\n",
      "ever\n",
      "whatever\n",
      "skip\n",
      "where\n",
      "joblo\n",
      "nightmare\n",
      "elm\n",
      "street\n",
      "3\n",
      "7\n",
      "/\n",
      "10\n",
      "blair\n",
      "witch\n",
      "2\n",
      "crow\n",
      "9\n",
      "salvation\n",
      "4\n",
      "stir\n",
      "echoes\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "neg_features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "for k, v in neg_features.items():\n",
    "    if v == True:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now redo this in whole documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will use Support Vector Classifier for text classification. Before classifcation, we need to make train and test set, same as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(featuresets, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 500\n"
     ]
    }
   ],
   "source": [
    "print(len(training), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use `SVC` from sklearn and `SklearnClassifier` from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.802\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the model\n",
    "model = SklearnClassifier(SVC(kernel='linear'))\n",
    "\n",
    "# Train the model\n",
    "model.train(training)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = nltk.classify.accuracy(model, test)\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we can build the text classifier model with almost 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this post, we covered tokenization, stemming, POS tagging, chucking/chinking, and NER for data preprocessing. After that, we built the classifier model with Support Vector Machine, the training it with data. As a result we could build the text classifier model with 80% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
