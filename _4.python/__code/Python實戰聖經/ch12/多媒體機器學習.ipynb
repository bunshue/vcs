{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "多媒體機器學習.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWdBUq8zKFt_"
      },
      "source": [
        "## MediaPipe模組：Google多媒體機器學習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsaijYHyLNrp"
      },
      "source": [
        "!pip install mediapipe==0.8.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojO0KsPpl1i8"
      },
      "source": [
        "!wget -O person1.jpg --content-disposition https://unsplash.com/photos/3g3grQaeA2o/download?force=true\n",
        "!wget -O person2.jpg --content-disposition https://unsplash.com/photos/GVVsC0JG6Ak/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW-bicsJIVEG"
      },
      "source": [
        "#臉部偵測\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "image = resizeimg(cv2.imread('person1.jpg'))\n",
        "# image = resizeimg(cv2.imread('person2.jpg'))\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_drawing = mp.solutions.drawing_utils \n",
        "face_detection = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "# print(results.detections)\n",
        "if results.detections:\n",
        "    for detection in results.detections:\n",
        "        # print('鼻子:')\n",
        "        # print(mp_face_detection.get_key_point(detection,mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
        "        mp_drawing.draw_detection(image, detection)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my2yiNb3mo9G"
      },
      "source": [
        "!wget -O person3.jpg --content-disposition https://unsplash.com/photos/JyVcAIUAcPM/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRWxYuJOOMXE"
      },
      "source": [
        "#臉部特徵網\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "image = resizeimg(cv2.imread('person3.jpg'))\n",
        "# image = resizeimg(cv2.imread('person1.jpg'))\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=5, min_detection_confidence=0.5)\n",
        "results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_face_landmarks:\n",
        "    for face_landmarks in results.multi_face_landmarks:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image=image, landmark_list=face_landmarks,\n",
        "            connections=mp_face_mesh.FACE_CONNECTIONS,\n",
        "            landmark_drawing_spec=drawing_spec,\n",
        "            connection_drawing_spec=drawing_spec)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVdzJMkhm5DY"
      },
      "source": [
        "!wget -O hand1.jpg --content-disposition https://unsplash.com/photos/33VdiGc2O9o/download?force=true\n",
        "!wget -O hand2.jpg --content-disposition https://unsplash.com/photos/qKspdY9XUzs/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wjUEfRYPRJo"
      },
      "source": [
        "#手部偵測\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "# image = resizeimg(cv2.imread('hand1.jpg'))\n",
        "image = resizeimg(cv2.imread('hand2.jpg'))\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, \n",
        "\t\tmin_detection_confidence=0.5)\n",
        "results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.multi_hand_landmarks:\n",
        "    for hand_landmarks in results.multi_hand_landmarks:\n",
        "        # print('姆指尖：', hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP])\n",
        "        mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40qkWKZQnHgp"
      },
      "source": [
        "!wget -O pose1.jpg --content-disposition https://unsplash.com/photos/A3MleA0jtoE/download?force=true\n",
        "!wget -O pose2.jpg --content-disposition https://unsplash.com/photos/wa8o6rs22Fw/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEipSoViP_pl"
      },
      "source": [
        "#姿勢偵測\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "image = resizeimg(cv2.imread('pose1.jpg'))\n",
        "# image = resizeimg(cv2.imread('pose2.jpg'))\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, \n",
        "\t\tmin_detection_confidence=0.5)\n",
        "results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.pose_landmarks:\n",
        "    # print('鼻子：', results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE])\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N4XysrfRPUl"
      },
      "source": [
        "#人體整合偵測\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "image = resizeimg(cv2.imread('pose1.jpg'))\n",
        "# image = resizeimg(cv2.imread('pose2.jpg'))\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=True, model_complexity=1)\n",
        "results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.pose_landmarks:\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNpX0vzdnbiU"
      },
      "source": [
        "!wget -O object1.jpg --content-disposition https://unsplash.com/photos/kvmdsTrGOBM/download?force=true\n",
        "!wget -O object2.jpg --content-disposition https://unsplash.com/photos/rhcllVy2zBU/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF6N0fTWR8iw"
      },
      "source": [
        "#3D物體偵測\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "image = resizeimg(cv2.imread('object1.jpg'))\n",
        "# image = resizeimg(cv2.imread('object2.jpg'))\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_objectron = mp.solutions.objectron\n",
        "objectron = mp_objectron.Objectron(static_image_mode=True, max_num_objects=5, min_detection_confidence=0.5, model_name='Chair')\n",
        "\n",
        "results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "if results.detected_objects:\n",
        "    for detected_object in results.detected_objects:\n",
        "        mp_drawing.draw_landmarks(image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)\n",
        "        mp_drawing.draw_axis(image, detected_object.rotation, detected_object.translation)\n",
        "cv2_imshow(image) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2ACDnSZpJk6"
      },
      "source": [
        "## cvzone模組：簡單易用多媒體機器學習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jDCrwosp4or"
      },
      "source": [
        "!pip install cvzone==1.3.7\n",
        "!pip install mediapipe==0.8.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI_-2Ez6pPvN"
      },
      "source": [
        "#臉部偵測\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "import cv2, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "img = resizeimg(cv2.imread('person1.jpg'))\n",
        "# img = resizeimg(cv2.imread('person2.jpg'))\n",
        "detector = FaceDetector()\n",
        "img, bboxs = detector.findFaces(img)\n",
        "# print('人臉範圍：', bboxs)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PY2Uzt6vNlq"
      },
      "source": [
        "#臉部特徵網\n",
        "from cvzone.FaceMeshModule import FaceMeshDetector\n",
        "import cv2, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "img = resizeimg(cv2.imread('person1.jpg'))\n",
        "# img = resizeimg(cv2.imread('person2.jpg'))\n",
        "detector = FaceMeshDetector(staticMode=True, maxFaces=5)\n",
        "img, faces = detector.findFaceMesh(img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3or0Bv8Hwgxz"
      },
      "source": [
        "#手部偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "img = resizeimg(cv2.imread('hand1.jpg'))\n",
        "# img = resizeimg(cv2.imread('hand2.jpg'))\n",
        "detector = HandDetector(mode=False, detectionCon=0.5, maxHands=2)\n",
        "img = detector.findHands(img)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8xjx-wqo2X2"
      },
      "source": [
        "!wget -O hand3.jpg --content-disposition https://unsplash.com/photos/fYTfOzaRVWw/download?force=true\n",
        "!wget -O hand4.jpg --content-disposition https://unsplash.com/photos/Lzys6r1xFD8/download?force=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTyRz6NxsAF"
      },
      "source": [
        "#手部狀態偵測\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "import cv2, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "img = resizeimg(cv2.imread('hand3.jpg'))\n",
        "# img = resizeimg(cv2.imread('hand4.jpg'))\n",
        "detector = HandDetector(mode=False, detectionCon=0.5)\n",
        "img = detector.findHands(img)\n",
        "lmList, bboxInfo = detector.findPosition(img)\n",
        "#print('特徵點：', lmList)\n",
        "if lmList:\n",
        "  bbox = bboxInfo['bbox']\n",
        "  #左右手\n",
        "  myHandType = detector.handType() \n",
        "  cv2.putText(img, 'Hand:{}'.format(myHandType), (bbox[0], bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
        "\n",
        "  #伸出手指數\n",
        "  fingers = detector.fingersUp()\n",
        "  #print(fingers)\n",
        "  upFingers = fingers.count(1)\n",
        "  cv2.putText(img, 'Finger:{}'.format(upFingers), (bbox[0]+100, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
        "\n",
        "  #兩特徵點距離\n",
        "  distance, img, info = detector.findDistance(8, 12, img) #食指與中指\n",
        "  cv2.putText(img, 'Dist:{}'.format(str(int(distance))), (bbox[0]+200, bbox[1]-25), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryWbz6PO0wiu"
      },
      "source": [
        "#姿勢偵測\n",
        "from cvzone.PoseModule import PoseDetector\n",
        "import cv2, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "dH, dW = 480, 480\n",
        "def resizeimg(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (dW, math.floor(h/(w/dW))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/dH)), dH))\n",
        "  return img\n",
        "\n",
        "img = resizeimg(cv2.imread('pose1.jpg'))\n",
        "# img = resizeimg(cv2.imread('pose2.jpg'))\n",
        "detector = PoseDetector()\n",
        "img = detector.findPose(img)\n",
        "cv2_imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}