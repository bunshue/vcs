{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH14gradio網頁互動.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-2Cul9rIZRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a63e25-cf18-42c2-ba9a-5d49b7b51083"
      },
      "source": [
        "!pip install gradio==3.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-2.9.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.17.6-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.0 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 38.3 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.75.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.5)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.10.3-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.0.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.10.8)\n",
            "Collecting starlette==0.17.1\n",
            "  Downloading starlette-0.17.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 10.3 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Collecting cryptography>=2.5\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 332 kB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Collecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.5.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=598e0a316b5367342705db8d9d0416016291f7f1404088a2a21ccdfd16a38ca7\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=efbaf2a48908ff76cab5b081c2ff62f433bf49954946c17821cb53fa7fd20c49\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, multidict, markdown-it-py, frozenlist, anyio, yarl, starlette, pynacl, pydantic, monotonic, mdit-py-plugins, linkify-it-py, h11, cryptography, bcrypt, backoff, asynctest, async-timeout, asgiref, aiosignal, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.5.0 asgiref-3.5.0 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 bcrypt-3.2.0 cryptography-36.0.2 fastapi-0.75.1 ffmpy-0.3.0 frozenlist-1.3.0 gradio-2.9.1 h11-0.13.0 linkify-it-py-1.0.3 markdown-it-py-2.0.1 mdit-py-plugins-0.3.0 mdurl-0.1.1 monotonic-1.6 multidict-6.0.2 orjson-3.6.7 paramiko-2.10.3 pycryptodome-3.14.1 pydantic-1.9.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 sniffio-1.2.0 starlette-0.17.1 uc-micro-py-1.0.1 uvicorn-0.17.6 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDZCGplTO42"
      },
      "source": [
        "## 基本原理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afmkfd_rIl3N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "7e6b4324-3619-4a14-c64c-6b84f10123fc"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def replace1(text):\n",
        "  return text.replace('morning', 'evening')\n",
        "\n",
        "grobj = gr.Interface(fn=replace1, inputs=gr.inputs.Textbox(), outputs=gr.outputs.Textbox())\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://46187.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f7bc3fdbad0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://46187.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f7bcf528c90>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://46187.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFjgF3VyTZj5"
      },
      "source": [
        "## 手寫數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYhNb9FJIqH2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from urllib.request import urlretrieve\n",
        "import gradio as gr\n",
        "\n",
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model = tf.keras.models.load_model(\"mnist-model.h5\")\n",
        "\n",
        "def mnist(image):\n",
        "    image = image.reshape(1, -1)  #(28,28)轉為(1,784)\n",
        "    prediction = model.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}\n",
        "\n",
        "out = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=out, title=\"手寫數字\")\n",
        "#grobj = gr.Interface(fn=mnist, inputs=\"sketchpad\", outputs=out, title=\"手寫數字\", live=True)\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkd9Hh6_TfoM"
      },
      "source": [
        "## Inception圖片物件偵測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMVSAVjBI07u"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "model = tf.keras.applications.InceptionV3()\n",
        "#讀取標籤\n",
        "response = requests.get('https://git.io/JJkYN')\n",
        "labels = response.text.split('\\n')\n",
        "#print(labels)\n",
        "\n",
        "def classify(img):\n",
        "  img = np.expand_dims(img, 0)\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  prediction = model.predict(img).flatten()\n",
        "  return {labels[i]: float(prediction[i]) for i in range(len(prediction))}\n",
        "\n",
        "image = gr.inputs.Image(shape=(299, 299))\n",
        "label = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "grobj = gr.Interface(fn=classify, inputs=image, outputs=label, title='Inception物件偵測')\n",
        "#grobj = gr.Interface(fn=classify, inputs=image, outputs=label, title='Inception物件偵測', examples=[['lion1.jpg'], ['tiger1.jpg']])\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVCCmThPTnzq"
      },
      "source": [
        "## 英文對話(GPT-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdeVMtaiOaoR"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJmiRBd9LRMN"
      },
      "source": [
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "def generate_text(inp):\n",
        "    input_ids = tokenizer.encode(inp, return_tensors='tf')\n",
        "    beam_output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
        "    output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    return output[:-1]\n",
        "\n",
        "out = gr.outputs.Textbox(label='GPT-2回應')\n",
        "grobj = gr.Interface(generate_text,inputs=\"textbox\", outputs=out, title=\"GPT-2\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NYO1aRQT8eH"
      },
      "source": [
        "## 自動歌詞產生器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "345wsv7rUzBf"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "grobj = gr.Interface.load(\"huggingface/uer/gpt2-chinese-lyric\", inputs=\"text\", outputs=\"text\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfLqxqcRR132"
      },
      "source": [
        "!pip install opencc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8y_ZbAtLIks"
      },
      "source": [
        "import gradio as gr\n",
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
        "from opencc import OpenCC\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
        "cc = OpenCC('s2twp')\n",
        "\n",
        "def generate_text(inp):\n",
        "    text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "    ret = text_generator(inp, max_length=100, do_sample=True)\n",
        "    return cc.convert(ret[0]['generated_text'])\n",
        "\n",
        "output_text = gr.outputs.Textbox()\n",
        "grobj = gr.Interface(generate_text,inputs=\"textbox\", outputs=output_text, title=\"自動產生歌詞\")\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF3SkWJjT12x"
      },
      "source": [
        "## 鐵達尼號生存預測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLpEW9pQ9JSv"
      },
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def encode_ages(df): \n",
        "    df.Age = df.Age.fillna(-0.5)\n",
        "    bins = (-1, 0, 5, 12, 18, 25, 35, 50, 80)\n",
        "    categories = pd.cut(df.Age, bins, labels=False)\n",
        "    df.Age = categories\n",
        "    return df\n",
        "\n",
        "def encode_fares(df):\n",
        "    df.Fare = df.Fare.fillna(-0.5)\n",
        "    bins = (-1, 0, 8, 15, 31, 50, 80, 100, 550)\n",
        "    categories = pd.cut(df.Fare, bins, labels=False)\n",
        "    df.Fare = categories\n",
        "    return df\n",
        "\n",
        "def encode_sex(df):\n",
        "    mapping = {\"male\": 0, \"female\": 1}\n",
        "    return df.replace({'Sex': mapping})\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/gradio-app/titanic/master/train.csv')\n",
        "\n",
        "def transform_features(df):\n",
        "    df = encode_ages(df)\n",
        "    df = encode_fares(df)\n",
        "    df = encode_sex(df)\n",
        "    return df\n",
        "\n",
        "data1 = data[['Fare', 'Age', 'Sex', 'Survived']]\n",
        "data1 = transform_features(data1)\n",
        "X_all = data1.drop(['Survived'], axis=1)\n",
        "y_all = data1['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "def predict_survival(sex, age, fare):\n",
        "    df = pd.DataFrame.from_dict({'Sex': [sex], 'Age': [age], 'Fare': [fare]})\n",
        "    df = encode_sex(df)\n",
        "    df = encode_fares(df)\n",
        "    df = encode_ages(df)\n",
        "    pred = clf.predict_proba(df)[0]\n",
        "    return {'死亡': pred[0], '生還': pred[1]}\n",
        "\n",
        "sex = gr.inputs.Radio(['female', 'male'], label=\"性別\")\n",
        "age = gr.inputs.Slider(minimum=0, maximum=80, step=1, default=22, label=\"年齡\")\n",
        "fare = gr.inputs.Slider(minimum=0, maximum=550, step=1, default=20, label=\"船費\")\n",
        "out = gr.outputs.Label(label='預測結果')\n",
        "grobj = gr.Interface(fn=predict_survival, inputs=[sex, age, fare], outputs=out, title='鐵達尼號生存預測', live=True)\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx7iHq2lUKNf"
      },
      "source": [
        "## 使用自行訓練的模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7d1v2SUNqZ"
      },
      "source": [
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "model = tensorflow.keras.models.load_model('left_right.h5')\n",
        "labels = ['normal','left','right']\n",
        "\n",
        "def classify(img):\n",
        "  img = (img.astype(np.float32) / 127.0) - 1\n",
        "  img = np.expand_dims(img, 0)\n",
        "  prediction = model.predict(img)\n",
        "  return {labels[i]: float(prediction[0][i]) for i in range(len(prediction[0]))}\n",
        "\n",
        "image = gr.inputs.Image(shape=(224, 224), label='輸入圖片')\n",
        "label = gr.outputs.Label(num_top_classes=3, label='預測結果')\n",
        "grobj = gr.Interface(fn=classify, inputs=image, outputs=label, examples=[['left1.jpg'], ['right1.jpg'], ['normal1.jpg']], title='使用自行訓練的模型')\n",
        "grobj.launch()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}