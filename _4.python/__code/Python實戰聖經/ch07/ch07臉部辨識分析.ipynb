{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch07臉部辨識分析.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFlbbnYbiifl"
      },
      "source": [
        "## face_engine：簡單易用的臉部辨識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j40enRjciNH0"
      },
      "source": [
        "!pip install face-engine==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpwyrw2ztNkt"
      },
      "source": [
        "!mkdir -p /usr/local/lib/python3.7/dist-packages/face_engine/resources/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q-GcI2grjHi"
      },
      "source": [
        "!cp \"dlib_face_recognition_resnet_model_v1.dat\" /usr/local/lib/python3.7/dist-packages/face_engine/resources/data\n",
        "!cp \"shape_predictor_5_face_landmarks.dat\" /usr/local/lib/python3.7/dist-packages/face_engine/resources/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvzDwy_pko9I"
      },
      "source": [
        "from face_engine import FaceEngine\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaMubVXiktEV"
      },
      "source": [
        "engine = FaceEngine()\n",
        "filename = 'person1.jpg'\n",
        "# filename = 'person2.jpg'\n",
        "# filename = 'person3.jpg'\n",
        "#try:\n",
        "_, boxes = engine.find_faces(filename)\n",
        "print(boxes)\n",
        "\n",
        "img = Image.open(filename)\n",
        "drawing = ImageDraw.Draw(img)\n",
        "for i in range(len(boxes)):\n",
        "    drawing.rectangle(boxes[i], outline='white', width=2)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "#except:\n",
        "#  print('未偵測到人臉！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-L6jJHjbWY2"
      },
      "source": [
        "engine = FaceEngine()\n",
        "img1 = 'sample1.jpg'\n",
        "# img1 = 'sample2.jpg'\n",
        "# img1 = 'sample3.jpg'\n",
        "img2 = 'person3.jpg'\n",
        "score, box = engine.compare_faces(img1, img2)\n",
        "print(score, box)\n",
        "img = Image.open(img2)\n",
        "drawing = ImageDraw.Draw(img)\n",
        "drawing.rectangle(box, outline='white', width=2)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR_KPr41vgsR"
      },
      "source": [
        "engine = FaceEngine()\n",
        "img1 = 'sample1.jpg'\n",
        "img2 = 'sample2.jpg'\n",
        "img3 = 'sample3.jpg'\n",
        "engine.fit([img1, img2, img3], ['jeng', 'chiou', 'david'])\n",
        "\n",
        "testimage = 'catch.jpg'\n",
        "# testimage = 'person2.jpg'\n",
        "names, boxes = engine.make_prediction(testimage)\n",
        "print(names, boxes)\n",
        "img = Image.open(testimage)\n",
        "drawing = ImageDraw.Draw(img)\n",
        "for i in range(len(boxes)):\n",
        "    drawing.rectangle(boxes[i], outline='white', width=2)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmux8lcci41l"
      },
      "source": [
        "engine = FaceEngine()\n",
        "img1 = 'sample1.jpg'\n",
        "img2 = 'sample2.jpg'\n",
        "img3 = 'sample3.jpg'\n",
        "engine.fit([img1, img2, img3], ['jeng', 'chiou', 'david'])\n",
        "engine.save('ehappy.p')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ANKGAbdjjmy"
      },
      "source": [
        "from face_engine import load_engine\n",
        "\n",
        "engine = load_engine('ehappy.p')\n",
        "testimage = 'catch.jpg'\n",
        "names, boxes = engine.make_prediction(testimage)\n",
        "print(names, boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYvbGQn9_i1W"
      },
      "source": [
        "## face-recognition：效果絕佳的人臉辨識"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikKzTN_cAKFO"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mD2-V5SAbIN"
      },
      "source": [
        "import face_recognition\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpZfxrEeAdXi"
      },
      "source": [
        "# filename = 'person1.jpg'\n",
        "# filename = 'person2.jpg'\n",
        "# filename = 'person3.jpg'\n",
        "filename = 'person12.jpg'\n",
        "image = face_recognition.load_image_file(filename)\n",
        "boxes = face_recognition.face_locations(image)\n",
        "print(boxes)\n",
        "\n",
        "img = Image.open(filename)\n",
        "drawing = ImageDraw.Draw(img)\n",
        "for i in range(len(boxes)):\n",
        "    drawing.rectangle((boxes[i][3],boxes[i][0],boxes[i][1],boxes[i][2]), outline='red', width=2)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7obOlwemAght"
      },
      "source": [
        "filename = 'obama.jpg'\n",
        "image = face_recognition.load_image_file(filename)\n",
        "landmarks = face_recognition.face_landmarks(image)\n",
        "print(landmarks)\n",
        "print('鼻樑位置：{}'.format(landmarks[0]['nose_bridge']))\n",
        "\n",
        "img = Image.open(filename)\n",
        "drawing = ImageDraw.Draw(img)\n",
        "for landmark in landmarks:\n",
        "    for feature in landmark.keys():\n",
        "        drawing.line(landmark[feature], width=5)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCGu2PjXAjvd"
      },
      "source": [
        "img1 = face_recognition.load_image_file('sample1.jpg')\n",
        "img2 = face_recognition.load_image_file('sample2.jpg')\n",
        "img3 = face_recognition.load_image_file('sample3.jpg')\n",
        "encoding1 = face_recognition.face_encodings(img1)[0]\n",
        "encoding2 = face_recognition.face_encodings(img2)[0]\n",
        "encoding3 = face_recognition.face_encodings(img3)[0]\n",
        "known_faces = [encoding1, encoding2, encoding3]\n",
        "names = ['jeng', 'chiou', 'david']\n",
        "\n",
        "unknown = face_recognition.load_image_file(\"catch.jpg\")\n",
        "# unknown = face_recognition.load_image_file(\"lily2.jpg\")\n",
        "encoding_unknown = face_recognition.face_encodings(unknown)[0]\n",
        "results = face_recognition.compare_faces(known_faces, encoding_unknown)\n",
        "print(results)\n",
        "face = ''\n",
        "for i in range(len(results)):\n",
        "  if results[i]: face = face + names[i] + '  '\n",
        "if face == '': print('圖片中辨識不到資料庫中人臉！')\n",
        "else: print('圖片中的人臉：' + face)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CFNZRaGAnEP"
      },
      "source": [
        "img1 = face_recognition.load_image_file('sample1.jpg')\n",
        "img2 = face_recognition.load_image_file('sample2.jpg')\n",
        "img3 = face_recognition.load_image_file('sample3.jpg')\n",
        "encoding1 = face_recognition.face_encodings(img1)[0]\n",
        "encoding2 = face_recognition.face_encodings(img2)[0]\n",
        "encoding3 = face_recognition.face_encodings(img3)[0]\n",
        "known_faces = [encoding1, encoding2, encoding3]\n",
        "names = ['jeng', 'chiou', 'david']\n",
        "\n",
        "unknown = face_recognition.load_image_file(\"catch.jpg\")\n",
        "#unknown = face_recognition.load_image_file(\"lily2.jpg\")\n",
        "encoding_unknown = face_recognition.face_encodings(unknown)[0]\n",
        "distances = face_recognition.face_distance(known_faces, encoding_unknown)\n",
        "print(distances)\n",
        "face = ''\n",
        "for i in range(len(distances)):\n",
        "  if distances[i] < 0.5: face = face + names[i] + '  '\n",
        "if face == '': print('圖片中辨識不到資料庫中人臉！')\n",
        "else: print('圖片中的人臉：' + face)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mAWxEVslyH6"
      },
      "source": [
        "## fer：偵測臉部表情"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaNl1cLwlgEM"
      },
      "source": [
        "!pip install fer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d8igWMovFHP"
      },
      "source": [
        "from fer import FER\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEU4ZeIFvIqc"
      },
      "source": [
        "img = cv2.imread(\"angry1.jpg\")\n",
        "detector = FER()\n",
        "emotion = detector.detect_emotions(img)\n",
        "print(emotion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKgcRKbjvL59"
      },
      "source": [
        "img = cv2.imread(\"angry1.jpg\")\n",
        "# img = cv2.imread(\"happy1.jpg\")\n",
        "detector = FER()\n",
        "try:\n",
        "  emotion, score = detector.top_emotion(img)\n",
        "  print(emotion, score)\n",
        "except:\n",
        "  print('未偵測到人臉！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFUceRdgvPm7"
      },
      "source": [
        "img = cv2.imread(\"happy1.jpg\")\n",
        "detector = FER(mtcnn=True)\n",
        "try:\n",
        "  emotion, score = detector.top_emotion(img)\n",
        "  print(emotion, score)\n",
        "except:\n",
        "  print('未偵測到人臉！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7rWS5tPwZSM"
      },
      "source": [
        "## facemask_detection：偵測是否戴口罩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf0VftAZwjHS"
      },
      "source": [
        "!pip install facemask_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6WDDGc-EqsQ"
      },
      "source": [
        "from facemask_detection.pre_trained_models import get_model as get_classifier\n",
        "import albumentations as A\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0YYRrduEtzz"
      },
      "source": [
        "model = get_classifier(\"tf_efficientnet_b0_ns_2020-07-29\")\n",
        "model.eval()\n",
        "image1 = cv2.cvtColor(cv2.imread(\"mask1.jpg\"), cv2.COLOR_BGR2RGB)\n",
        "# image1 = cv2.cvtColor(cv2.imread(\"person1.jpg\"), cv2.COLOR_BGR2RGB)\n",
        "transform = A.Compose([A.SmallestMaxSize(max_size=256, p=1), \n",
        "                       A.CenterCrop(height=224, width=224, p=1),\n",
        "                       A.Normalize(p=1)])\n",
        "trans_image = transform(image=image1)['image']\n",
        "input = torch.from_numpy(np.transpose(trans_image, (2, 0, 1))).unsqueeze(0)\n",
        "print(\"戴口罩的機率為：\", model(input)[0].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ynvd9ruE2LW"
      },
      "source": [
        "## facemask_detection：標示人物是否戴口罩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M-_bQMfFYmS"
      },
      "source": [
        "!pip install facemask_detection\n",
        "!pip install retinaface_pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJ9Rs8lFZsK"
      },
      "source": [
        "from retinaface.pre_trained_models import get_model as get_detector\n",
        "from facemask_detection.pre_trained_models import get_model as get_classifier\n",
        "import albumentations as A\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EVy-AcKFc1j"
      },
      "source": [
        "face_detector = get_detector(\"resnet50_2020-07-20\", max_size=800)\n",
        "face_detector.eval()\n",
        "image1 = cv2.cvtColor(cv2.imread(\"mask3.jpg\"), cv2.COLOR_BGR2RGB)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "plt.imshow(image1)\n",
        "with torch.no_grad():\n",
        "  annotations = face_detector.predict_jsons(image1)\n",
        "print(annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxst0Rw5Fkcz"
      },
      "source": [
        "mask_classifier = get_classifier(\"tf_efficientnet_b0_ns_2020-07-29\")\n",
        "mask_classifier.eval()\n",
        "transform = A.Compose([A.SmallestMaxSize(max_size=256, p=1), \n",
        "                       A.CenterCrop(height=224, width=224, p=1),\n",
        "                       A.Normalize(p=1)])\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "  for annotation in annotations:\n",
        "    x_min, y_min, x_max, y_max = annotation['bbox']\n",
        "    x_min = np.clip(x_min, 0, x_max)\n",
        "    y_min = np.clip(y_min, 0, y_max)\n",
        "    crop = image1[y_min:y_max, x_min:x_max]\n",
        "    crop_transformed = transform(image=crop)['image']\n",
        "    model_input = torch.from_numpy(np.transpose(crop_transformed, (2, 0, 1)))  \n",
        "    predictions += [mask_classifier(model_input.unsqueeze(0))[0].item()] \n",
        "vis_image = image1.copy()\n",
        "for prediction_id, annotation in enumerate(annotations):\n",
        "    is_mask = predictions[prediction_id] > 0.5\n",
        "    if is_mask:\n",
        "      color = (255, 0, 0)    \n",
        "      text = \"mask\"\n",
        "    else:\n",
        "      color = (0, 255, 0)\n",
        "      text = \"no mask\"\n",
        "    x_min, y_min, x_max, y_max = annotation[\"bbox\"]\n",
        "    x_min = np.clip(x_min, 0, x_max - 1)\n",
        "    y_min = np.clip(y_min, 0, y_max - 1)\n",
        "    vis_image = cv2.rectangle(vis_image, (x_min, y_min), (x_max, y_max), color=color, thickness=2)\n",
        "    vis_image = cv2.putText(vis_image, text, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX,  0.4, color, 2, cv2.LINE_AA) \n",
        "plt.imshow(vis_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVMC-hj7D9UH"
      },
      "source": [
        "## Deepface：人臉特徵分析工具"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw8ku_iaEFpV"
      },
      "source": [
        "!pip install deepface"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jclGlzboEbzn"
      },
      "source": [
        "### 人臉偵測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McLX5J9wEWNR"
      },
      "source": [
        "from deepface import DeepFace\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSME_rIzEgs1"
      },
      "source": [
        "imgpath = 'person1.jpg'\n",
        "img_sr = cv2.imread(imgpath)\n",
        "plt.imshow(cv2.cvtColor(img_sr, cv2.COLOR_BGR2RGB))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXX2B7ClFEOq"
      },
      "source": [
        "image = DeepFace.detectFace(img_path=imgpath, enforce_detection=False)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFWGHeFOFIL6"
      },
      "source": [
        "image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAyl9trhFMxT"
      },
      "source": [
        "image *= 255.0\n",
        "cv2.imwrite( \"detectFace.jpg\", image[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7A6nNfJFRHZ"
      },
      "source": [
        "image = DeepFace.detectFace(img_path=imgpath, detector_backend='retinaface', enforce_detection=False)\n",
        "#image = DeepFace.detectFace(img_path=imgpath, detector_backend='mtcnn'', enforce_detection=False)\n",
        "#image = DeepFace.detectFace(img_path=imgpath, detector_backend='dlib'', enforce_detection=False)\n",
        "#image = DeepFace.detectFace(img_path=imgpath, detector_backend='ssd'', enforce_detection=False)  #有錯誤\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cGZyYz5Flpl"
      },
      "source": [
        "### 人臉驗證"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM-X43USFVU_"
      },
      "source": [
        "face1 = 'bear1.jpg'\n",
        "face2 = 'bear2.jpg'\n",
        "#face2 = 'jeng1.jpg'\n",
        "#face2 = 'david1.jpg'\n",
        "result = DeepFace.verify(face1, face2, model_name='DeepFace', model=DeepFace.build_model('DeepFace'), enforce_detection=False)\n",
        "print(result)\n",
        "if result[\"verified\"]: print('兩張圖片是同一人！')\n",
        "else: print('兩張圖片不是同一人！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nRpj_WwF4Q8"
      },
      "source": [
        "face1 = 'bear1.jpg'\n",
        "face2 = 'jeng1.jpg'\n",
        "models = [\"VGG-Face\", \"Facenet\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"Dlib\", \"ArcFace\"]\n",
        "result =[]\n",
        "for model in models: \n",
        "    ret= DeepFace.verify(face1, face2, model_name = model, enforce_detection=False)\n",
        "    result.append(ret)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pAcU8bLGQIV"
      },
      "source": [
        "### 搜尋人臉"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbD2zE5PGRFi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b65h_FcSGK7u"
      },
      "source": [
        "#尋找單一相同人臉\n",
        "face1 = 'bear2.jpg'\n",
        "df = DeepFace.find(img_path = face1, db_path = 'member', enforce_detection=False)\n",
        "#print(df)\n",
        "count = np.sum((df['VGG-Face_cosine']<=0.25)!=0) #計算符合的人臉數量\n",
        "if count > 0:\n",
        "  split1 = df['identity'][0].split('/')\n",
        "  print(split1[-1])\n",
        "else:\n",
        "  print('沒有符合的人臉！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuSmqPaVGhhS"
      },
      "source": [
        "#尋找所有相同人臉\n",
        "face1 = 'tem.jpg'\n",
        "df = DeepFace.find(img_path = face1, db_path = 'member', enforce_detection=False)\n",
        "#print(df)\n",
        "count = np.sum((df['VGG-Face_cosine']<=0.25)!=0) #計算符合的人臉數量\n",
        "if count > 0:\n",
        "  for i in range(count):\n",
        "    split1 = df['identity'][i].split('/')\n",
        "    print(split1[-1])\n",
        "else:\n",
        "  print('沒有符合的人臉！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1LCbK4AGtRw"
      },
      "source": [
        "### 範例：攝影機拍攝登入系統"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAXPkluqGkhd"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def take_photo(filename='person.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = '拍攝';\n",
        "      div.appendChild(capture);\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  print('攝影錯誤：{}'.format(str(err)))\n",
        "\n",
        "df = DeepFace.find(img_path = 'person.jpg', db_path = 'member', enforce_detection=False)\n",
        "#print(df)\n",
        "count = np.sum((df['VGG-Face_cosine']<=0.25)!=0) #計算符合的人臉數量\n",
        "if count > 0:\n",
        "  print('歡迎登入系統！')\n",
        "else:\n",
        "  print('抱歉！你不是會員！')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U10uZe2G9Il"
      },
      "source": [
        "### 人臉屬性分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyr7I5AnG22i"
      },
      "source": [
        "face1 = 'bear1.jpg'\n",
        "img = cv2.imread(face1)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "obj = DeepFace.analyze(img_path = face1, actions = ['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
        "#print(obj)\n",
        "print('年齡：{}'.format(obj['age']))\n",
        "print('性別：{}'.format(obj['gender']))\n",
        "print('種族：{}'.format(obj['dominant_race']))\n",
        "print('情緒：{}'.format(obj['dominant_emotion']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwJIXWofHGNm"
      },
      "source": [
        "### 範例：攝影機拍攝人臉屬性分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULeZMy7UHByp"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image\n",
        "\n",
        "def take_photo(filename='person.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = '拍攝';\n",
        "      div.appendChild(capture);\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  print('攝影錯誤：{}'.format(str(err)))\n",
        "\n",
        "obj = DeepFace.analyze(img_path = 'person.jpg', actions = ['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
        "label = {'angry':'生氣', 'disgust':'厭惡', 'fear':'恐懼', 'happy':'開心', 'neutral':'中性', 'sad':'悲傷', 'surprise':'吃驚',\n",
        "          'Man':'男', 'Woman':'女',\n",
        "          'asian':'亞洲', 'black':'黑', 'indian':'印第安', 'latino hispanic':'拉丁美洲', 'middle eastern':'中東', 'white':'白'}\n",
        "print('\\n你是{}歲的{}性{}人，目前情緒似乎是{}'.format(obj['age'], label[obj['gender']], label[obj['dominant_race']], label[obj['dominant_emotion']]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}