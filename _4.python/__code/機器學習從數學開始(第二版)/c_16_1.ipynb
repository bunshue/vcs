{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = u'data/c_16/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_data=data_path+u'neg.csv'\n",
    "pos_data=data_path+u'pos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pip install jieba\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with codecs.open(neg_data,encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        words = list(jieba.cut(line.replace('|','')))\n",
    "        corpus.append(' '.join(words))\n",
    "\n",
    "neg_df = pd.DataFrame()\n",
    "neg_df['content'] = corpus\n",
    "neg_df['label'] = 0\n",
    "\n",
    "corpus2 = []\n",
    "with codecs.open(pos_data,encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        words = list(jieba.cut(line.replace('|','')))\n",
    "        corpus2.append(' '.join(words))\n",
    "\n",
    "pos_df = pd.DataFrame()\n",
    "pos_df['content']=corpus2\n",
    "pos_df['label'] = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>纸质 很差 ， 封面 也 很 滥 ， 像 盗版书 ， 内容 很 乱 ， 写得 不好 ， 啰 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>纸质 差 ， 总体 只 比 盗版书 好 一点儿 。 \\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>纸张 的 质量 也 不好 ， 文字 部分 更是 倾斜 的 ， 盗版 的 很 不负责任 ， 虽...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>纸张 不好 ， 编校 质量 太烂 ， 别字 连篇 。 内容 还 可以 。 \\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>职场 如 战场 在 这部 小说 里 被 阐述 的 淋漓尽致 ， 拉拉 工作勤奋 如 老黄牛 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  纸质 很差 ， 封面 也 很 滥 ， 像 盗版书 ， 内容 很 乱 ， 写得 不好 ， 啰 ...      0\n",
       "1                     纸质 差 ， 总体 只 比 盗版书 好 一点儿 。 \\r\\n      0\n",
       "2  纸张 的 质量 也 不好 ， 文字 部分 更是 倾斜 的 ， 盗版 的 很 不负责任 ， 虽...      0\n",
       "3          纸张 不好 ， 编校 质量 太烂 ， 别字 连篇 。 内容 还 可以 。 \\r\\n      0\n",
       "4  职场 如 战场 在 这部 小说 里 被 阐述 的 淋漓尽致 ， 拉拉 工作勤奋 如 老黄牛 ...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>昨晚 看着 看着 就 睡着 了 ， 今天 早晨 醒来 就 立马 抓起 继续 啃 ， 正逢 小...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>昨天 我 把 这 套书 看 完 了 ， 结尾 我 不是 很 喜欢 有点 太 戏剧 了 ， 但...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>昨天晚上 看 完 了 ， 此书 揭开 了 猎头 的 神秘 面纱 ， 将 猎头 与 HR 的 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>昨天 带 宝宝 在 朋友 的 小区 玩 。 有 工人 正在 植树 ， 宝宝 目不转睛 地 观...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>最 真实 与 实用 的 白领 成长 故事 ， 也 是 目前为止 我 所读 过 的 最 深刻 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  昨晚 看着 看着 就 睡着 了 ， 今天 早晨 醒来 就 立马 抓起 继续 啃 ， 正逢 小...      1\n",
       "1  昨天 我 把 这 套书 看 完 了 ， 结尾 我 不是 很 喜欢 有点 太 戏剧 了 ， 但...      1\n",
       "2  昨天晚上 看 完 了 ， 此书 揭开 了 猎头 的 神秘 面纱 ， 将 猎头 与 HR 的 ...      1\n",
       "3  昨天 带 宝宝 在 朋友 的 小区 玩 。 有 工人 正在 植树 ， 宝宝 目不转睛 地 观...      1\n",
       "4  最 真实 与 实用 的 白领 成长 故事 ， 也 是 目前为止 我 所读 过 的 最 深刻 ...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.concat((neg_df,pos_df))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>纸质 很差 ， 封面 也 很 滥 ， 像 盗版书 ， 内容 很 乱 ， 写得 不好 ， 啰 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>纸质 差 ， 总体 只 比 盗版书 好 一点儿 。 \\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>纸张 的 质量 也 不好 ， 文字 部分 更是 倾斜 的 ， 盗版 的 很 不负责任 ， 虽...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>纸张 不好 ， 编校 质量 太烂 ， 别字 连篇 。 内容 还 可以 。 \\r\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>职场 如 战场 在 这部 小说 里 被 阐述 的 淋漓尽致 ， 拉拉 工作勤奋 如 老黄牛 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  纸质 很差 ， 封面 也 很 滥 ， 像 盗版书 ， 内容 很 乱 ， 写得 不好 ， 啰 ...      0\n",
       "1                     纸质 差 ， 总体 只 比 盗版书 好 一点儿 。 \\r\\n      0\n",
       "2  纸张 的 质量 也 不好 ， 文字 部分 更是 倾斜 的 ， 盗版 的 很 不负责任 ， 虽...      0\n",
       "3          纸张 不好 ， 编校 质量 太烂 ， 别字 连篇 。 内容 还 可以 。 \\r\\n      0\n",
       "4  职场 如 战场 在 这部 小说 里 被 阐述 的 淋漓尽致 ， 拉拉 工作勤奋 如 老黄牛 ...      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "counts = cv.fit_transform(corpus_df['content'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "targets = corpus_df['label'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = [u'这 本 书 真差', u\"这个 电影 还 可 以\"]\n",
    "example_counts = cv.transform(examples)\n",
    "predictions = classifier.predict(example_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
