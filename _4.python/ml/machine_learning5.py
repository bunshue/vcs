"""
æ©Ÿå™¨å­¸ç¿’å…¥é–€


"""

print("------------------------------------------------------------")  # 60å€‹

# å…±åŒ
import os
import sys
import time
import math
import time
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

font_filename = "C:/_git/vcs/_1.data/______test_files1/_font/msch.ttf"
# è¨­å®šä¸­æ–‡å­—å‹åŠè² è™Ÿæ­£ç¢ºé¡¯ç¤º
# è¨­å®šä¸­æ–‡å­—å‹æª”
plt.rcParams["font.sans-serif"] = "Microsoft JhengHei"  # å°‡å­—é«”æ›æˆ Microsoft JhengHei
# è¨­å®šè² è™Ÿ
plt.rcParams["axes.unicode_minus"] = False  # è®“è² è™Ÿå¯æ­£å¸¸é¡¯ç¤º
plt.rcParams["font.size"] = 12  # è¨­å®šå­—å‹å¤§å°

print("------------------------------------------------------------")  # 60å€‹

"""
01.è®€å…¥åŸºæœ¬å¥—ä»¶

æ©Ÿå™¨å­¸ç¿’å…¶å¯¦åŸºæœ¬ä¸Šå’Œæˆ‘å€‘ä¸€ç›´ä»¥ä¾†èªªçš„ä¸€æ¨£, å°±æ˜¯æˆ‘å€‘è¦å­¸ä¸€å€‹æœªçŸ¥çš„å‡½æ•¸
f(x)=y

å¦‚æœæ˜¯åˆ†é¡, åŸºæœ¬ä¸Šå°±æ˜¯æœ‰ä¸€ç­†è³‡æ–™ x=(x1,x2,â€¦,xk), æˆ‘å€‘æƒ³çŸ¥é“é€™
f(x)=y,å…¶ä¸­çš„ y å°±æ˜¯æŸä¸€å€‹é¡åˆ¥ã€‚

é€™ç¨®å­¸å‡½æ•¸çš„æ–¹æ³•, åˆå¯ä»¥åˆ†ç‚º:

    supervised learning
    unsupervised learning

å…¶ä¸­çš„ supervised learning å°±æ˜¯æˆ‘å€‘æœ‰ä¸€çµ„çŸ¥é“ç­”æ¡ˆçš„è¨“ç·´è³‡æ–™, ç„¶å¾Œæ‰¾åˆ°æˆ‘å€‘è¦çš„å‡½æ•¸ã€‚è€Œ unsupervised learning å°±ç¥äº†, æˆ‘å€‘ä¸çŸ¥é“ç­”æ¡ˆ, å»è¦é›»è…¦è‡ªå·±å»å­¸!

åšæ•¸æ“šåˆ†æ, å¹¾ä¹æ¯ä¸€æ¬¡éƒ½è¦è®€å…¥é€™äº›å¥—ä»¶!
"""

# 02. é—œæ–¼ overfitting

# æˆ‘å€‘åœ¨æ•¸æ“šåˆ†æ, å°±æ˜¯æ”¶é›†äº†æ­·å²è³‡æ–™, æ¯”å¦‚èªªé€™äº›æ•¸æ“šã€‚

X = np.random.randn(6)
Y = np.random.randn(6)
plt.scatter(X, Y, c="r", s=100)
plt.grid()
plt.title("aaaa")
plt.show()

x = np.linspace(0, 1, 200)
y = -((x - 1) ** 2) + 1
plt.plot(x, y)
plt.grid()
plt.title("aaaa")
plt.show()


# çœŸå¯¦ä¸–ç•Œçœ‹ä¾†æ¯”è¼ƒåƒæ˜¯é€™æ¨£...

X = np.linspace(0, 1, 20)
Y = -((X - 1) ** 2) + 1 + 0.08 * np.random.randn(20)
plt.scatter(X, Y, c="r", s=50)
plt.plot(x, y)
plt.grid()
plt.title("aaaa")
plt.show()

z = np.polyfit(X, Y, 19)
p = np.poly1d(z)
plt.plot(x, p(x), "r")
plt.scatter(X, Y, c="r", s=50)
plt.plot(x, y)
plt.ylim(0, 2)
plt.grid()
plt.title("é€™å«å¾ˆä½çš„ bias, å¾ˆé«˜çš„ variance")
plt.show()

"""
03. è¿´æ­¸æ³•é æ¸¬å‡½æ•¸
03-1. å‡çš„æ•¸æ“šçœŸçš„è¿´æ­¸
åšä¸€æ¢ç›´ç·š

æˆ‘å€‘ä¾†ä¸€æ¢ç·š, æ¯”å¦‚èªª f(x)=1.2x+0.8

æº–å‚™å¥½å€‹ 1000 å€‹é» (ç¾å ´å»ºè­°, é›–ç„¶å¤šäº†ä¸€é»...)

åŠ å…¥ noise é …, çœ‹ä¾†æ›´çœŸå¯¦ å¤§æ¦‚çš„æƒ³æ³•å°±æ˜¯, æˆ‘å€‘çœŸå¯¦ä¸–ç•Œçš„å•é¡Œ, åŒ–æˆå‡½æ•¸, æˆ‘å€‘å‡è¨­èƒŒå¾Œæœ‰å€‹ç¾å¥½çš„å‡½æ•¸ã€‚ä½†ç›¸ä¿¡æˆ‘å€‘å¾ˆå°‘çœ‹åˆ°çœŸå¯¦ä¸–ç•Œçš„è³‡æ–™é‚£éº¼æ¼‚äº®ã€‚åœ¨çµ±è¨ˆä¸Š, æˆ‘å€‘å°±æ˜¯å‡è¨­

ğ‘“(ğ‘¥)+ğœ€(ğ‘¥)

ä¹Ÿå°±æ˜¯éƒ½æœ‰å€‹ noise é …ã€‚
"""

x = np.linspace(0, 1, 300)

y = 1.2 * x + 0.8 + 0.2 * np.random.randn(300)

# ç•«å‡ºåœ–å½¢ä¾†ã€‚

plt.scatter(x, y)

plt.grid()
plt.title("aaaa")
plt.show()


"""
åˆ†è¨“ç·´è³‡æ–™ã€æ¸¬è©¦è³‡æ–™

ä¸€èˆ¬æˆ‘å€‘æƒ³è¦çœ‹ç®—å‡ºä¾†çš„é€¼è¿‘å‡½æ•¸åœ¨é æ¸¬ä¸Šæ˜¯ä¸æ˜¯å¯é , æœƒæŠŠä¸€äº›è³‡æ–™ç•™çµ¦ã€Œæ¸¬è©¦ã€, å°±æ˜¯ä¸è®“é›»è…¦åœ¨è¨ˆç®—æ™‚ã€Œçœ‹åˆ°ã€é€™äº›æ¸¬è©¦è³‡æ–™ã€‚ç­‰å‡½æ•¸å­¸æˆäº†ä»¥å¾Œ, å†ä¾†æ¸¬è©¦æº–ä¸æº–ç¢ºã€‚é€™æ˜¯æˆ‘å€‘å¯ä»¥ç”¨

sklearn.model_selection è£¡çš„ train_test_split

ä¾†äº‚æ•¸é¸ä¸€å®šç™¾åˆ†æ¯”çš„è³‡æ–™ä¾†ç”¨ã€‚
"""
from sklearn.model_selection import train_test_split

# æŠŠåŸä¾†çš„ x, y ä¸­çš„ 80% çµ¦ training data, 20% çµ¦ testing dataã€‚

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=9487
)

# len(x_train)    #80%
# len(x_test)     #20%

"""
ã€é‡é»ã€‘æ³¨æ„è¼¸å…¥æ ¼å¼

åªæœ‰ä¸€å€‹ feature æ™‚, æˆ‘å€‘è¦å°å¿ƒçš„æ˜¯, å¾ˆå¤šæ©Ÿå™¨å­¸ç¿’ã€æ·±åº¦å­¸ç¿’çš„å¥—ä»¶, éƒ½ä¸å¸Œæœ›æˆ‘å€‘ç”¨

x=[x1,x2,â€¦,xn]

é€™æ¨£å­å»åš, è€Œæ˜¯å¸Œæœ›è®Šæˆ

x=[[x1],[x2],â€¦,[xn]]

é€™ç¨®å½¢å¼!
"""

xx = np.array([3, 9, 8, 1, 2])
yy = np.array([1, 3, 9, 2, 4])

"""
xx.shape
xx.reshape(5,1)
xx = xx.reshape(len(xx),1)
"""

# æ­£å¼è½‰æˆ‘å€‘çš„è¨“ç·´è³‡æ–™

x_train = x_train.reshape(len(x_train), 1)
x_test = x_test.reshape(len(x_test), 1)

# step 1. é–‹ä¸€å°ã€Œç·šæ€§è¿´æ­¸æ©Ÿã€

from sklearn.linear_model import LinearRegression

regr = LinearRegression()

# step 2. fit å­¸ç¿’ã€è¨“ç·´

regr.fit(x_train, y_train)

# step 3. predict é æ¸¬

Ypred = regr.predict(x_test)

# x: x_test
# y: Ypred
# x_test.ravel()

plt.plot(x_test.ravel(), Ypred, "r")

plt.scatter(x_test.ravel(), y_test)

plt.grid()
plt.title("aaaa")
plt.show()


# è¨ˆç®—åˆ†æ•¸
from sklearn.metrics import mean_squared_error, r2_score

mse_t = mean_squared_error(y_train, regr.predict(x_train))
r2_t = r2_score(y_train, regr.predict(x_train))
print("è¨“ç·´è³‡æ–™")
print("MSE =", mse_t)
print("R2 =", r2_t)

mse = mean_squared_error(y_test, Ypred)
r2 = r2_score(y_test, Ypred)
print("æ¸¬è©¦è³‡æ–™")
print(f"MSE = {mse:.4f}")
print(f"R2 = {r2:.4f}")


print("------------------------------------------------------------")  # 60å€‹

"""
Python-3-Data-Analysis-Basics 1

"""

print("------------------------------------------------------------")  # 60å€‹


"""
åœ¨é‡‘èé æ¸¬ä¸Šçš„æ‡‰ç”¨

"""

print("------------------------------------------------------------")  # 60å€‹

"""
ç¥ç¶“ç¶²è·¯
é€£ SVM éƒ½æ²’è¾¦æ³•, é‚£ä¸€å®šæ˜¯æ–¹æ³•é‚„ä¸å¤ é«˜ç´š, æ‰€ä»¥æˆ‘å€‘ç”¨æ›´é«˜ç´šçš„ç¥ç¶“ç¶²è·¯ä¾†åšåšçœ‹!
"""

from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.optimizers import SGD

# [2] æ‰“é€ æˆ‘å€‘çš„ç¥ç¶“ç¶²è·¯å‡½æ•¸å­¸ç¿’æ©Ÿ

model = Sequential()

model.add(Dense(20, input_dim=5))

model.add(Activation("relu"))

model.add(Dense(20))

model.add(Activation("relu"))

model.add(Dense(1))

model.add(Activation("sigmoid"))

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# çœ‹ä¸€ä¸‹æˆ‘å€‘ç¥ç¶“ç¶²è·¯é•·ä»€éº¼æ¨£å­, æœ‰æ²’æœ‰åšéŒ¯ã€‚

model.summary()


""" TBD
#[3] è¨“ç·´

model.fit(x_train, yb_train, batch_size=100, epochs=20)


#[4] é æ¸¬

#çœ‹èµ·ä¾†ä¸å¤ªå¦™, æˆ‘å€‘ä¾†è©¦è©¦é æ¸¬...

NN_pred = model.predict_classes(x_test)

YP_NN = yb_test[(NN_pred==1).ravel()]

len(YP_NN)

458

len(YP_NN[YP_NN == 1])

246

246/458

0.537117903930131

çµæœçœŸæ˜¯æ…˜æ…˜æ…˜, æ€éº¼æœƒé€™æ¨£å‘¢?

"""

print("------------------------------------------------------------")  # 60å€‹

"""
13.ç•«æˆ‘å€‘ç·´ç¿’æˆæœçš„è¨è«–


"""

print("------------------------------------------------------------")  # 60å€‹

# 02 [ç·´ç¿’] åœ–å½¢åŒ–æˆ‘å€‘çš„æˆæœ

# 1. ä¸Šæ¬¡çš„æˆæœæ‹¿å›ä¾†ä½¿ç”¨

# è¨˜å¾—ä¸Šæ¬¡æˆ‘å€‘åšäº†å€‹é³¶å°¾èŠ±åˆ†é¡å™¨ã€‚
# 1.1 æ‰¾å›æˆ‘å€‘çš„åˆ†é¡å™¨

from sklearn.externals import joblib

clf = joblib.load("iris_clf_01.pkl")

# çœŸçš„å¯ä»¥ç”¨äº†å—?

print(clf.predict([[2, 3]]))


# å¯ä»¥! å¤ªæ£’äº†!
# 1.2 çœ‹çœ‹æˆ‘å€‘åˆ†é¡çš„å…¨è²Œ

# æˆ‘å€‘ç”¨ä¸€ä¸‹ä¹‹å‰çš„æ–¹å¼, ç•«å‡ºæˆ‘å€‘æƒ³è¦çœ‹åˆ°æˆ‘å€‘å¯æ„›çš„ SVM æ˜¯æ€éº¼ä»¥èŠ±è¼é•·åº¦ã€èŠ±è¼å¯¬åº¦ä¾†åˆ†é¡çš„ã€‚
# ä¸Šæ¬¡æˆ‘å€‘ç”¨äº† Python æ‰€è¬‚ "list comprehension" çš„ä½œæ³• (æœ¬è³ªä¸Šæ˜¯ for è¿´åœˆ), ç¾åœ¨æˆ‘å€‘æ›å€‹æ–¹å¼çœ‹ä¾†æ¯”è¼ƒã€Œé«˜ç´šã€çš„æ–¹å¼ã€‚

xt, yt = np.meshgrid(np.arange(-2, 2, 0.5), np.arange(-1, 1, 0.5))

print(xt)
print(yt)

# çœ‹å¾—å‡ºä¾† meshgrid åšäº†ä»€éº¼å‘¢? åŸºæœ¬ä¸Šå®ƒå°±æ˜¯èªªæˆ‘å€‘åœ¨ x, y å…©å€‹æŒ‡å®šç¯„åœçš„é•·æ–¹å‹ç•¶ä¸­, ä¾æˆ‘å€‘æŒ‡å®šçš„é–“éš”æ‰¾å‡ºæ ¼é»ã€‚
# é€™äº›æ ¼é»çš„åº§æ¨™åˆ†æˆ x åº§æ¨™ä¸€å€‹ array, y åº§æ¨™ä¸€å€‹ã€‚x æˆ– y åº§æ¨™çš„ array, çš„åº§æ¨™æ˜¯ä¸€åˆ—ä¸€åˆ—æ¨™è¨˜çš„ã€‚
# è¦æ˜¯ä½ è¦ºå¾—é€™æ¨£çš„è¡¨ç¤ºæ³•å¾ˆè¨å­, æˆ‘å€‘ä¹Ÿå¯ä»¥è®“å®ƒè®Šä¸€é•·ä¸²çš„å‘é‡ã€‚

print(xt.ravel())

# æ³¨æ„é€™å…¶å¯¦åŸä¾†çš„ xt ä¸¦æ²’æœ‰è®Šå“¦ã€‚

print(xt)

# æˆ‘å€‘å¯ä»¥æŠŠ (x,y) ä¸€é»ä¸€é»çš„åº§æ¨™æ”¶é›†èµ·ä¾†å—?

print(np.c_[xt.ravel(), yt.ravel()])


# æŠŠè³‡æ–™çš„å‹å¼é€™æ¨£è®Šä¾†è®Šå»æœƒæ˜¯æ•¸æ“šåˆ†æéå¸¸éå¸¸å¸¸åšçš„äº‹æƒ…ã€‚
# æˆ‘å€‘ç¶“é€™éº¼å¤šå»¢è©±å¾Œçµ‚æ–¼å¯ä»¥ä¾†åšæ­£äº‹ã€‚

xx, yy = np.meshgrid(np.arange(3, 8.5, 0.2), np.arange(1.5, 5.0, 0.2))

Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

plt.scatter(xx.ravel(), yy.ravel(), s=50, c=Z)
plt.show()

# é›–ç„¶çœ‹ä¾†æˆ‘å€‘ç”¨äº†æ¯”è¼ƒå¤šç™½ç—´çš„æ–¹æ³•åšå‡ºä¸€æ¨£çš„äº‹, ä¸éä¸€äº›æŠ€å·§ä¹‹å¾Œä¹Ÿå¯ä»¥å¸¸å¸¸ä½¿ç”¨ã€‚
# 1.3 å¿«é€Ÿæ›å€‹é…è‰²

plt.scatter(xx.ravel(), yy.ravel(), s=50, c=Z, cmap=plt.cm.coolwarm, alpha=0.8)
plt.show()


plt.scatter(xx.ravel(), yy.ravel(), s=50, c=Z, cmap=plt.cm.prism, alpha=0.8)
plt.show()


# 1.4 å–å›é³¶å°¾èŠ±è¨“ç·´è³‡æ–™

from sklearn.datasets import load_iris

iris = load_iris()

x = iris.data[:, :2]

y = iris.target

# æˆ‘å€‘ä¾†ç•«ç•«æ¯”è¼ƒã€‚

plt.subplot(121)

plt.scatter(x[:, 0], x[:, 1], s=50, c=y)

plt.subplot(122)

plt.scatter(x[:, 0], x[:, 1], s=50, c=clf.predict(x))

plt.show()

# å·¦é‚Šçš„æ˜¯è¨“ç·´è³‡æ–™, å³é‚Šæ˜¯ç”¨æˆ‘å€‘ SVM åˆ†é¡å™¨åˆ†å‡ºä¾†çš„ã€‚ä½ æœ‰çœ‹å‡ºå·®ç•°å—? æ˜¯ä¸æ˜¯å¾ˆé›£çœ‹å‡º? æˆ‘å€‘ä¾†ç”¨ç”¨å¦ä¸€å€‹æ–¹å¼ã€‚

# 1.5 ç•«åœ–çš„å¦ä¸€å€‹æ–¹å¼

xx, yy = np.meshgrid(np.arange(3, 8.5, 0.02), np.arange(1.5, 5.0, 0.02))
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)
plt.show()


Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)
plt.scatter(x[:, 0], x[:, 1], s=50, c=y, cmap=plt.cm.coolwarm)
plt.show()

print("------------------------------------------------------------")  # 60å€‹

# æ‰“é–‹ä¸€å€‹ç·šæ€§è¿´æ­¸çš„å‡½æ•¸å­¸ç¿’æ©Ÿ

from sklearn.linear_model import LinearRegression

regr = LinearRegression()

# é€ è³‡æ–™, èª¿æ•´æˆ sklearn æœƒæ¥å—çš„å½¢ç‹€

x = np.linspace(0, 5, 100)
y = 1.9 * x + 0.8 + 0.5 * np.random.randn(100)

X = x.reshape(len(x), 1)

# æŠŠè³‡æ–™æ”¾é€²å‡½æ•¸å­¸ç¿’æ©Ÿï¼Œé–‹å§‹å®ƒçš„è¨“ç·´

regr.fit(X, y)

# ç”¨ predict çœ‹ä¸€ä¸‹è¨“ç·´çš„æˆæœï¼Œé †ä¾¿ç•«å€‹åœ–

Y = regr.predict(X)

plt.scatter(x, y)
plt.plot(x, Y, "r")
plt.show()

# çµæœçœ‹èµ·ä¾†ä¸éŒ¯ï¼Œæœƒæœ‰å¾®å°èª¤å·®çš„åŸå› ï¼Œå‰‡æ˜¯å› ç‚ºçœŸå¯¦ä¸–ç•Œçš„è³‡æ–™æœ‰ä¸å¯é¿å…çš„é›œè¨Š

print("------------------------------------------------------------")  # 60å€‹

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# å‡å‹»åœ°åœ¨ 0 åˆ° 5 ä¹‹é–“å–ä¸€ç™¾å€‹é»ï¼Œå†éš¨ä¾¿æ±ºå®šä¸€å€‹å‡½æ•¸ï¼Œå«åš y = f(x) = 1.9x + 0.8 å¥½äº†
# ç‚ºäº†å¢åŠ çœŸå¯¦æ„Ÿï¼ŒåŠ ä¸Šä¸€é»é›œè¨Š

x = np.linspace(0, 5, 100)
y = 1.9 * x + 0.8 + 0.5 * np.random.randn(100)

# é–‹é–‹å¿ƒå¿ƒåœ°è®“ sklearn å¹«æˆ‘å€‘åˆ†é›¢å‡ºè¨“ç·´è³‡æ–™è·Ÿæ¸¬è©¦è³‡æ–™ï¼Œæ¸¬è©¦è³‡æ–™çš„æ¯”ä¾‹æ˜¯ 0.3 çš„è©±ï¼Œ
# è¨“ç·´è³‡æ–™å°±æœƒè‡ªå‹•æ˜¯ 0.7 äº†å‘¢ï¼ŒçœŸæ˜¯æ–¹ä¾¿ï¼
# random_state å¯ä»¥æ˜¯è€å¯¶ç”¨çš„ 87 ï¼Œè¦é¸å…¶ä»–æ•¸å­—ä¹Ÿç•¶ç„¶å¯ä»¥

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.3, random_state=87
)
x_train = x_train.reshape(len(x_train), 1)
x_test = x_test.reshape(len(x_test), 1)

# ä¸€æ¨£å«å‡ºä¸€å€‹ç·šæ€§è¿´æ­¸çš„å‡½æ•¸å­¸ç¿’æ©Ÿï¼Œå†æ”¾é€²ã€Œè¨“ç·´è³‡æ–™ã€è®“å®ƒé–‹å§‹è¨“ç·´

regr = LinearRegression()
regr.fit(x_train, y_train)

# ç”¨ plot æŠŠã€Œè¨“ç·´è³‡æ–™ã€çš„æ­£ç¢ºç­”æ¡ˆç•«æˆä¸€æ¢ç·šï¼Œå†æŠŠæ¨¡å‹ predict å‡ºä¾†çš„çµæœæé»ç•«åœ¨åŒä¸€å¼µåœ–ä¸Š
# å¯ä»¥æ¸…æ¥šçš„çœ‹åˆ°çµæœ

plt.scatter(x_train, y_train)
plt.plot(x_train, regr.predict(x_train), "r")
plt.show()


# è·Ÿä¸Šé¢ä¸€æ¨£çš„åšæ³•ï¼Œåªæ˜¯é€™æ¬¡å°è±¡æ›æˆã€Œæ¸¬è©¦è³‡æ–™ã€

plt.scatter(x_test, y_test)
plt.plot(x_test, regr.predict(x_test), "r")
plt.show()

print("------------------------------------------------------------")  # 60å€‹


print("------------------------------------------------------------")  # 60å€‹


print("------------------------------------------------------------")  # 60å€‹




