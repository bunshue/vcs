"""
æ©Ÿå™¨å­¸ç¿’å…¥é–€


"""

import sys
import numpy as np
import matplotlib.pyplot as plt

print('------------------------------------------------------------')	#60å€‹

"""
01.è®€å…¥åŸºæœ¬å¥—ä»¶

æ©Ÿå™¨å­¸ç¿’å…¶å¯¦åŸºæœ¬ä¸Šå’Œæˆ‘å€‘ä¸€ç›´ä»¥ä¾†èªªçš„ä¸€æ¨£, å°±æ˜¯æˆ‘å€‘è¦å­¸ä¸€å€‹æœªçŸ¥çš„å‡½æ•¸
f(x)=y

å¦‚æœæ˜¯åˆ†é¡, åŸºæœ¬ä¸Šå°±æ˜¯æœ‰ä¸€ç­†è³‡æ–™ x=(x1,x2,â€¦,xk), æˆ‘å€‘æƒ³çŸ¥é“é€™
f(x)=y,å…¶ä¸­çš„ y å°±æ˜¯æŸä¸€å€‹é¡åˆ¥ã€‚

é€™ç¨®å­¸å‡½æ•¸çš„æ–¹æ³•, åˆå¯ä»¥åˆ†ç‚º:

    supervised learning
    unsupervised learning

å…¶ä¸­çš„ supervised learning å°±æ˜¯æˆ‘å€‘æœ‰ä¸€çµ„çŸ¥é“ç­”æ¡ˆçš„è¨“ç·´è³‡æ–™, ç„¶å¾Œæ‰¾åˆ°æˆ‘å€‘è¦çš„å‡½æ•¸ã€‚è€Œ unsupervised learning å°±ç¥äº†, æˆ‘å€‘ä¸çŸ¥é“ç­”æ¡ˆ, å»è¦é›»è…¦è‡ªå·±å»å­¸!

åšæ•¸æ“šåˆ†æ, å¹¾ä¹æ¯ä¸€æ¬¡éƒ½è¦è®€å…¥é€™äº›å¥—ä»¶!
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# ç”¨ Seaborn ç•«åœ–, ä¸¦è¨­å¥½åœ–çš„å¤§å°

import seaborn as sns
sns.set(rc={'figure.figsize':(11.7,8.27)})


#02. é—œæ–¼ overfitting

#æˆ‘å€‘åœ¨æ•¸æ“šåˆ†æ, å°±æ˜¯æ”¶é›†äº†æ­·å²è³‡æ–™, æ¯”å¦‚èªªé€™äº›æ•¸æ“šã€‚

X = np.random.randn(6)
Y = np.random.randn(6)
plt.scatter(X, Y, c='r', s=100)
plt.grid()
plt.title('aaaa')
plt.show()

x = np.linspace(0, 1, 200)
y = -(x-1)**2+1
plt.plot(x,y)
plt.grid()
plt.title('aaaa')
plt.show()


#çœŸå¯¦ä¸–ç•Œçœ‹ä¾†æ¯”è¼ƒåƒæ˜¯é€™æ¨£...

X = np.linspace(0, 1, 20)
Y = -(X-1)**2+1 + 0.08*np.random.randn(20)
plt.scatter(X,Y, c='r',s=50)
plt.plot(x,y)
plt.grid()
plt.title('aaaa')
plt.show()

z = np.polyfit(X, Y, 19)
p = np.poly1d(z)
plt.plot(x, p(x),'r')
plt.scatter(X,Y, c='r',s=50)
plt.plot(x,y)
plt.ylim(0, 2)
plt.grid()
plt.title('é€™å«å¾ˆä½çš„ bias, å¾ˆé«˜çš„ variance')
plt.show()

"""
03. è¿´æ­¸æ³•é æ¸¬å‡½æ•¸
03-1. å‡çš„æ•¸æ“šçœŸçš„è¿´æ­¸
åšä¸€æ¢ç›´ç·š

æˆ‘å€‘ä¾†ä¸€æ¢ç·š, æ¯”å¦‚èªª f(x)=1.2x+0.8

æº–å‚™å¥½å€‹ 1000 å€‹é» (ç¾å ´å»ºè­°, é›–ç„¶å¤šäº†ä¸€é»...)

åŠ å…¥ noise é …, çœ‹ä¾†æ›´çœŸå¯¦ å¤§æ¦‚çš„æƒ³æ³•å°±æ˜¯, æˆ‘å€‘çœŸå¯¦ä¸–ç•Œçš„å•é¡Œ, åŒ–æˆå‡½æ•¸, æˆ‘å€‘å‡è¨­èƒŒå¾Œæœ‰å€‹ç¾å¥½çš„å‡½æ•¸ã€‚ä½†ç›¸ä¿¡æˆ‘å€‘å¾ˆå°‘çœ‹åˆ°çœŸå¯¦ä¸–ç•Œçš„è³‡æ–™é‚£éº¼æ¼‚äº®ã€‚åœ¨çµ±è¨ˆä¸Š, æˆ‘å€‘å°±æ˜¯å‡è¨­

ğ‘“(ğ‘¥)+ğœ€(ğ‘¥)

ä¹Ÿå°±æ˜¯éƒ½æœ‰å€‹ noise é …ã€‚
"""

x = np.linspace(0, 1, 300)

y = 1.2*x + 0.8 + 0.2*np.random.randn(300)

#ç•«å‡ºåœ–å½¢ä¾†ã€‚

plt.scatter(x,y)

plt.grid()
plt.title('aaaa')
plt.show()


"""
åˆ†è¨“ç·´è³‡æ–™ã€æ¸¬è©¦è³‡æ–™

ä¸€èˆ¬æˆ‘å€‘æƒ³è¦çœ‹ç®—å‡ºä¾†çš„é€¼è¿‘å‡½æ•¸åœ¨é æ¸¬ä¸Šæ˜¯ä¸æ˜¯å¯é , æœƒæŠŠä¸€äº›è³‡æ–™ç•™çµ¦ã€Œæ¸¬è©¦ã€, å°±æ˜¯ä¸è®“é›»è…¦åœ¨è¨ˆç®—æ™‚ã€Œçœ‹åˆ°ã€é€™äº›æ¸¬è©¦è³‡æ–™ã€‚ç­‰å‡½æ•¸å­¸æˆäº†ä»¥å¾Œ, å†ä¾†æ¸¬è©¦æº–ä¸æº–ç¢ºã€‚é€™æ˜¯æˆ‘å€‘å¯ä»¥ç”¨

sklearn.model_selection è£¡çš„ train_test_split

ä¾†äº‚æ•¸é¸ä¸€å®šç™¾åˆ†æ¯”çš„è³‡æ–™ä¾†ç”¨ã€‚
"""
from sklearn.model_selection import train_test_split

#æŠŠåŸä¾†çš„ x, y ä¸­çš„ 80% çµ¦ training data, 20% çµ¦ testing dataã€‚

x_train, x_test, y_train, y_test = train_test_split(x, y,
                                                   test_size = 0.2,
                                                   random_state = 9487)

#len(x_train)    #80%
#len(x_test)     #20%

"""
ã€é‡é»ã€‘æ³¨æ„è¼¸å…¥æ ¼å¼

åªæœ‰ä¸€å€‹ feature æ™‚, æˆ‘å€‘è¦å°å¿ƒçš„æ˜¯, å¾ˆå¤šæ©Ÿå™¨å­¸ç¿’ã€æ·±åº¦å­¸ç¿’çš„å¥—ä»¶, éƒ½ä¸å¸Œæœ›æˆ‘å€‘ç”¨

x=[x1,x2,â€¦,xn]

é€™æ¨£å­å»åš, è€Œæ˜¯å¸Œæœ›è®Šæˆ

x=[[x1],[x2],â€¦,[xn]]

é€™ç¨®å½¢å¼!
"""

xx = np.array([3, 9, 8, 1, 2])
yy = np.array([1, 3, 9, 2, 4])

"""
xx.shape
xx.reshape(5,1)
xx = xx.reshape(len(xx),1)
"""

#æ­£å¼è½‰æˆ‘å€‘çš„è¨“ç·´è³‡æ–™

x_train = x_train.reshape(len(x_train),1)
x_test = x_test.reshape(len(x_test), 1)

#step 1. é–‹ä¸€å°ã€Œç·šæ€§è¿´æ­¸æ©Ÿã€

from sklearn.linear_model import LinearRegression

regr = LinearRegression()

#step 2. fit å­¸ç¿’ã€è¨“ç·´

regr.fit(x_train, y_train)

#step 3. predict é æ¸¬

Ypred = regr.predict(x_test)

# x: x_test
# y: Ypred
# x_test.ravel()

plt.plot(x_test.ravel(), Ypred, 'r')

plt.scatter(x_test.ravel(), y_test)

plt.grid()
plt.title('aaaa')
plt.show()


#è¨ˆç®—åˆ†æ•¸
from sklearn.metrics import mean_squared_error, r2_score
mse_t = mean_squared_error(y_train, regr.predict(x_train))
r2_t = r2_score(y_train, regr.predict(x_train))
print('è¨“ç·´è³‡æ–™')
print('MSE =', mse_t)
print("R2 =", r2_t)

mse = mean_squared_error(y_test, Ypred)
r2 = r2_score(y_test, Ypred)
print("æ¸¬è©¦è³‡æ–™")
print(f"MSE = {mse:.4f}")
print(f"R2 = {r2:.4f}")




print('------------------------------------------------------------')	#60å€‹


print('ä½œæ¥­å®Œæˆ')

